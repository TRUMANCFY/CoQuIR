{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ea4328-f22c-4da2-8df0-38bedffb93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "from scipy.stats import pearsonr\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Sequence\n",
    "import copy\n",
    "from typing import Dict, Any, List\n",
    "random.seed(9001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eeebbac-d925-406e-8a09-d7e657f9cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "from mteb.task_selection import results_to_dataframe\n",
    "from mteb.abstasks.AbsTask import AbsTask\n",
    "from mteb.load_results.mteb_results import MTEBResults\n",
    "from mteb.model_meta import ModelMeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e165a-6ffc-4a25-8297-f94f02b6fb54",
   "metadata": {},
   "source": [
    "### Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fbd34d-9287-410f-9924-892f30a34a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = \n",
    "DATASET_DIR = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f85a720-e9f6-43db-b1eb-f11afbd7a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(result_dir: str,\n",
    "                    models: List[str],\n",
    "                    tasks: List[str],\n",
    "                    score_name: str='main_score') -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load PIR results and compute the mean score across tasks for each model.\n",
    "\n",
    "    Args:\n",
    "        result_dir (str): Directory containing the results.\n",
    "        models (List[str]): List of model names.\n",
    "        tasks (List[str]): List of task names.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, Any]]: Nested dictionary with model names as keys,\n",
    "            each containing a dictionary of task scores and a 'mean' key for the average score.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = defaultdict(dict)\n",
    "    for _model in models:\n",
    "        _model_path = os.path.join(result_dir, _model.replace('/', '__'))\n",
    "        assert os.path.isdir(_model_path), f\"Model {_model} not found in {result_dir}\"\n",
    "        \n",
    "        # Only one directory under _model_path\n",
    "        directories = [d for d in os.listdir(_model_path) if os.path.isdir(os.path.join(_model_path, d))]\n",
    "        assert len(directories) == 1, f\"Model {_model} has more than one directory\"\n",
    "        \n",
    "        sub_directories = [\n",
    "            d for d in os.listdir(os.path.join(_model_path, directories[0]))\n",
    "            if os.path.isdir(os.path.join(_model_path, directories[0], d))\n",
    "        ]\n",
    "        assert len(sub_directories) == 1, f\"Model {_model} has more than one sub-directory\"\n",
    "        \n",
    "        scores = []  # List to store scores for computing the mean\n",
    "        for _task in tasks:\n",
    "            _task_path = os.path.join(\n",
    "                _model_path, directories[0], sub_directories[0], f'{_task}.json'\n",
    "            )\n",
    "            if os.path.isfile(_task_path):\n",
    "                with open(_task_path, 'r') as f:\n",
    "                    score = np.mean([_score[score_name] for _score in json.load(f)['scores']['test']])\n",
    "                    results[_model][_task] = score\n",
    "                    scores.append(score)\n",
    "            else:\n",
    "                print(f\"Task {_task} not found in {result_dir}/{_model}\")\n",
    "                results[_model][_task] = 0\n",
    "                scores.append(0)\n",
    "        \n",
    "        # Compute and store the mean score for the current model\n",
    "        if scores:\n",
    "            mean_score = sum(scores) / len(scores)\n",
    "            results[_model]['mean'] = mean_score\n",
    "        else:\n",
    "            results[_model]['mean'] = None  # Handle case with no scores\n",
    "\n",
    "    return results\n",
    "\n",
    "def highlight_max_in_column(s):\n",
    "    \"\"\"\n",
    "    Highlights the maximum value in a Series with bold text.\n",
    "\n",
    "    Args:\n",
    "        s (pd.Series): A pandas Series representing a column in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of styles for each element in the Series.\n",
    "    \"\"\"\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38422998-fa3a-4649-a8c0-3f9b50875066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finegrained_results(result_dir: str,\n",
    "                    models: List[str],\n",
    "                    tasks: List[str],\n",
    "                    score_name: str = 'main_score') -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load PIR results and compute the mean score across tasks for each model.\n",
    "\n",
    "    Args:\n",
    "        result_dir (str): Directory containing the results.\n",
    "        models (List[str]): List of model names.\n",
    "        tasks (List[str]): List of task names.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, Any]]: Nested dictionary with model names as keys,\n",
    "            each containing a dictionary of task scores and a 'mean' key for the average score.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = defaultdict(dict)\n",
    "    for _model in models:\n",
    "        _model_path = os.path.join(result_dir, _model.replace('/', '__'))\n",
    "        assert os.path.isdir(_model_path), f\"Model {_model} not found in {result_dir}\"\n",
    "        \n",
    "        # Only one directory under _model_path\n",
    "        directories = [d for d in os.listdir(_model_path) if os.path.isdir(os.path.join(_model_path, d))]\n",
    "        assert len(directories) == 1, f\"Model {_model} has more than one directory\"\n",
    "        \n",
    "        sub_directories = [\n",
    "            d for d in os.listdir(os.path.join(_model_path, directories[0]))\n",
    "            if os.path.isdir(os.path.join(_model_path, directories[0], d))\n",
    "        ]\n",
    "        assert len(sub_directories) == 1, f\"Model {_model} has more than one sub-directory\"\n",
    "        \n",
    "        scores = []  # List to store scores for computing the mean\n",
    "        for _task in tasks:\n",
    "            _task_path = os.path.join(\n",
    "                _model_path, directories[0], sub_directories[0], f'{_task}.json'\n",
    "            )\n",
    "            if os.path.isfile(_task_path):\n",
    "                with open(_task_path, 'r') as f:\n",
    "                    for _hf_subset, _score in [(_score['hf_subset'], _score[score_name]) for _score in json.load(f)['scores']['test']]:\n",
    "                        results[_model][_task + '-' + _hf_subset] = _score\n",
    "                        scores.append(_score)\n",
    "            else:\n",
    "                print(f\"Task {_task} not found in {result_dir}/{_model}\")\n",
    "                results[_model][_task] = 0\n",
    "                scores.append(0)\n",
    "        \n",
    "        # Compute and store the mean score for the current model\n",
    "        if scores:\n",
    "            mean_score = sum(scores) / len(scores)\n",
    "            results[_model]['mean'] = mean_score\n",
    "        else:\n",
    "            results[_model]['mean'] = None  # Handle case with no scores\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df24ea-249b-44b1-94a8-3c2dcf311f28",
   "metadata": {},
   "source": [
    "## 1. Stardard Code Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963c6e48-2654-4adc-8512-de247119995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    'CodeNetBugPreferenceRetrieval',\n",
    "    'CodeNetEfficiencyPreferenceRetrieval',\n",
    "    'CVEFixesPreferenceRetrieval',\n",
    "    'Defects4JPreferenceRetrieval',\n",
    "    'DeprecatedCodePreferenceRetrieval',\n",
    "    'SaferCodePreferenceRetrieval',\n",
    "    'SQLR2PreferenceRetrieval',\n",
    "]\n",
    "\n",
    "models = [\n",
    "    'bm25s',\n",
    "    'facebook__contriever',\n",
    "    'Alibaba-NLP__gte-base-en-v1.5',\n",
    "    'sentence-transformers__gtr-t5-base',\n",
    "    'sentence-transformers__gtr-t5-large',\n",
    "    'intfloat__e5-base-v2',\n",
    "    'intfloat__e5-large-v2',\n",
    "    'Alibaba-NLP__gte-Qwen2-1.5B-instruct',\n",
    "    'intfloat__e5-mistral-7b-instruct',\n",
    "    'hkunlp__instructor-base',\n",
    "    'hkunlp__instructor-large',\n",
    "    'hkunlp__instructor-xl',\n",
    "    'samaya-ai__promptriever-llama2-7b-v1',\n",
    "    'samaya-ai__promptriever-llama3.1-8b-v1',\n",
    "    'samaya-ai__promptriever-llama3.1-8b-instruct-v1',\n",
    "    'samaya-ai__promptriever-mistral-v0.1-7b-v1',\n",
    "    'openai__text-embedding-ada-002',\n",
    "    'openai__text-embedding-3-small',\n",
    "    'openai__text-embedding-3-large',\n",
    "    'voyageai__voyage-code-2',\n",
    "    'voyageai__voyage-code-3',\n",
    "    'microsoft__codebert-base',\n",
    "    'microsoft__graphcodebert-base',\n",
    "    'nomic-ai__CodeRankEmbed',\n",
    "    'local-repllama-llama31-8b-lora-64',\n",
    "    'local-repllama-llama31-8b-lora-64-quality',\n",
    "    'local-repllama-llama32-3b-lora-256',\n",
    "    'local-repllama-llama32-3b-lora-256-quality',\n",
    "    'codesage__codesage-small',\n",
    "    'codesage__codesage-base',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b54025-ff50-464e-8006-254b76f7a346",
   "metadata": {},
   "source": [
    "### nDCG@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a50e9a7f-f483-411f-aba2-9213a5116c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_365d4_row12_col3, #T_365d4_row14_col4, #T_365d4_row20_col0, #T_365d4_row20_col1, #T_365d4_row20_col2, #T_365d4_row20_col5, #T_365d4_row20_col6, #T_365d4_row20_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_365d4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_365d4_level0_col0\" class=\"col_heading level0 col0\" >CodeNetBugPreferenceRetrieval</th>\n",
       "      <th id=\"T_365d4_level0_col1\" class=\"col_heading level0 col1\" >CodeNetEfficiencyPreferenceRetrieval</th>\n",
       "      <th id=\"T_365d4_level0_col2\" class=\"col_heading level0 col2\" >CVEFixesPreferenceRetrieval</th>\n",
       "      <th id=\"T_365d4_level0_col3\" class=\"col_heading level0 col3\" >Defects4JPreferenceRetrieval</th>\n",
       "      <th id=\"T_365d4_level0_col4\" class=\"col_heading level0 col4\" >DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th id=\"T_365d4_level0_col5\" class=\"col_heading level0 col5\" >SaferCodePreferenceRetrieval</th>\n",
       "      <th id=\"T_365d4_level0_col6\" class=\"col_heading level0 col6\" >SQLR2PreferenceRetrieval</th>\n",
       "      <th id=\"T_365d4_level0_col7\" class=\"col_heading level0 col7\" >mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row0\" class=\"row_heading level0 row0\" >bm25s</th>\n",
       "      <td id=\"T_365d4_row0_col0\" class=\"data row0 col0\" >0.023690</td>\n",
       "      <td id=\"T_365d4_row0_col1\" class=\"data row0 col1\" >0.016018</td>\n",
       "      <td id=\"T_365d4_row0_col2\" class=\"data row0 col2\" >0.686708</td>\n",
       "      <td id=\"T_365d4_row0_col3\" class=\"data row0 col3\" >0.649520</td>\n",
       "      <td id=\"T_365d4_row0_col4\" class=\"data row0 col4\" >0.513111</td>\n",
       "      <td id=\"T_365d4_row0_col5\" class=\"data row0 col5\" >0.562674</td>\n",
       "      <td id=\"T_365d4_row0_col6\" class=\"data row0 col6\" >0.407440</td>\n",
       "      <td id=\"T_365d4_row0_col7\" class=\"data row0 col7\" >0.408452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row1\" class=\"row_heading level0 row1\" >facebook__contriever</th>\n",
       "      <td id=\"T_365d4_row1_col0\" class=\"data row1 col0\" >0.042602</td>\n",
       "      <td id=\"T_365d4_row1_col1\" class=\"data row1 col1\" >0.035560</td>\n",
       "      <td id=\"T_365d4_row1_col2\" class=\"data row1 col2\" >0.577292</td>\n",
       "      <td id=\"T_365d4_row1_col3\" class=\"data row1 col3\" >0.496500</td>\n",
       "      <td id=\"T_365d4_row1_col4\" class=\"data row1 col4\" >0.373674</td>\n",
       "      <td id=\"T_365d4_row1_col5\" class=\"data row1 col5\" >0.461494</td>\n",
       "      <td id=\"T_365d4_row1_col6\" class=\"data row1 col6\" >0.181760</td>\n",
       "      <td id=\"T_365d4_row1_col7\" class=\"data row1 col7\" >0.309840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row2\" class=\"row_heading level0 row2\" >Alibaba-NLP__gte-base-en-v1.5</th>\n",
       "      <td id=\"T_365d4_row2_col0\" class=\"data row2 col0\" >0.050217</td>\n",
       "      <td id=\"T_365d4_row2_col1\" class=\"data row2 col1\" >0.040711</td>\n",
       "      <td id=\"T_365d4_row2_col2\" class=\"data row2 col2\" >0.756770</td>\n",
       "      <td id=\"T_365d4_row2_col3\" class=\"data row2 col3\" >0.741200</td>\n",
       "      <td id=\"T_365d4_row2_col4\" class=\"data row2 col4\" >0.553405</td>\n",
       "      <td id=\"T_365d4_row2_col5\" class=\"data row2 col5\" >0.706559</td>\n",
       "      <td id=\"T_365d4_row2_col6\" class=\"data row2 col6\" >0.138020</td>\n",
       "      <td id=\"T_365d4_row2_col7\" class=\"data row2 col7\" >0.426697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row3\" class=\"row_heading level0 row3\" >sentence-transformers__gtr-t5-base</th>\n",
       "      <td id=\"T_365d4_row3_col0\" class=\"data row3 col0\" >0.037531</td>\n",
       "      <td id=\"T_365d4_row3_col1\" class=\"data row3 col1\" >0.031757</td>\n",
       "      <td id=\"T_365d4_row3_col2\" class=\"data row3 col2\" >0.755962</td>\n",
       "      <td id=\"T_365d4_row3_col3\" class=\"data row3 col3\" >0.746810</td>\n",
       "      <td id=\"T_365d4_row3_col4\" class=\"data row3 col4\" >0.535365</td>\n",
       "      <td id=\"T_365d4_row3_col5\" class=\"data row3 col5\" >0.729153</td>\n",
       "      <td id=\"T_365d4_row3_col6\" class=\"data row3 col6\" >0.106860</td>\n",
       "      <td id=\"T_365d4_row3_col7\" class=\"data row3 col7\" >0.420491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row4\" class=\"row_heading level0 row4\" >sentence-transformers__gtr-t5-large</th>\n",
       "      <td id=\"T_365d4_row4_col0\" class=\"data row4 col0\" >0.072997</td>\n",
       "      <td id=\"T_365d4_row4_col1\" class=\"data row4 col1\" >0.062108</td>\n",
       "      <td id=\"T_365d4_row4_col2\" class=\"data row4 col2\" >0.796960</td>\n",
       "      <td id=\"T_365d4_row4_col3\" class=\"data row4 col3\" >0.782220</td>\n",
       "      <td id=\"T_365d4_row4_col4\" class=\"data row4 col4\" >0.595779</td>\n",
       "      <td id=\"T_365d4_row4_col5\" class=\"data row4 col5\" >0.753480</td>\n",
       "      <td id=\"T_365d4_row4_col6\" class=\"data row4 col6\" >0.162230</td>\n",
       "      <td id=\"T_365d4_row4_col7\" class=\"data row4 col7\" >0.460825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row5\" class=\"row_heading level0 row5\" >intfloat__e5-base-v2</th>\n",
       "      <td id=\"T_365d4_row5_col0\" class=\"data row5 col0\" >0.078253</td>\n",
       "      <td id=\"T_365d4_row5_col1\" class=\"data row5 col1\" >0.062887</td>\n",
       "      <td id=\"T_365d4_row5_col2\" class=\"data row5 col2\" >0.815572</td>\n",
       "      <td id=\"T_365d4_row5_col3\" class=\"data row5 col3\" >0.803840</td>\n",
       "      <td id=\"T_365d4_row5_col4\" class=\"data row5 col4\" >0.670520</td>\n",
       "      <td id=\"T_365d4_row5_col5\" class=\"data row5 col5\" >0.770150</td>\n",
       "      <td id=\"T_365d4_row5_col6\" class=\"data row5 col6\" >0.427900</td>\n",
       "      <td id=\"T_365d4_row5_col7\" class=\"data row5 col7\" >0.518446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row6\" class=\"row_heading level0 row6\" >intfloat__e5-large-v2</th>\n",
       "      <td id=\"T_365d4_row6_col0\" class=\"data row6 col0\" >0.150840</td>\n",
       "      <td id=\"T_365d4_row6_col1\" class=\"data row6 col1\" >0.134210</td>\n",
       "      <td id=\"T_365d4_row6_col2\" class=\"data row6 col2\" >0.816638</td>\n",
       "      <td id=\"T_365d4_row6_col3\" class=\"data row6 col3\" >0.813650</td>\n",
       "      <td id=\"T_365d4_row6_col4\" class=\"data row6 col4\" >0.679690</td>\n",
       "      <td id=\"T_365d4_row6_col5\" class=\"data row6 col5\" >0.759033</td>\n",
       "      <td id=\"T_365d4_row6_col6\" class=\"data row6 col6\" >0.424720</td>\n",
       "      <td id=\"T_365d4_row6_col7\" class=\"data row6 col7\" >0.539826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row7\" class=\"row_heading level0 row7\" >Alibaba-NLP__gte-Qwen2-1.5B-instruct</th>\n",
       "      <td id=\"T_365d4_row7_col0\" class=\"data row7 col0\" >0.122938</td>\n",
       "      <td id=\"T_365d4_row7_col1\" class=\"data row7 col1\" >0.114149</td>\n",
       "      <td id=\"T_365d4_row7_col2\" class=\"data row7 col2\" >0.843964</td>\n",
       "      <td id=\"T_365d4_row7_col3\" class=\"data row7 col3\" >0.809370</td>\n",
       "      <td id=\"T_365d4_row7_col4\" class=\"data row7 col4\" >0.735735</td>\n",
       "      <td id=\"T_365d4_row7_col5\" class=\"data row7 col5\" >0.786633</td>\n",
       "      <td id=\"T_365d4_row7_col6\" class=\"data row7 col6\" >0.199780</td>\n",
       "      <td id=\"T_365d4_row7_col7\" class=\"data row7 col7\" >0.516081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row8\" class=\"row_heading level0 row8\" >intfloat__e5-mistral-7b-instruct</th>\n",
       "      <td id=\"T_365d4_row8_col0\" class=\"data row8 col0\" >0.329696</td>\n",
       "      <td id=\"T_365d4_row8_col1\" class=\"data row8 col1\" >0.296498</td>\n",
       "      <td id=\"T_365d4_row8_col2\" class=\"data row8 col2\" >0.818562</td>\n",
       "      <td id=\"T_365d4_row8_col3\" class=\"data row8 col3\" >0.824220</td>\n",
       "      <td id=\"T_365d4_row8_col4\" class=\"data row8 col4\" >0.724860</td>\n",
       "      <td id=\"T_365d4_row8_col5\" class=\"data row8 col5\" >0.764849</td>\n",
       "      <td id=\"T_365d4_row8_col6\" class=\"data row8 col6\" >0.308340</td>\n",
       "      <td id=\"T_365d4_row8_col7\" class=\"data row8 col7\" >0.581004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row9\" class=\"row_heading level0 row9\" >hkunlp__instructor-base</th>\n",
       "      <td id=\"T_365d4_row9_col0\" class=\"data row9 col0\" >0.044007</td>\n",
       "      <td id=\"T_365d4_row9_col1\" class=\"data row9 col1\" >0.036884</td>\n",
       "      <td id=\"T_365d4_row9_col2\" class=\"data row9 col2\" >0.802858</td>\n",
       "      <td id=\"T_365d4_row9_col3\" class=\"data row9 col3\" >0.800850</td>\n",
       "      <td id=\"T_365d4_row9_col4\" class=\"data row9 col4\" >0.613234</td>\n",
       "      <td id=\"T_365d4_row9_col5\" class=\"data row9 col5\" >0.743686</td>\n",
       "      <td id=\"T_365d4_row9_col6\" class=\"data row9 col6\" >0.124450</td>\n",
       "      <td id=\"T_365d4_row9_col7\" class=\"data row9 col7\" >0.452281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row10\" class=\"row_heading level0 row10\" >hkunlp__instructor-large</th>\n",
       "      <td id=\"T_365d4_row10_col0\" class=\"data row10 col0\" >0.085355</td>\n",
       "      <td id=\"T_365d4_row10_col1\" class=\"data row10 col1\" >0.076783</td>\n",
       "      <td id=\"T_365d4_row10_col2\" class=\"data row10 col2\" >0.799242</td>\n",
       "      <td id=\"T_365d4_row10_col3\" class=\"data row10 col3\" >0.777570</td>\n",
       "      <td id=\"T_365d4_row10_col4\" class=\"data row10 col4\" >0.615350</td>\n",
       "      <td id=\"T_365d4_row10_col5\" class=\"data row10 col5\" >0.750184</td>\n",
       "      <td id=\"T_365d4_row10_col6\" class=\"data row10 col6\" >0.205130</td>\n",
       "      <td id=\"T_365d4_row10_col7\" class=\"data row10 col7\" >0.472802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row11\" class=\"row_heading level0 row11\" >hkunlp__instructor-xl</th>\n",
       "      <td id=\"T_365d4_row11_col0\" class=\"data row11 col0\" >0.094322</td>\n",
       "      <td id=\"T_365d4_row11_col1\" class=\"data row11 col1\" >0.081941</td>\n",
       "      <td id=\"T_365d4_row11_col2\" class=\"data row11 col2\" >0.812452</td>\n",
       "      <td id=\"T_365d4_row11_col3\" class=\"data row11 col3\" >0.805940</td>\n",
       "      <td id=\"T_365d4_row11_col4\" class=\"data row11 col4\" >0.628151</td>\n",
       "      <td id=\"T_365d4_row11_col5\" class=\"data row11 col5\" >0.760073</td>\n",
       "      <td id=\"T_365d4_row11_col6\" class=\"data row11 col6\" >0.242900</td>\n",
       "      <td id=\"T_365d4_row11_col7\" class=\"data row11 col7\" >0.489397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row12\" class=\"row_heading level0 row12\" >samaya-ai__promptriever-llama2-7b-v1</th>\n",
       "      <td id=\"T_365d4_row12_col0\" class=\"data row12 col0\" >0.249912</td>\n",
       "      <td id=\"T_365d4_row12_col1\" class=\"data row12 col1\" >0.226173</td>\n",
       "      <td id=\"T_365d4_row12_col2\" class=\"data row12 col2\" >0.852512</td>\n",
       "      <td id=\"T_365d4_row12_col3\" class=\"data row12 col3\" >0.848970</td>\n",
       "      <td id=\"T_365d4_row12_col4\" class=\"data row12 col4\" >0.725905</td>\n",
       "      <td id=\"T_365d4_row12_col5\" class=\"data row12 col5\" >0.794741</td>\n",
       "      <td id=\"T_365d4_row12_col6\" class=\"data row12 col6\" >0.380270</td>\n",
       "      <td id=\"T_365d4_row12_col7\" class=\"data row12 col7\" >0.582640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row13\" class=\"row_heading level0 row13\" >samaya-ai__promptriever-llama3.1-8b-v1</th>\n",
       "      <td id=\"T_365d4_row13_col0\" class=\"data row13 col0\" >0.393214</td>\n",
       "      <td id=\"T_365d4_row13_col1\" class=\"data row13 col1\" >0.359524</td>\n",
       "      <td id=\"T_365d4_row13_col2\" class=\"data row13 col2\" >0.846532</td>\n",
       "      <td id=\"T_365d4_row13_col3\" class=\"data row13 col3\" >0.837610</td>\n",
       "      <td id=\"T_365d4_row13_col4\" class=\"data row13 col4\" >0.749201</td>\n",
       "      <td id=\"T_365d4_row13_col5\" class=\"data row13 col5\" >0.793270</td>\n",
       "      <td id=\"T_365d4_row13_col6\" class=\"data row13 col6\" >0.409950</td>\n",
       "      <td id=\"T_365d4_row13_col7\" class=\"data row13 col7\" >0.627043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row14\" class=\"row_heading level0 row14\" >samaya-ai__promptriever-llama3.1-8b-instruct-v1</th>\n",
       "      <td id=\"T_365d4_row14_col0\" class=\"data row14 col0\" >0.443575</td>\n",
       "      <td id=\"T_365d4_row14_col1\" class=\"data row14 col1\" >0.408819</td>\n",
       "      <td id=\"T_365d4_row14_col2\" class=\"data row14 col2\" >0.849664</td>\n",
       "      <td id=\"T_365d4_row14_col3\" class=\"data row14 col3\" >0.843490</td>\n",
       "      <td id=\"T_365d4_row14_col4\" class=\"data row14 col4\" >0.757373</td>\n",
       "      <td id=\"T_365d4_row14_col5\" class=\"data row14 col5\" >0.797880</td>\n",
       "      <td id=\"T_365d4_row14_col6\" class=\"data row14 col6\" >0.462870</td>\n",
       "      <td id=\"T_365d4_row14_col7\" class=\"data row14 col7\" >0.651953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row15\" class=\"row_heading level0 row15\" >samaya-ai__promptriever-mistral-v0.1-7b-v1</th>\n",
       "      <td id=\"T_365d4_row15_col0\" class=\"data row15 col0\" >0.330670</td>\n",
       "      <td id=\"T_365d4_row15_col1\" class=\"data row15 col1\" >0.305847</td>\n",
       "      <td id=\"T_365d4_row15_col2\" class=\"data row15 col2\" >0.847970</td>\n",
       "      <td id=\"T_365d4_row15_col3\" class=\"data row15 col3\" >0.847060</td>\n",
       "      <td id=\"T_365d4_row15_col4\" class=\"data row15 col4\" >0.727672</td>\n",
       "      <td id=\"T_365d4_row15_col5\" class=\"data row15 col5\" >0.783384</td>\n",
       "      <td id=\"T_365d4_row15_col6\" class=\"data row15 col6\" >0.392570</td>\n",
       "      <td id=\"T_365d4_row15_col7\" class=\"data row15 col7\" >0.605025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row16\" class=\"row_heading level0 row16\" >openai__text-embedding-ada-002</th>\n",
       "      <td id=\"T_365d4_row16_col0\" class=\"data row16 col0\" >0.322489</td>\n",
       "      <td id=\"T_365d4_row16_col1\" class=\"data row16 col1\" >0.289987</td>\n",
       "      <td id=\"T_365d4_row16_col2\" class=\"data row16 col2\" >0.825258</td>\n",
       "      <td id=\"T_365d4_row16_col3\" class=\"data row16 col3\" >0.823100</td>\n",
       "      <td id=\"T_365d4_row16_col4\" class=\"data row16 col4\" >0.627890</td>\n",
       "      <td id=\"T_365d4_row16_col5\" class=\"data row16 col5\" >0.771706</td>\n",
       "      <td id=\"T_365d4_row16_col6\" class=\"data row16 col6\" >0.333310</td>\n",
       "      <td id=\"T_365d4_row16_col7\" class=\"data row16 col7\" >0.570534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row17\" class=\"row_heading level0 row17\" >openai__text-embedding-3-small</th>\n",
       "      <td id=\"T_365d4_row17_col0\" class=\"data row17 col0\" >0.168091</td>\n",
       "      <td id=\"T_365d4_row17_col1\" class=\"data row17 col1\" >0.143453</td>\n",
       "      <td id=\"T_365d4_row17_col2\" class=\"data row17 col2\" >0.817368</td>\n",
       "      <td id=\"T_365d4_row17_col3\" class=\"data row17 col3\" >0.814710</td>\n",
       "      <td id=\"T_365d4_row17_col4\" class=\"data row17 col4\" >0.672451</td>\n",
       "      <td id=\"T_365d4_row17_col5\" class=\"data row17 col5\" >0.767576</td>\n",
       "      <td id=\"T_365d4_row17_col6\" class=\"data row17 col6\" >0.288430</td>\n",
       "      <td id=\"T_365d4_row17_col7\" class=\"data row17 col7\" >0.524583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row18\" class=\"row_heading level0 row18\" >openai__text-embedding-3-large</th>\n",
       "      <td id=\"T_365d4_row18_col0\" class=\"data row18 col0\" >0.287930</td>\n",
       "      <td id=\"T_365d4_row18_col1\" class=\"data row18 col1\" >0.241333</td>\n",
       "      <td id=\"T_365d4_row18_col2\" class=\"data row18 col2\" >0.826900</td>\n",
       "      <td id=\"T_365d4_row18_col3\" class=\"data row18 col3\" >0.821330</td>\n",
       "      <td id=\"T_365d4_row18_col4\" class=\"data row18 col4\" >0.695605</td>\n",
       "      <td id=\"T_365d4_row18_col5\" class=\"data row18 col5\" >0.775780</td>\n",
       "      <td id=\"T_365d4_row18_col6\" class=\"data row18 col6\" >0.371120</td>\n",
       "      <td id=\"T_365d4_row18_col7\" class=\"data row18 col7\" >0.574285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row19\" class=\"row_heading level0 row19\" >voyageai__voyage-code-2</th>\n",
       "      <td id=\"T_365d4_row19_col0\" class=\"data row19 col0\" >0.716851</td>\n",
       "      <td id=\"T_365d4_row19_col1\" class=\"data row19 col1\" >0.679973</td>\n",
       "      <td id=\"T_365d4_row19_col2\" class=\"data row19 col2\" >0.844760</td>\n",
       "      <td id=\"T_365d4_row19_col3\" class=\"data row19 col3\" >0.828270</td>\n",
       "      <td id=\"T_365d4_row19_col4\" class=\"data row19 col4\" >0.739011</td>\n",
       "      <td id=\"T_365d4_row19_col5\" class=\"data row19 col5\" >0.776910</td>\n",
       "      <td id=\"T_365d4_row19_col6\" class=\"data row19 col6\" >0.424910</td>\n",
       "      <td id=\"T_365d4_row19_col7\" class=\"data row19 col7\" >0.715812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row20\" class=\"row_heading level0 row20\" >voyageai__voyage-code-3</th>\n",
       "      <td id=\"T_365d4_row20_col0\" class=\"data row20 col0\" >0.791577</td>\n",
       "      <td id=\"T_365d4_row20_col1\" class=\"data row20 col1\" >0.747922</td>\n",
       "      <td id=\"T_365d4_row20_col2\" class=\"data row20 col2\" >0.858070</td>\n",
       "      <td id=\"T_365d4_row20_col3\" class=\"data row20 col3\" >0.845350</td>\n",
       "      <td id=\"T_365d4_row20_col4\" class=\"data row20 col4\" >0.753332</td>\n",
       "      <td id=\"T_365d4_row20_col5\" class=\"data row20 col5\" >0.826597</td>\n",
       "      <td id=\"T_365d4_row20_col6\" class=\"data row20 col6\" >0.495530</td>\n",
       "      <td id=\"T_365d4_row20_col7\" class=\"data row20 col7\" >0.759768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row21\" class=\"row_heading level0 row21\" >microsoft__codebert-base</th>\n",
       "      <td id=\"T_365d4_row21_col0\" class=\"data row21 col0\" >0.003616</td>\n",
       "      <td id=\"T_365d4_row21_col1\" class=\"data row21 col1\" >0.001682</td>\n",
       "      <td id=\"T_365d4_row21_col2\" class=\"data row21 col2\" >0.010848</td>\n",
       "      <td id=\"T_365d4_row21_col3\" class=\"data row21 col3\" >0.010270</td>\n",
       "      <td id=\"T_365d4_row21_col4\" class=\"data row21 col4\" >0.006474</td>\n",
       "      <td id=\"T_365d4_row21_col5\" class=\"data row21 col5\" >0.045433</td>\n",
       "      <td id=\"T_365d4_row21_col6\" class=\"data row21 col6\" >0.001910</td>\n",
       "      <td id=\"T_365d4_row21_col7\" class=\"data row21 col7\" >0.011462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row22\" class=\"row_heading level0 row22\" >microsoft__graphcodebert-base</th>\n",
       "      <td id=\"T_365d4_row22_col0\" class=\"data row22 col0\" >0.006623</td>\n",
       "      <td id=\"T_365d4_row22_col1\" class=\"data row22 col1\" >0.003934</td>\n",
       "      <td id=\"T_365d4_row22_col2\" class=\"data row22 col2\" >0.087800</td>\n",
       "      <td id=\"T_365d4_row22_col3\" class=\"data row22 col3\" >0.048470</td>\n",
       "      <td id=\"T_365d4_row22_col4\" class=\"data row22 col4\" >0.024099</td>\n",
       "      <td id=\"T_365d4_row22_col5\" class=\"data row22 col5\" >0.154910</td>\n",
       "      <td id=\"T_365d4_row22_col6\" class=\"data row22 col6\" >0.003660</td>\n",
       "      <td id=\"T_365d4_row22_col7\" class=\"data row22 col7\" >0.047071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row23\" class=\"row_heading level0 row23\" >nomic-ai__CodeRankEmbed</th>\n",
       "      <td id=\"T_365d4_row23_col0\" class=\"data row23 col0\" >0.064095</td>\n",
       "      <td id=\"T_365d4_row23_col1\" class=\"data row23 col1\" >0.046057</td>\n",
       "      <td id=\"T_365d4_row23_col2\" class=\"data row23 col2\" >0.804296</td>\n",
       "      <td id=\"T_365d4_row23_col3\" class=\"data row23 col3\" >0.811770</td>\n",
       "      <td id=\"T_365d4_row23_col4\" class=\"data row23 col4\" >0.724124</td>\n",
       "      <td id=\"T_365d4_row23_col5\" class=\"data row23 col5\" >0.706596</td>\n",
       "      <td id=\"T_365d4_row23_col6\" class=\"data row23 col6\" >0.367850</td>\n",
       "      <td id=\"T_365d4_row23_col7\" class=\"data row23 col7\" >0.503541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row24\" class=\"row_heading level0 row24\" >local-repllama-llama31-8b-lora-64</th>\n",
       "      <td id=\"T_365d4_row24_col0\" class=\"data row24 col0\" >0.360581</td>\n",
       "      <td id=\"T_365d4_row24_col1\" class=\"data row24 col1\" >0.335464</td>\n",
       "      <td id=\"T_365d4_row24_col2\" class=\"data row24 col2\" >0.837022</td>\n",
       "      <td id=\"T_365d4_row24_col3\" class=\"data row24 col3\" >0.824340</td>\n",
       "      <td id=\"T_365d4_row24_col4\" class=\"data row24 col4\" >0.732781</td>\n",
       "      <td id=\"T_365d4_row24_col5\" class=\"data row24 col5\" >0.790347</td>\n",
       "      <td id=\"T_365d4_row24_col6\" class=\"data row24 col6\" >0.407620</td>\n",
       "      <td id=\"T_365d4_row24_col7\" class=\"data row24 col7\" >0.612594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row25\" class=\"row_heading level0 row25\" >local-repllama-llama31-8b-lora-64-quality</th>\n",
       "      <td id=\"T_365d4_row25_col0\" class=\"data row25 col0\" >0.359437</td>\n",
       "      <td id=\"T_365d4_row25_col1\" class=\"data row25 col1\" >0.346802</td>\n",
       "      <td id=\"T_365d4_row25_col2\" class=\"data row25 col2\" >0.796812</td>\n",
       "      <td id=\"T_365d4_row25_col3\" class=\"data row25 col3\" >0.760110</td>\n",
       "      <td id=\"T_365d4_row25_col4\" class=\"data row25 col4\" >0.681421</td>\n",
       "      <td id=\"T_365d4_row25_col5\" class=\"data row25 col5\" >0.809073</td>\n",
       "      <td id=\"T_365d4_row25_col6\" class=\"data row25 col6\" >0.327750</td>\n",
       "      <td id=\"T_365d4_row25_col7\" class=\"data row25 col7\" >0.583058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row26\" class=\"row_heading level0 row26\" >local-repllama-llama32-3b-lora-256</th>\n",
       "      <td id=\"T_365d4_row26_col0\" class=\"data row26 col0\" >0.269011</td>\n",
       "      <td id=\"T_365d4_row26_col1\" class=\"data row26 col1\" >0.232464</td>\n",
       "      <td id=\"T_365d4_row26_col2\" class=\"data row26 col2\" >0.831238</td>\n",
       "      <td id=\"T_365d4_row26_col3\" class=\"data row26 col3\" >0.816580</td>\n",
       "      <td id=\"T_365d4_row26_col4\" class=\"data row26 col4\" >0.724812</td>\n",
       "      <td id=\"T_365d4_row26_col5\" class=\"data row26 col5\" >0.772413</td>\n",
       "      <td id=\"T_365d4_row26_col6\" class=\"data row26 col6\" >0.397500</td>\n",
       "      <td id=\"T_365d4_row26_col7\" class=\"data row26 col7\" >0.577717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row27\" class=\"row_heading level0 row27\" >local-repllama-llama32-3b-lora-256-quality</th>\n",
       "      <td id=\"T_365d4_row27_col0\" class=\"data row27 col0\" >0.262220</td>\n",
       "      <td id=\"T_365d4_row27_col1\" class=\"data row27 col1\" >0.242653</td>\n",
       "      <td id=\"T_365d4_row27_col2\" class=\"data row27 col2\" >0.780576</td>\n",
       "      <td id=\"T_365d4_row27_col3\" class=\"data row27 col3\" >0.744160</td>\n",
       "      <td id=\"T_365d4_row27_col4\" class=\"data row27 col4\" >0.607230</td>\n",
       "      <td id=\"T_365d4_row27_col5\" class=\"data row27 col5\" >0.793976</td>\n",
       "      <td id=\"T_365d4_row27_col6\" class=\"data row27 col6\" >0.274910</td>\n",
       "      <td id=\"T_365d4_row27_col7\" class=\"data row27 col7\" >0.529389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row28\" class=\"row_heading level0 row28\" >codesage__codesage-small</th>\n",
       "      <td id=\"T_365d4_row28_col0\" class=\"data row28 col0\" >0.155909</td>\n",
       "      <td id=\"T_365d4_row28_col1\" class=\"data row28 col1\" >0.130395</td>\n",
       "      <td id=\"T_365d4_row28_col2\" class=\"data row28 col2\" >0.816314</td>\n",
       "      <td id=\"T_365d4_row28_col3\" class=\"data row28 col3\" >0.801960</td>\n",
       "      <td id=\"T_365d4_row28_col4\" class=\"data row28 col4\" >0.709867</td>\n",
       "      <td id=\"T_365d4_row28_col5\" class=\"data row28 col5\" >0.776359</td>\n",
       "      <td id=\"T_365d4_row28_col6\" class=\"data row28 col6\" >0.091140</td>\n",
       "      <td id=\"T_365d4_row28_col7\" class=\"data row28 col7\" >0.497421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_365d4_level0_row29\" class=\"row_heading level0 row29\" >codesage__codesage-base</th>\n",
       "      <td id=\"T_365d4_row29_col0\" class=\"data row29 col0\" >0.206335</td>\n",
       "      <td id=\"T_365d4_row29_col1\" class=\"data row29 col1\" >0.179977</td>\n",
       "      <td id=\"T_365d4_row29_col2\" class=\"data row29 col2\" >0.814862</td>\n",
       "      <td id=\"T_365d4_row29_col3\" class=\"data row29 col3\" >0.823870</td>\n",
       "      <td id=\"T_365d4_row29_col4\" class=\"data row29 col4\" >0.716305</td>\n",
       "      <td id=\"T_365d4_row29_col5\" class=\"data row29 col5\" >0.776571</td>\n",
       "      <td id=\"T_365d4_row29_col6\" class=\"data row29 col6\" >0.153570</td>\n",
       "      <td id=\"T_365d4_row29_col7\" class=\"data row29 col7\" >0.524499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa1a120d0a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_results(RESULT_DIR, models, tasks)\n",
    "df = pd.DataFrame.from_dict(data, orient='index').style.apply(highlight_max_in_column, axis=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093eec55-f142-455d-a093-7999772e461d",
   "metadata": {},
   "source": [
    "### MRR@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b650e633-df67-4cc4-8b14-64b2864f7e80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_13359_row15_col3, #T_13359_row20_col0, #T_13359_row20_col1, #T_13359_row20_col2, #T_13359_row20_col4, #T_13359_row20_col5, #T_13359_row20_col6, #T_13359_row20_col7 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_13359\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_13359_level0_col0\" class=\"col_heading level0 col0\" >CodeNetBugPreferenceRetrieval</th>\n",
       "      <th id=\"T_13359_level0_col1\" class=\"col_heading level0 col1\" >CodeNetEfficiencyPreferenceRetrieval</th>\n",
       "      <th id=\"T_13359_level0_col2\" class=\"col_heading level0 col2\" >CVEFixesPreferenceRetrieval</th>\n",
       "      <th id=\"T_13359_level0_col3\" class=\"col_heading level0 col3\" >Defects4JPreferenceRetrieval</th>\n",
       "      <th id=\"T_13359_level0_col4\" class=\"col_heading level0 col4\" >DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th id=\"T_13359_level0_col5\" class=\"col_heading level0 col5\" >SaferCodePreferenceRetrieval</th>\n",
       "      <th id=\"T_13359_level0_col6\" class=\"col_heading level0 col6\" >SQLR2PreferenceRetrieval</th>\n",
       "      <th id=\"T_13359_level0_col7\" class=\"col_heading level0 col7\" >mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row0\" class=\"row_heading level0 row0\" >bm25s</th>\n",
       "      <td id=\"T_13359_row0_col0\" class=\"data row0 col0\" >0.027623</td>\n",
       "      <td id=\"T_13359_row0_col1\" class=\"data row0 col1\" >0.017121</td>\n",
       "      <td id=\"T_13359_row0_col2\" class=\"data row0 col2\" >0.620801</td>\n",
       "      <td id=\"T_13359_row0_col3\" class=\"data row0 col3\" >0.571994</td>\n",
       "      <td id=\"T_13359_row0_col4\" class=\"data row0 col4\" >0.345391</td>\n",
       "      <td id=\"T_13359_row0_col5\" class=\"data row0 col5\" >0.480747</td>\n",
       "      <td id=\"T_13359_row0_col6\" class=\"data row0 col6\" >0.367719</td>\n",
       "      <td id=\"T_13359_row0_col7\" class=\"data row0 col7\" >0.347343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row1\" class=\"row_heading level0 row1\" >facebook__contriever</th>\n",
       "      <td id=\"T_13359_row1_col0\" class=\"data row1 col0\" >0.058414</td>\n",
       "      <td id=\"T_13359_row1_col1\" class=\"data row1 col1\" >0.047684</td>\n",
       "      <td id=\"T_13359_row1_col2\" class=\"data row1 col2\" >0.498378</td>\n",
       "      <td id=\"T_13359_row1_col3\" class=\"data row1 col3\" >0.430755</td>\n",
       "      <td id=\"T_13359_row1_col4\" class=\"data row1 col4\" >0.299047</td>\n",
       "      <td id=\"T_13359_row1_col5\" class=\"data row1 col5\" >0.362177</td>\n",
       "      <td id=\"T_13359_row1_col6\" class=\"data row1 col6\" >0.165324</td>\n",
       "      <td id=\"T_13359_row1_col7\" class=\"data row1 col7\" >0.265968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row2\" class=\"row_heading level0 row2\" >Alibaba-NLP__gte-base-en-v1.5</th>\n",
       "      <td id=\"T_13359_row2_col0\" class=\"data row2 col0\" >0.067853</td>\n",
       "      <td id=\"T_13359_row2_col1\" class=\"data row2 col1\" >0.055278</td>\n",
       "      <td id=\"T_13359_row2_col2\" class=\"data row2 col2\" >0.675761</td>\n",
       "      <td id=\"T_13359_row2_col3\" class=\"data row2 col3\" >0.671603</td>\n",
       "      <td id=\"T_13359_row2_col4\" class=\"data row2 col4\" >0.458251</td>\n",
       "      <td id=\"T_13359_row2_col5\" class=\"data row2 col5\" >0.615709</td>\n",
       "      <td id=\"T_13359_row2_col6\" class=\"data row2 col6\" >0.120718</td>\n",
       "      <td id=\"T_13359_row2_col7\" class=\"data row2 col7\" >0.380739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row3\" class=\"row_heading level0 row3\" >sentence-transformers__gtr-t5-base</th>\n",
       "      <td id=\"T_13359_row3_col0\" class=\"data row3 col0\" >0.054817</td>\n",
       "      <td id=\"T_13359_row3_col1\" class=\"data row3 col1\" >0.043855</td>\n",
       "      <td id=\"T_13359_row3_col2\" class=\"data row3 col2\" >0.670361</td>\n",
       "      <td id=\"T_13359_row3_col3\" class=\"data row3 col3\" >0.664680</td>\n",
       "      <td id=\"T_13359_row3_col4\" class=\"data row3 col4\" >0.440766</td>\n",
       "      <td id=\"T_13359_row3_col5\" class=\"data row3 col5\" >0.634615</td>\n",
       "      <td id=\"T_13359_row3_col6\" class=\"data row3 col6\" >0.084533</td>\n",
       "      <td id=\"T_13359_row3_col7\" class=\"data row3 col7\" >0.370518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row4\" class=\"row_heading level0 row4\" >sentence-transformers__gtr-t5-large</th>\n",
       "      <td id=\"T_13359_row4_col0\" class=\"data row4 col0\" >0.100716</td>\n",
       "      <td id=\"T_13359_row4_col1\" class=\"data row4 col1\" >0.081560</td>\n",
       "      <td id=\"T_13359_row4_col2\" class=\"data row4 col2\" >0.715084</td>\n",
       "      <td id=\"T_13359_row4_col3\" class=\"data row4 col3\" >0.707569</td>\n",
       "      <td id=\"T_13359_row4_col4\" class=\"data row4 col4\" >0.493739</td>\n",
       "      <td id=\"T_13359_row4_col5\" class=\"data row4 col5\" >0.654435</td>\n",
       "      <td id=\"T_13359_row4_col6\" class=\"data row4 col6\" >0.127128</td>\n",
       "      <td id=\"T_13359_row4_col7\" class=\"data row4 col7\" >0.411461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row5\" class=\"row_heading level0 row5\" >intfloat__e5-base-v2</th>\n",
       "      <td id=\"T_13359_row5_col0\" class=\"data row5 col0\" >0.108133</td>\n",
       "      <td id=\"T_13359_row5_col1\" class=\"data row5 col1\" >0.085871</td>\n",
       "      <td id=\"T_13359_row5_col2\" class=\"data row5 col2\" >0.740699</td>\n",
       "      <td id=\"T_13359_row5_col3\" class=\"data row5 col3\" >0.734029</td>\n",
       "      <td id=\"T_13359_row5_col4\" class=\"data row5 col4\" >0.554018</td>\n",
       "      <td id=\"T_13359_row5_col5\" class=\"data row5 col5\" >0.682599</td>\n",
       "      <td id=\"T_13359_row5_col6\" class=\"data row5 col6\" >0.385947</td>\n",
       "      <td id=\"T_13359_row5_col7\" class=\"data row5 col7\" >0.470185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row6\" class=\"row_heading level0 row6\" >intfloat__e5-large-v2</th>\n",
       "      <td id=\"T_13359_row6_col0\" class=\"data row6 col0\" >0.195422</td>\n",
       "      <td id=\"T_13359_row6_col1\" class=\"data row6 col1\" >0.174440</td>\n",
       "      <td id=\"T_13359_row6_col2\" class=\"data row6 col2\" >0.741656</td>\n",
       "      <td id=\"T_13359_row6_col3\" class=\"data row6 col3\" >0.745225</td>\n",
       "      <td id=\"T_13359_row6_col4\" class=\"data row6 col4\" >0.561858</td>\n",
       "      <td id=\"T_13359_row6_col5\" class=\"data row6 col5\" >0.670862</td>\n",
       "      <td id=\"T_13359_row6_col6\" class=\"data row6 col6\" >0.381011</td>\n",
       "      <td id=\"T_13359_row6_col7\" class=\"data row6 col7\" >0.495782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row7\" class=\"row_heading level0 row7\" >Alibaba-NLP__gte-Qwen2-1.5B-instruct</th>\n",
       "      <td id=\"T_13359_row7_col0\" class=\"data row7 col0\" >0.157970</td>\n",
       "      <td id=\"T_13359_row7_col1\" class=\"data row7 col1\" >0.148821</td>\n",
       "      <td id=\"T_13359_row7_col2\" class=\"data row7 col2\" >0.785788</td>\n",
       "      <td id=\"T_13359_row7_col3\" class=\"data row7 col3\" >0.740444</td>\n",
       "      <td id=\"T_13359_row7_col4\" class=\"data row7 col4\" >0.617184</td>\n",
       "      <td id=\"T_13359_row7_col5\" class=\"data row7 col5\" >0.703080</td>\n",
       "      <td id=\"T_13359_row7_col6\" class=\"data row7 col6\" >0.154275</td>\n",
       "      <td id=\"T_13359_row7_col7\" class=\"data row7 col7\" >0.472509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row8\" class=\"row_heading level0 row8\" >intfloat__e5-mistral-7b-instruct</th>\n",
       "      <td id=\"T_13359_row8_col0\" class=\"data row8 col0\" >0.399009</td>\n",
       "      <td id=\"T_13359_row8_col1\" class=\"data row8 col1\" >0.356252</td>\n",
       "      <td id=\"T_13359_row8_col2\" class=\"data row8 col2\" >0.749444</td>\n",
       "      <td id=\"T_13359_row8_col3\" class=\"data row8 col3\" >0.758945</td>\n",
       "      <td id=\"T_13359_row8_col4\" class=\"data row8 col4\" >0.611430</td>\n",
       "      <td id=\"T_13359_row8_col5\" class=\"data row8 col5\" >0.676966</td>\n",
       "      <td id=\"T_13359_row8_col6\" class=\"data row8 col6\" >0.260900</td>\n",
       "      <td id=\"T_13359_row8_col7\" class=\"data row8 col7\" >0.544706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row9\" class=\"row_heading level0 row9\" >hkunlp__instructor-base</th>\n",
       "      <td id=\"T_13359_row9_col0\" class=\"data row9 col0\" >0.060527</td>\n",
       "      <td id=\"T_13359_row9_col1\" class=\"data row9 col1\" >0.048069</td>\n",
       "      <td id=\"T_13359_row9_col2\" class=\"data row9 col2\" >0.724202</td>\n",
       "      <td id=\"T_13359_row9_col3\" class=\"data row9 col3\" >0.725136</td>\n",
       "      <td id=\"T_13359_row9_col4\" class=\"data row9 col4\" >0.510993</td>\n",
       "      <td id=\"T_13359_row9_col5\" class=\"data row9 col5\" >0.644316</td>\n",
       "      <td id=\"T_13359_row9_col6\" class=\"data row9 col6\" >0.106088</td>\n",
       "      <td id=\"T_13359_row9_col7\" class=\"data row9 col7\" >0.402761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row10\" class=\"row_heading level0 row10\" >hkunlp__instructor-large</th>\n",
       "      <td id=\"T_13359_row10_col0\" class=\"data row10 col0\" >0.113473</td>\n",
       "      <td id=\"T_13359_row10_col1\" class=\"data row10 col1\" >0.100835</td>\n",
       "      <td id=\"T_13359_row10_col2\" class=\"data row10 col2\" >0.716626</td>\n",
       "      <td id=\"T_13359_row10_col3\" class=\"data row10 col3\" >0.695481</td>\n",
       "      <td id=\"T_13359_row10_col4\" class=\"data row10 col4\" >0.514290</td>\n",
       "      <td id=\"T_13359_row10_col5\" class=\"data row10 col5\" >0.657472</td>\n",
       "      <td id=\"T_13359_row10_col6\" class=\"data row10 col6\" >0.178694</td>\n",
       "      <td id=\"T_13359_row10_col7\" class=\"data row10 col7\" >0.425267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row11\" class=\"row_heading level0 row11\" >hkunlp__instructor-xl</th>\n",
       "      <td id=\"T_13359_row11_col0\" class=\"data row11 col0\" >0.125475</td>\n",
       "      <td id=\"T_13359_row11_col1\" class=\"data row11 col1\" >0.105762</td>\n",
       "      <td id=\"T_13359_row11_col2\" class=\"data row11 col2\" >0.731667</td>\n",
       "      <td id=\"T_13359_row11_col3\" class=\"data row11 col3\" >0.735299</td>\n",
       "      <td id=\"T_13359_row11_col4\" class=\"data row11 col4\" >0.523764</td>\n",
       "      <td id=\"T_13359_row11_col5\" class=\"data row11 col5\" >0.664654</td>\n",
       "      <td id=\"T_13359_row11_col6\" class=\"data row11 col6\" >0.206893</td>\n",
       "      <td id=\"T_13359_row11_col7\" class=\"data row11 col7\" >0.441931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row12\" class=\"row_heading level0 row12\" >samaya-ai__promptriever-llama2-7b-v1</th>\n",
       "      <td id=\"T_13359_row12_col0\" class=\"data row12 col0\" >0.316609</td>\n",
       "      <td id=\"T_13359_row12_col1\" class=\"data row12 col1\" >0.279289</td>\n",
       "      <td id=\"T_13359_row12_col2\" class=\"data row12 col2\" >0.787691</td>\n",
       "      <td id=\"T_13359_row12_col3\" class=\"data row12 col3\" >0.791726</td>\n",
       "      <td id=\"T_13359_row12_col4\" class=\"data row12 col4\" >0.628100</td>\n",
       "      <td id=\"T_13359_row12_col5\" class=\"data row12 col5\" >0.712918</td>\n",
       "      <td id=\"T_13359_row12_col6\" class=\"data row12 col6\" >0.339710</td>\n",
       "      <td id=\"T_13359_row12_col7\" class=\"data row12 col7\" >0.550863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row13\" class=\"row_heading level0 row13\" >samaya-ai__promptriever-llama3.1-8b-v1</th>\n",
       "      <td id=\"T_13359_row13_col0\" class=\"data row13 col0\" >0.460880</td>\n",
       "      <td id=\"T_13359_row13_col1\" class=\"data row13 col1\" >0.411037</td>\n",
       "      <td id=\"T_13359_row13_col2\" class=\"data row13 col2\" >0.785547</td>\n",
       "      <td id=\"T_13359_row13_col3\" class=\"data row13 col3\" >0.779651</td>\n",
       "      <td id=\"T_13359_row13_col4\" class=\"data row13 col4\" >0.657115</td>\n",
       "      <td id=\"T_13359_row13_col5\" class=\"data row13 col5\" >0.710508</td>\n",
       "      <td id=\"T_13359_row13_col6\" class=\"data row13 col6\" >0.372257</td>\n",
       "      <td id=\"T_13359_row13_col7\" class=\"data row13 col7\" >0.596714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row14\" class=\"row_heading level0 row14\" >samaya-ai__promptriever-llama3.1-8b-instruct-v1</th>\n",
       "      <td id=\"T_13359_row14_col0\" class=\"data row14 col0\" >0.507303</td>\n",
       "      <td id=\"T_13359_row14_col1\" class=\"data row14 col1\" >0.456657</td>\n",
       "      <td id=\"T_13359_row14_col2\" class=\"data row14 col2\" >0.787422</td>\n",
       "      <td id=\"T_13359_row14_col3\" class=\"data row14 col3\" >0.786928</td>\n",
       "      <td id=\"T_13359_row14_col4\" class=\"data row14 col4\" >0.664120</td>\n",
       "      <td id=\"T_13359_row14_col5\" class=\"data row14 col5\" >0.714959</td>\n",
       "      <td id=\"T_13359_row14_col6\" class=\"data row14 col6\" >0.425634</td>\n",
       "      <td id=\"T_13359_row14_col7\" class=\"data row14 col7\" >0.620432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row15\" class=\"row_heading level0 row15\" >samaya-ai__promptriever-mistral-v0.1-7b-v1</th>\n",
       "      <td id=\"T_13359_row15_col0\" class=\"data row15 col0\" >0.400143</td>\n",
       "      <td id=\"T_13359_row15_col1\" class=\"data row15 col1\" >0.357807</td>\n",
       "      <td id=\"T_13359_row15_col2\" class=\"data row15 col2\" >0.782709</td>\n",
       "      <td id=\"T_13359_row15_col3\" class=\"data row15 col3\" >0.793293</td>\n",
       "      <td id=\"T_13359_row15_col4\" class=\"data row15 col4\" >0.628359</td>\n",
       "      <td id=\"T_13359_row15_col5\" class=\"data row15 col5\" >0.699451</td>\n",
       "      <td id=\"T_13359_row15_col6\" class=\"data row15 col6\" >0.346700</td>\n",
       "      <td id=\"T_13359_row15_col7\" class=\"data row15 col7\" >0.572637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row16\" class=\"row_heading level0 row16\" >openai__text-embedding-ada-002</th>\n",
       "      <td id=\"T_13359_row16_col0\" class=\"data row16 col0\" >0.400541</td>\n",
       "      <td id=\"T_13359_row16_col1\" class=\"data row16 col1\" >0.351515</td>\n",
       "      <td id=\"T_13359_row16_col2\" class=\"data row16 col2\" >0.766112</td>\n",
       "      <td id=\"T_13359_row16_col3\" class=\"data row16 col3\" >0.763659</td>\n",
       "      <td id=\"T_13359_row16_col4\" class=\"data row16 col4\" >0.535909</td>\n",
       "      <td id=\"T_13359_row16_col5\" class=\"data row16 col5\" >0.692835</td>\n",
       "      <td id=\"T_13359_row16_col6\" class=\"data row16 col6\" >0.298001</td>\n",
       "      <td id=\"T_13359_row16_col7\" class=\"data row16 col7\" >0.544082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row17\" class=\"row_heading level0 row17\" >openai__text-embedding-3-small</th>\n",
       "      <td id=\"T_13359_row17_col0\" class=\"data row17 col0\" >0.220927</td>\n",
       "      <td id=\"T_13359_row17_col1\" class=\"data row17 col1\" >0.188745</td>\n",
       "      <td id=\"T_13359_row17_col2\" class=\"data row17 col2\" >0.758057</td>\n",
       "      <td id=\"T_13359_row17_col3\" class=\"data row17 col3\" >0.752629</td>\n",
       "      <td id=\"T_13359_row17_col4\" class=\"data row17 col4\" >0.577271</td>\n",
       "      <td id=\"T_13359_row17_col5\" class=\"data row17 col5\" >0.689330</td>\n",
       "      <td id=\"T_13359_row17_col6\" class=\"data row17 col6\" >0.253128</td>\n",
       "      <td id=\"T_13359_row17_col7\" class=\"data row17 col7\" >0.491441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row18\" class=\"row_heading level0 row18\" >openai__text-embedding-3-large</th>\n",
       "      <td id=\"T_13359_row18_col0\" class=\"data row18 col0\" >0.354968</td>\n",
       "      <td id=\"T_13359_row18_col1\" class=\"data row18 col1\" >0.297847</td>\n",
       "      <td id=\"T_13359_row18_col2\" class=\"data row18 col2\" >0.769917</td>\n",
       "      <td id=\"T_13359_row18_col3\" class=\"data row18 col3\" >0.761120</td>\n",
       "      <td id=\"T_13359_row18_col4\" class=\"data row18 col4\" >0.608402</td>\n",
       "      <td id=\"T_13359_row18_col5\" class=\"data row18 col5\" >0.698377</td>\n",
       "      <td id=\"T_13359_row18_col6\" class=\"data row18 col6\" >0.327678</td>\n",
       "      <td id=\"T_13359_row18_col7\" class=\"data row18 col7\" >0.545473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row19\" class=\"row_heading level0 row19\" >voyageai__voyage-code-2</th>\n",
       "      <td id=\"T_13359_row19_col0\" class=\"data row19 col0\" >0.698938</td>\n",
       "      <td id=\"T_13359_row19_col1\" class=\"data row19 col1\" >0.644876</td>\n",
       "      <td id=\"T_13359_row19_col2\" class=\"data row19 col2\" >0.795675</td>\n",
       "      <td id=\"T_13359_row19_col3\" class=\"data row19 col3\" >0.769857</td>\n",
       "      <td id=\"T_13359_row19_col4\" class=\"data row19 col4\" >0.638053</td>\n",
       "      <td id=\"T_13359_row19_col5\" class=\"data row19 col5\" >0.703243</td>\n",
       "      <td id=\"T_13359_row19_col6\" class=\"data row19 col6\" >0.374077</td>\n",
       "      <td id=\"T_13359_row19_col7\" class=\"data row19 col7\" >0.660674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row20\" class=\"row_heading level0 row20\" >voyageai__voyage-code-3</th>\n",
       "      <td id=\"T_13359_row20_col0\" class=\"data row20 col0\" >0.756121</td>\n",
       "      <td id=\"T_13359_row20_col1\" class=\"data row20 col1\" >0.681901</td>\n",
       "      <td id=\"T_13359_row20_col2\" class=\"data row20 col2\" >0.810517</td>\n",
       "      <td id=\"T_13359_row20_col3\" class=\"data row20 col3\" >0.790995</td>\n",
       "      <td id=\"T_13359_row20_col4\" class=\"data row20 col4\" >0.667322</td>\n",
       "      <td id=\"T_13359_row20_col5\" class=\"data row20 col5\" >0.766181</td>\n",
       "      <td id=\"T_13359_row20_col6\" class=\"data row20 col6\" >0.438268</td>\n",
       "      <td id=\"T_13359_row20_col7\" class=\"data row20 col7\" >0.701615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row21\" class=\"row_heading level0 row21\" >microsoft__codebert-base</th>\n",
       "      <td id=\"T_13359_row21_col0\" class=\"data row21 col0\" >0.005005</td>\n",
       "      <td id=\"T_13359_row21_col1\" class=\"data row21 col1\" >0.002050</td>\n",
       "      <td id=\"T_13359_row21_col2\" class=\"data row21 col2\" >0.007177</td>\n",
       "      <td id=\"T_13359_row21_col3\" class=\"data row21 col3\" >0.006936</td>\n",
       "      <td id=\"T_13359_row21_col4\" class=\"data row21 col4\" >0.004009</td>\n",
       "      <td id=\"T_13359_row21_col5\" class=\"data row21 col5\" >0.031745</td>\n",
       "      <td id=\"T_13359_row21_col6\" class=\"data row21 col6\" >0.001170</td>\n",
       "      <td id=\"T_13359_row21_col7\" class=\"data row21 col7\" >0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row22\" class=\"row_heading level0 row22\" >microsoft__graphcodebert-base</th>\n",
       "      <td id=\"T_13359_row22_col0\" class=\"data row22 col0\" >0.008887</td>\n",
       "      <td id=\"T_13359_row22_col1\" class=\"data row22 col1\" >0.005196</td>\n",
       "      <td id=\"T_13359_row22_col2\" class=\"data row22 col2\" >0.061737</td>\n",
       "      <td id=\"T_13359_row22_col3\" class=\"data row22 col3\" >0.041384</td>\n",
       "      <td id=\"T_13359_row22_col4\" class=\"data row22 col4\" >0.016520</td>\n",
       "      <td id=\"T_13359_row22_col5\" class=\"data row22 col5\" >0.116688</td>\n",
       "      <td id=\"T_13359_row22_col6\" class=\"data row22 col6\" >0.002408</td>\n",
       "      <td id=\"T_13359_row22_col7\" class=\"data row22 col7\" >0.036117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row23\" class=\"row_heading level0 row23\" >nomic-ai__CodeRankEmbed</th>\n",
       "      <td id=\"T_13359_row23_col0\" class=\"data row23 col0\" >0.084676</td>\n",
       "      <td id=\"T_13359_row23_col1\" class=\"data row23 col1\" >0.060071</td>\n",
       "      <td id=\"T_13359_row23_col2\" class=\"data row23 col2\" >0.746516</td>\n",
       "      <td id=\"T_13359_row23_col3\" class=\"data row23 col3\" >0.753309</td>\n",
       "      <td id=\"T_13359_row23_col4\" class=\"data row23 col4\" >0.631144</td>\n",
       "      <td id=\"T_13359_row23_col5\" class=\"data row23 col5\" >0.624235</td>\n",
       "      <td id=\"T_13359_row23_col6\" class=\"data row23 col6\" >0.339418</td>\n",
       "      <td id=\"T_13359_row23_col7\" class=\"data row23 col7\" >0.462767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row24\" class=\"row_heading level0 row24\" >local-repllama-llama31-8b-lora-64</th>\n",
       "      <td id=\"T_13359_row24_col0\" class=\"data row24 col0\" >0.430421</td>\n",
       "      <td id=\"T_13359_row24_col1\" class=\"data row24 col1\" >0.391655</td>\n",
       "      <td id=\"T_13359_row24_col2\" class=\"data row24 col2\" >0.774880</td>\n",
       "      <td id=\"T_13359_row24_col3\" class=\"data row24 col3\" >0.762925</td>\n",
       "      <td id=\"T_13359_row24_col4\" class=\"data row24 col4\" >0.638170</td>\n",
       "      <td id=\"T_13359_row24_col5\" class=\"data row24 col5\" >0.704639</td>\n",
       "      <td id=\"T_13359_row24_col6\" class=\"data row24 col6\" >0.371119</td>\n",
       "      <td id=\"T_13359_row24_col7\" class=\"data row24 col7\" >0.581973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row25\" class=\"row_heading level0 row25\" >local-repllama-llama31-8b-lora-64-quality</th>\n",
       "      <td id=\"T_13359_row25_col0\" class=\"data row25 col0\" >0.427950</td>\n",
       "      <td id=\"T_13359_row25_col1\" class=\"data row25 col1\" >0.411446</td>\n",
       "      <td id=\"T_13359_row25_col2\" class=\"data row25 col2\" >0.725706</td>\n",
       "      <td id=\"T_13359_row25_col3\" class=\"data row25 col3\" >0.684150</td>\n",
       "      <td id=\"T_13359_row25_col4\" class=\"data row25 col4\" >0.595487</td>\n",
       "      <td id=\"T_13359_row25_col5\" class=\"data row25 col5\" >0.735038</td>\n",
       "      <td id=\"T_13359_row25_col6\" class=\"data row25 col6\" >0.284541</td>\n",
       "      <td id=\"T_13359_row25_col7\" class=\"data row25 col7\" >0.552046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row26\" class=\"row_heading level0 row26\" >local-repllama-llama32-3b-lora-256</th>\n",
       "      <td id=\"T_13359_row26_col0\" class=\"data row26 col0\" >0.333979</td>\n",
       "      <td id=\"T_13359_row26_col1\" class=\"data row26 col1\" >0.276105</td>\n",
       "      <td id=\"T_13359_row26_col2\" class=\"data row26 col2\" >0.770716</td>\n",
       "      <td id=\"T_13359_row26_col3\" class=\"data row26 col3\" >0.753618</td>\n",
       "      <td id=\"T_13359_row26_col4\" class=\"data row26 col4\" >0.631558</td>\n",
       "      <td id=\"T_13359_row26_col5\" class=\"data row26 col5\" >0.681836</td>\n",
       "      <td id=\"T_13359_row26_col6\" class=\"data row26 col6\" >0.364803</td>\n",
       "      <td id=\"T_13359_row26_col7\" class=\"data row26 col7\" >0.544659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row27\" class=\"row_heading level0 row27\" >local-repllama-llama32-3b-lora-256-quality</th>\n",
       "      <td id=\"T_13359_row27_col0\" class=\"data row27 col0\" >0.318275</td>\n",
       "      <td id=\"T_13359_row27_col1\" class=\"data row27 col1\" >0.291169</td>\n",
       "      <td id=\"T_13359_row27_col2\" class=\"data row27 col2\" >0.708312</td>\n",
       "      <td id=\"T_13359_row27_col3\" class=\"data row27 col3\" >0.670882</td>\n",
       "      <td id=\"T_13359_row27_col4\" class=\"data row27 col4\" >0.520784</td>\n",
       "      <td id=\"T_13359_row27_col5\" class=\"data row27 col5\" >0.715456</td>\n",
       "      <td id=\"T_13359_row27_col6\" class=\"data row27 col6\" >0.239468</td>\n",
       "      <td id=\"T_13359_row27_col7\" class=\"data row27 col7\" >0.494907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row28\" class=\"row_heading level0 row28\" >codesage__codesage-small</th>\n",
       "      <td id=\"T_13359_row28_col0\" class=\"data row28 col0\" >0.203189</td>\n",
       "      <td id=\"T_13359_row28_col1\" class=\"data row28 col1\" >0.167226</td>\n",
       "      <td id=\"T_13359_row28_col2\" class=\"data row28 col2\" >0.749343</td>\n",
       "      <td id=\"T_13359_row28_col3\" class=\"data row28 col3\" >0.734547</td>\n",
       "      <td id=\"T_13359_row28_col4\" class=\"data row28 col4\" >0.612058</td>\n",
       "      <td id=\"T_13359_row28_col5\" class=\"data row28 col5\" >0.694410</td>\n",
       "      <td id=\"T_13359_row28_col6\" class=\"data row28 col6\" >0.069544</td>\n",
       "      <td id=\"T_13359_row28_col7\" class=\"data row28 col7\" >0.461474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13359_level0_row29\" class=\"row_heading level0 row29\" >codesage__codesage-base</th>\n",
       "      <td id=\"T_13359_row29_col0\" class=\"data row29 col0\" >0.265841</td>\n",
       "      <td id=\"T_13359_row29_col1\" class=\"data row29 col1\" >0.225786</td>\n",
       "      <td id=\"T_13359_row29_col2\" class=\"data row29 col2\" >0.747903</td>\n",
       "      <td id=\"T_13359_row29_col3\" class=\"data row29 col3\" >0.759231</td>\n",
       "      <td id=\"T_13359_row29_col4\" class=\"data row29 col4\" >0.615877</td>\n",
       "      <td id=\"T_13359_row29_col5\" class=\"data row29 col5\" >0.688971</td>\n",
       "      <td id=\"T_13359_row29_col6\" class=\"data row29 col6\" >0.129260</td>\n",
       "      <td id=\"T_13359_row29_col7\" class=\"data row29 col7\" >0.490410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa1a14f5cd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_results(RESULT_DIR, models, tasks, 'mrr_at_10')\n",
    "df = pd.DataFrame.from_dict(data, orient='index').style.apply(highlight_max_in_column, axis=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148fc36-7b10-4d44-b372-25767a5eb967",
   "metadata": {},
   "source": [
    "## 2. Preference-guided Code Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8b547-a66b-4a67-a2a6-9cc103afb6d0",
   "metadata": {},
   "source": [
    "#### Load golden labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59313b1e-0061-4c51-b144-22540a9d38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # skip empty lines\n",
    "                data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58aa0776-8c9e-49b1-b901-c136ffbb3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the map between tasks an subtasks\n",
    "task_sub_task_mapping = {\n",
    "    \"CodeNetBugPreferenceRetrieval\": [\"c\",\"cpp\", \"go\", \"java\", \"javascript\", \"python\", \"ruby\", \"rust\", \"swift\", \"typescript\"],\n",
    "    \"CodeNetEfficiencyPreferenceRetrieval\": [\"c\",\"cpp\", \"go\", \"java\", \"javascript\", \"python\", \"ruby\", \"rust\", \"swift\", \"typescript\"],\n",
    "    \"CVEFixesPreferenceRetrieval\": ['c', 'go', 'java', 'python', 'ruby'],\n",
    "    \"Defects4JPreferenceRetrieval\": [None],\n",
    "    \"DeprecatedCodePreferenceRetrieval\": ['numpy', 'pandas', 'pytorch', 'scipy', 'seaborn', 'sklearn', 'tensorflow', 'transformers'],\n",
    "    \"SaferCodePreferenceRetrieval\": [\"c\", \"cpp\", \"python\", \"java\", \"javascript\", \"go\", \"ruby\"],\n",
    "    \"SQLR2PreferenceRetrieval\": [None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03f24d01-d70e-4d7d-b76d-f23f086deef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the golden qrels\n",
    "datadir_mapping = {\n",
    "    \"CodeNetBugPreferenceRetrieval\": \"codenet_bug\",\n",
    "    \"CodeNetEfficiencyPreferenceRetrieval\": \"codenet_effi\",\n",
    "    \"CVEFixesPreferenceRetrieval\": \"CVEFixes\",\n",
    "    \"Defects4JPreferenceRetrieval\": \"Defects4J\",\n",
    "    \"DeprecatedCodePreferenceRetrieval\": \"DeprecatedCode\",\n",
    "    \"SaferCodePreferenceRetrieval\": \"SafeCoder\",\n",
    "    'SQLR2PreferenceRetrieval': \"sqlr2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d127b911-51b4-408f-90f8-080bc09a4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang(_doc_str):\n",
    "    return _doc_str.split(\"-\")[1]\n",
    "\n",
    "def get_lang_codenet(_doc_str):\n",
    "    return _doc_str.split(\"-\")[-2].lower()\n",
    "\n",
    "def load_qrels(task, lang):\n",
    "    if task=='DeprecatedCodePreferenceRetrieval':\n",
    "        qrels_path = os.path.join(DATASET_DIR, datadir_mapping[task], f'qrels-{lang}.jsonl')\n",
    "    else:\n",
    "        qrels_path = os.path.join(DATASET_DIR, datadir_mapping[task], 'qrels.jsonl')\n",
    "\n",
    "    lines = load_jsonl(qrels_path)\n",
    "\n",
    "    # filtering only for CVEFixesPreferenceRetrieval\n",
    "    if task == 'CVEFixesPreferenceRetrieval' or task == 'SaferCodePreferenceRetrieval':\n",
    "        tmp_lines = []\n",
    "        for _line in lines:\n",
    "            filtered_pos_docids = [_id for _id in _line['pos-docids'] if get_lang(_id) == lang]\n",
    "            filtered_neg_docids = [_id for _id in _line['neg-docids'] if get_lang(_id) == lang]\n",
    "            _line['pos-docids'] = filtered_pos_docids\n",
    "            _line['neg-docids'] = filtered_neg_docids\n",
    "            if len(filtered_neg_docids) != 0 and len(filtered_neg_docids) != 0:\n",
    "                tmp_lines.append(_line)\n",
    "\n",
    "        lines = tmp_lines\n",
    "\n",
    "    if task.startswith(\"CodeNet\"):\n",
    "        tmp_lines = []\n",
    "        for _line in lines:\n",
    "            filtered_pos_docids = [_id for _id in _line['pos-docids'] if get_lang_codenet(_id) == lang]\n",
    "            filtered_neg_docids = [_id for _id in _line['neg-docids'] if get_lang_codenet(_id) == lang]\n",
    "            _line['pos-docids'] = filtered_pos_docids\n",
    "            _line['neg-docids'] = filtered_neg_docids\n",
    "            if len(filtered_neg_docids) != 0 and len(filtered_neg_docids) != 0:\n",
    "                tmp_lines.append(_line)\n",
    "\n",
    "        lines = tmp_lines\n",
    "\n",
    "    qrels_dict = {_line['qid']: _line for _line in lines}\n",
    "    return qrels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc12c0-0631-4ac1-b57a-434a366ba314",
   "metadata": {},
   "source": [
    "#### Obtain the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e31a07e8-6f31-4110-a495-ad5e0d8352fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(model, task, subtask):\n",
    "    prediction_file = f'{task}_{subtask}_predictions.json' if subtask is not None else f'{task}_default_predictions.json'\n",
    "    prediction_path = os.path.join(result_dir, model, prediction_file)\n",
    "\n",
    "    with open(prediction_path, 'r') as f:\n",
    "        json_dict = json.loads(f.read())\n",
    "\n",
    "    json_sorted_dict = {}\n",
    "    for _k, _v in json_dict.items():\n",
    "        sorted_doc_values = sorted([(_docid, _score) for _docid, _score in _v.items()], key=lambda x: x[1], reverse=True)\n",
    "        json_sorted_dict[_k] = [_item[0] for _item in sorted_doc_values]\n",
    "\n",
    "    return json_sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de9bdd-1b7f-4f2b-81b2-09f72ca7871d",
   "metadata": {},
   "source": [
    "## Metrics for Quality-aware Code Information Retrieval\n",
    "\n",
    "Assume for each query, we have:\n",
    "- A set of positive samples: $\\mathcal{P} = \\{p_1, p_2, \\dots, p_m\\}$\n",
    "- A set of negative samples: $\\mathcal{N} = \\{n_1, n_2, \\dots, n_n\\}$\n",
    "- Each sample has a model score: $s(x)$\n",
    "- Total number of candidates: $C = |\\mathcal{P}| + |\\mathcal{N}|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe87a91-c71b-4c1a-a938-74debbb1ce2a",
   "metadata": {},
   "source": [
    "### 2.1: Pairwise Preference Accuracy (PPA)\n",
    "\n",
    "Measures the proportion of positive-negative pairs where the positive is scored higher:\n",
    "\n",
    "$$\n",
    "\\text{PPA} = \\frac{1}{|\\mathcal{P}| \\cdot |\\mathcal{N}|} \\sum_{p \\in \\mathcal{P}} \\sum_{n \\in \\mathcal{N}} \\mathbb{1}(s(p) > s(n))\n",
    "$$\n",
    "\n",
    "- **Upper bound (best case)**: $\\text{PPA} = 1$, meaning all positives are scored above all negatives.\n",
    "- **Lower bound (worst case)**: $\\text{PPA} = 0$, meaning all negatives are scored above all positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c317efc-84ee-4f96-9fba-1e61307e7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ppa(_qrels_dict, _predictions):\n",
    "    overall_ppa = []\n",
    "    for _qrels_key in list(_qrels_dict.keys()):\n",
    "        pos_docids = _qrels_dict[_qrels_key]['pos-docids']\n",
    "        neg_docids = _qrels_dict[_qrels_key]['neg-docids']\n",
    "\n",
    "        query_ppa = []\n",
    "        for _pos_docid in pos_docids:\n",
    "            _pos_docid_rank = _predictions[_qrels_key].index(_pos_docid) if _pos_docid in _predictions[_qrels_key] else len(_predictions[_qrels_key])\n",
    "            for _neg_docid in neg_docids:\n",
    "                _neg_docid_rank = _predictions[_qrels_key].index(_neg_docid) if _neg_docid in _predictions[_qrels_key] else len(_predictions[_qrels_key])\n",
    "                if _pos_docid_rank < _neg_docid_rank:\n",
    "                    query_ppa.append(1)\n",
    "                else:\n",
    "                    query_ppa.append(0)\n",
    "        overall_ppa.append(np.mean(query_ppa))\n",
    "\n",
    "    assert len(overall_ppa) > 0\n",
    "    return np.mean(overall_ppa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1706b43c-1113-40d5-8683-ab4efb2bad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [30:34<00:00, 61.14s/it]\n"
     ]
    }
   ],
   "source": [
    "ppa_dict = defaultdict(dict)\n",
    "\n",
    "for _model in tqdm(models):\n",
    "    for _task in tasks:\n",
    "        ppa_values = []\n",
    "        for _subtask in task_sub_task_mapping[_task]:\n",
    "            _qrels_dict = load_qrels(_task, _subtask)\n",
    "            _predictions = load_predictions(_model, _task, _subtask)\n",
    "            _ppa_value = compute_ppa(_qrels_dict, _predictions)\n",
    "            ppa_values.append(_ppa_value)\n",
    "            ppa_dict[_model][_task + '-' + _subtask if _subtask is not None else _task] = _ppa_value\n",
    "        \n",
    "        # Compute mean PPA over subtasks\n",
    "        if _task not in ppa_dict[_model]:\n",
    "            mean_ppa = sum(ppa_values) / len(ppa_values) if ppa_values else None\n",
    "            ppa_dict[_model][_task] = mean_ppa\n",
    "\n",
    "df = pd.DataFrame.from_dict(ppa_dict, orient='index').style.apply(highlight_max_in_column, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ded750c-64cc-42cc-bf14-fb6cf2b46cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodeNetBugPreferenceRetrieval</th>\n",
       "      <th>CodeNetEfficiencyPreferenceRetrieval</th>\n",
       "      <th>CVEFixesPreferenceRetrieval</th>\n",
       "      <th>Defects4JPreferenceRetrieval</th>\n",
       "      <th>DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th>SaferCodePreferenceRetrieval</th>\n",
       "      <th>SQLR2PreferenceRetrieval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bm25s</th>\n",
       "      <td>0.460592</td>\n",
       "      <td>0.371700</td>\n",
       "      <td>0.648998</td>\n",
       "      <td>0.567452</td>\n",
       "      <td>0.177335</td>\n",
       "      <td>0.505294</td>\n",
       "      <td>0.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook__contriever</th>\n",
       "      <td>0.408573</td>\n",
       "      <td>0.385453</td>\n",
       "      <td>0.531247</td>\n",
       "      <td>0.468951</td>\n",
       "      <td>0.473865</td>\n",
       "      <td>0.410161</td>\n",
       "      <td>0.593825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-base-en-v1.5</th>\n",
       "      <td>0.442425</td>\n",
       "      <td>0.386383</td>\n",
       "      <td>0.553256</td>\n",
       "      <td>0.595289</td>\n",
       "      <td>0.506067</td>\n",
       "      <td>0.477051</td>\n",
       "      <td>0.603781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-base</th>\n",
       "      <td>0.407176</td>\n",
       "      <td>0.339693</td>\n",
       "      <td>0.572111</td>\n",
       "      <td>0.571734</td>\n",
       "      <td>0.474838</td>\n",
       "      <td>0.496209</td>\n",
       "      <td>0.649839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-large</th>\n",
       "      <td>0.455356</td>\n",
       "      <td>0.391341</td>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.576017</td>\n",
       "      <td>0.467169</td>\n",
       "      <td>0.488318</td>\n",
       "      <td>0.681315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-base-v2</th>\n",
       "      <td>0.476349</td>\n",
       "      <td>0.432534</td>\n",
       "      <td>0.605025</td>\n",
       "      <td>0.591006</td>\n",
       "      <td>0.479891</td>\n",
       "      <td>0.527586</td>\n",
       "      <td>0.695093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-large-v2</th>\n",
       "      <td>0.462021</td>\n",
       "      <td>0.467265</td>\n",
       "      <td>0.610142</td>\n",
       "      <td>0.620985</td>\n",
       "      <td>0.467820</td>\n",
       "      <td>0.516071</td>\n",
       "      <td>0.730491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-Qwen2-1.5B-instruct</th>\n",
       "      <td>0.443527</td>\n",
       "      <td>0.441737</td>\n",
       "      <td>0.647909</td>\n",
       "      <td>0.603854</td>\n",
       "      <td>0.468762</td>\n",
       "      <td>0.516740</td>\n",
       "      <td>0.711484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-mistral-7b-instruct</th>\n",
       "      <td>0.492720</td>\n",
       "      <td>0.482654</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.644540</td>\n",
       "      <td>0.524875</td>\n",
       "      <td>0.503371</td>\n",
       "      <td>0.735318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base</th>\n",
       "      <td>0.422701</td>\n",
       "      <td>0.394064</td>\n",
       "      <td>0.607700</td>\n",
       "      <td>0.608137</td>\n",
       "      <td>0.490619</td>\n",
       "      <td>0.495242</td>\n",
       "      <td>0.713998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large</th>\n",
       "      <td>0.432950</td>\n",
       "      <td>0.426712</td>\n",
       "      <td>0.576440</td>\n",
       "      <td>0.543897</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.495357</td>\n",
       "      <td>0.701227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl</th>\n",
       "      <td>0.445227</td>\n",
       "      <td>0.424331</td>\n",
       "      <td>0.590283</td>\n",
       "      <td>0.608137</td>\n",
       "      <td>0.475088</td>\n",
       "      <td>0.475076</td>\n",
       "      <td>0.731798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1</th>\n",
       "      <td>0.475894</td>\n",
       "      <td>0.461753</td>\n",
       "      <td>0.653528</td>\n",
       "      <td>0.693790</td>\n",
       "      <td>0.518630</td>\n",
       "      <td>0.536916</td>\n",
       "      <td>0.819690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1</th>\n",
       "      <td>0.480779</td>\n",
       "      <td>0.468667</td>\n",
       "      <td>0.643632</td>\n",
       "      <td>0.676660</td>\n",
       "      <td>0.553417</td>\n",
       "      <td>0.519658</td>\n",
       "      <td>0.795253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1</th>\n",
       "      <td>0.509411</td>\n",
       "      <td>0.490770</td>\n",
       "      <td>0.637491</td>\n",
       "      <td>0.674518</td>\n",
       "      <td>0.545447</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.826529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1</th>\n",
       "      <td>0.467305</td>\n",
       "      <td>0.467178</td>\n",
       "      <td>0.635628</td>\n",
       "      <td>0.685225</td>\n",
       "      <td>0.512973</td>\n",
       "      <td>0.507586</td>\n",
       "      <td>0.813355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-ada-002</th>\n",
       "      <td>0.503193</td>\n",
       "      <td>0.482328</td>\n",
       "      <td>0.622463</td>\n",
       "      <td>0.642398</td>\n",
       "      <td>0.511178</td>\n",
       "      <td>0.490298</td>\n",
       "      <td>0.755531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-small</th>\n",
       "      <td>0.478576</td>\n",
       "      <td>0.475005</td>\n",
       "      <td>0.607506</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.520049</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.715607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-large</th>\n",
       "      <td>0.522286</td>\n",
       "      <td>0.477876</td>\n",
       "      <td>0.625901</td>\n",
       "      <td>0.644540</td>\n",
       "      <td>0.533620</td>\n",
       "      <td>0.504370</td>\n",
       "      <td>0.739541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-2</th>\n",
       "      <td>0.555524</td>\n",
       "      <td>0.510665</td>\n",
       "      <td>0.665572</td>\n",
       "      <td>0.659529</td>\n",
       "      <td>0.494402</td>\n",
       "      <td>0.519476</td>\n",
       "      <td>0.723753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-3</th>\n",
       "      <td>0.595961</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.682124</td>\n",
       "      <td>0.695931</td>\n",
       "      <td>0.573364</td>\n",
       "      <td>0.604895</td>\n",
       "      <td>0.688455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__codebert-base</th>\n",
       "      <td>0.343351</td>\n",
       "      <td>0.210807</td>\n",
       "      <td>0.385367</td>\n",
       "      <td>0.451820</td>\n",
       "      <td>0.191906</td>\n",
       "      <td>0.524768</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__graphcodebert-base</th>\n",
       "      <td>0.393534</td>\n",
       "      <td>0.262829</td>\n",
       "      <td>0.466357</td>\n",
       "      <td>0.524625</td>\n",
       "      <td>0.282865</td>\n",
       "      <td>0.546306</td>\n",
       "      <td>0.259151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai__CodeRankEmbed</th>\n",
       "      <td>0.458748</td>\n",
       "      <td>0.425701</td>\n",
       "      <td>0.618693</td>\n",
       "      <td>0.653105</td>\n",
       "      <td>0.524456</td>\n",
       "      <td>0.419545</td>\n",
       "      <td>0.775442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64</th>\n",
       "      <td>0.485688</td>\n",
       "      <td>0.478696</td>\n",
       "      <td>0.631742</td>\n",
       "      <td>0.655246</td>\n",
       "      <td>0.541780</td>\n",
       "      <td>0.511162</td>\n",
       "      <td>0.798069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64-quality</th>\n",
       "      <td>0.679526</td>\n",
       "      <td>0.716330</td>\n",
       "      <td>0.636850</td>\n",
       "      <td>0.571734</td>\n",
       "      <td>0.720812</td>\n",
       "      <td>0.730671</td>\n",
       "      <td>0.742056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256</th>\n",
       "      <td>0.427969</td>\n",
       "      <td>0.396668</td>\n",
       "      <td>0.632434</td>\n",
       "      <td>0.648822</td>\n",
       "      <td>0.553844</td>\n",
       "      <td>0.496307</td>\n",
       "      <td>0.805209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256-quality</th>\n",
       "      <td>0.674569</td>\n",
       "      <td>0.701375</td>\n",
       "      <td>0.623522</td>\n",
       "      <td>0.584582</td>\n",
       "      <td>0.664861</td>\n",
       "      <td>0.722034</td>\n",
       "      <td>0.704043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-small</th>\n",
       "      <td>0.479749</td>\n",
       "      <td>0.442748</td>\n",
       "      <td>0.586093</td>\n",
       "      <td>0.608137</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.525892</td>\n",
       "      <td>0.597647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-base</th>\n",
       "      <td>0.500223</td>\n",
       "      <td>0.464432</td>\n",
       "      <td>0.578671</td>\n",
       "      <td>0.646681</td>\n",
       "      <td>0.507169</td>\n",
       "      <td>0.501625</td>\n",
       "      <td>0.607401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CodeNetBugPreferenceRetrieval  \\\n",
       "bm25s                                                                 0.460592   \n",
       "facebook__contriever                                                  0.408573   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                         0.442425   \n",
       "sentence-transformers__gtr-t5-base                                    0.407176   \n",
       "sentence-transformers__gtr-t5-large                                   0.455356   \n",
       "intfloat__e5-base-v2                                                  0.476349   \n",
       "intfloat__e5-large-v2                                                 0.462021   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                  0.443527   \n",
       "intfloat__e5-mistral-7b-instruct                                      0.492720   \n",
       "hkunlp__instructor-base                                               0.422701   \n",
       "hkunlp__instructor-large                                              0.432950   \n",
       "hkunlp__instructor-xl                                                 0.445227   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                  0.475894   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                0.480779   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                       0.509411   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                            0.467305   \n",
       "openai__text-embedding-ada-002                                        0.503193   \n",
       "openai__text-embedding-3-small                                        0.478576   \n",
       "openai__text-embedding-3-large                                        0.522286   \n",
       "voyageai__voyage-code-2                                               0.555524   \n",
       "voyageai__voyage-code-3                                               0.595961   \n",
       "microsoft__codebert-base                                              0.343351   \n",
       "microsoft__graphcodebert-base                                         0.393534   \n",
       "nomic-ai__CodeRankEmbed                                               0.458748   \n",
       "local-repllama-llama31-8b-lora-64                                     0.485688   \n",
       "local-repllama-llama31-8b-lora-64-quality                             0.679526   \n",
       "local-repllama-llama32-3b-lora-256                                    0.427969   \n",
       "local-repllama-llama32-3b-lora-256-quality                            0.674569   \n",
       "codesage__codesage-small                                              0.479749   \n",
       "codesage__codesage-base                                               0.500223   \n",
       "\n",
       "                                                 CodeNetEfficiencyPreferenceRetrieval  \\\n",
       "bm25s                                                                        0.371700   \n",
       "facebook__contriever                                                         0.385453   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                0.386383   \n",
       "sentence-transformers__gtr-t5-base                                           0.339693   \n",
       "sentence-transformers__gtr-t5-large                                          0.391341   \n",
       "intfloat__e5-base-v2                                                         0.432534   \n",
       "intfloat__e5-large-v2                                                        0.467265   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                         0.441737   \n",
       "intfloat__e5-mistral-7b-instruct                                             0.482654   \n",
       "hkunlp__instructor-base                                                      0.394064   \n",
       "hkunlp__instructor-large                                                     0.426712   \n",
       "hkunlp__instructor-xl                                                        0.424331   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                         0.461753   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                       0.468667   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                              0.490770   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                   0.467178   \n",
       "openai__text-embedding-ada-002                                               0.482328   \n",
       "openai__text-embedding-3-small                                               0.475005   \n",
       "openai__text-embedding-3-large                                               0.477876   \n",
       "voyageai__voyage-code-2                                                      0.510665   \n",
       "voyageai__voyage-code-3                                                      0.512606   \n",
       "microsoft__codebert-base                                                     0.210807   \n",
       "microsoft__graphcodebert-base                                                0.262829   \n",
       "nomic-ai__CodeRankEmbed                                                      0.425701   \n",
       "local-repllama-llama31-8b-lora-64                                            0.478696   \n",
       "local-repllama-llama31-8b-lora-64-quality                                    0.716330   \n",
       "local-repllama-llama32-3b-lora-256                                           0.396668   \n",
       "local-repllama-llama32-3b-lora-256-quality                                   0.701375   \n",
       "codesage__codesage-small                                                     0.442748   \n",
       "codesage__codesage-base                                                      0.464432   \n",
       "\n",
       "                                                 CVEFixesPreferenceRetrieval  \\\n",
       "bm25s                                                               0.648998   \n",
       "facebook__contriever                                                0.531247   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                       0.553256   \n",
       "sentence-transformers__gtr-t5-base                                  0.572111   \n",
       "sentence-transformers__gtr-t5-large                                 0.572961   \n",
       "intfloat__e5-base-v2                                                0.605025   \n",
       "intfloat__e5-large-v2                                               0.610142   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                0.647909   \n",
       "intfloat__e5-mistral-7b-instruct                                    0.607143   \n",
       "hkunlp__instructor-base                                             0.607700   \n",
       "hkunlp__instructor-large                                            0.576440   \n",
       "hkunlp__instructor-xl                                               0.590283   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                0.653528   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                              0.643632   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                     0.637491   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                          0.635628   \n",
       "openai__text-embedding-ada-002                                      0.622463   \n",
       "openai__text-embedding-3-small                                      0.607506   \n",
       "openai__text-embedding-3-large                                      0.625901   \n",
       "voyageai__voyage-code-2                                             0.665572   \n",
       "voyageai__voyage-code-3                                             0.682124   \n",
       "microsoft__codebert-base                                            0.385367   \n",
       "microsoft__graphcodebert-base                                       0.466357   \n",
       "nomic-ai__CodeRankEmbed                                             0.618693   \n",
       "local-repllama-llama31-8b-lora-64                                   0.631742   \n",
       "local-repllama-llama31-8b-lora-64-quality                           0.636850   \n",
       "local-repllama-llama32-3b-lora-256                                  0.632434   \n",
       "local-repllama-llama32-3b-lora-256-quality                          0.623522   \n",
       "codesage__codesage-small                                            0.586093   \n",
       "codesage__codesage-base                                             0.578671   \n",
       "\n",
       "                                                 Defects4JPreferenceRetrieval  \\\n",
       "bm25s                                                                0.567452   \n",
       "facebook__contriever                                                 0.468951   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                        0.595289   \n",
       "sentence-transformers__gtr-t5-base                                   0.571734   \n",
       "sentence-transformers__gtr-t5-large                                  0.576017   \n",
       "intfloat__e5-base-v2                                                 0.591006   \n",
       "intfloat__e5-large-v2                                                0.620985   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                 0.603854   \n",
       "intfloat__e5-mistral-7b-instruct                                     0.644540   \n",
       "hkunlp__instructor-base                                              0.608137   \n",
       "hkunlp__instructor-large                                             0.543897   \n",
       "hkunlp__instructor-xl                                                0.608137   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                 0.693790   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                               0.676660   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                      0.674518   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                           0.685225   \n",
       "openai__text-embedding-ada-002                                       0.642398   \n",
       "openai__text-embedding-3-small                                       0.627409   \n",
       "openai__text-embedding-3-large                                       0.644540   \n",
       "voyageai__voyage-code-2                                              0.659529   \n",
       "voyageai__voyage-code-3                                              0.695931   \n",
       "microsoft__codebert-base                                             0.451820   \n",
       "microsoft__graphcodebert-base                                        0.524625   \n",
       "nomic-ai__CodeRankEmbed                                              0.653105   \n",
       "local-repllama-llama31-8b-lora-64                                    0.655246   \n",
       "local-repllama-llama31-8b-lora-64-quality                            0.571734   \n",
       "local-repllama-llama32-3b-lora-256                                   0.648822   \n",
       "local-repllama-llama32-3b-lora-256-quality                           0.584582   \n",
       "codesage__codesage-small                                             0.608137   \n",
       "codesage__codesage-base                                              0.646681   \n",
       "\n",
       "                                                 DeprecatedCodePreferenceRetrieval  \\\n",
       "bm25s                                                                     0.177335   \n",
       "facebook__contriever                                                      0.473865   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.506067   \n",
       "sentence-transformers__gtr-t5-base                                        0.474838   \n",
       "sentence-transformers__gtr-t5-large                                       0.467169   \n",
       "intfloat__e5-base-v2                                                      0.479891   \n",
       "intfloat__e5-large-v2                                                     0.467820   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.468762   \n",
       "intfloat__e5-mistral-7b-instruct                                          0.524875   \n",
       "hkunlp__instructor-base                                                   0.490619   \n",
       "hkunlp__instructor-large                                                  0.499850   \n",
       "hkunlp__instructor-xl                                                     0.475088   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.518630   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.553417   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           0.545447   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.512973   \n",
       "openai__text-embedding-ada-002                                            0.511178   \n",
       "openai__text-embedding-3-small                                            0.520049   \n",
       "openai__text-embedding-3-large                                            0.533620   \n",
       "voyageai__voyage-code-2                                                   0.494402   \n",
       "voyageai__voyage-code-3                                                   0.573364   \n",
       "microsoft__codebert-base                                                  0.191906   \n",
       "microsoft__graphcodebert-base                                             0.282865   \n",
       "nomic-ai__CodeRankEmbed                                                   0.524456   \n",
       "local-repllama-llama31-8b-lora-64                                         0.541780   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.720812   \n",
       "local-repllama-llama32-3b-lora-256                                        0.553844   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.664861   \n",
       "codesage__codesage-small                                                  0.532258   \n",
       "codesage__codesage-base                                                   0.507169   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval  \\\n",
       "bm25s                                                                0.505294   \n",
       "facebook__contriever                                                 0.410161   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                        0.477051   \n",
       "sentence-transformers__gtr-t5-base                                   0.496209   \n",
       "sentence-transformers__gtr-t5-large                                  0.488318   \n",
       "intfloat__e5-base-v2                                                 0.527586   \n",
       "intfloat__e5-large-v2                                                0.516071   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                 0.516740   \n",
       "intfloat__e5-mistral-7b-instruct                                     0.503371   \n",
       "hkunlp__instructor-base                                              0.495242   \n",
       "hkunlp__instructor-large                                             0.495357   \n",
       "hkunlp__instructor-xl                                                0.475076   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                 0.536916   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                               0.519658   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                      0.516035   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                           0.507586   \n",
       "openai__text-embedding-ada-002                                       0.490298   \n",
       "openai__text-embedding-3-small                                       0.502789   \n",
       "openai__text-embedding-3-large                                       0.504370   \n",
       "voyageai__voyage-code-2                                              0.519476   \n",
       "voyageai__voyage-code-3                                              0.604895   \n",
       "microsoft__codebert-base                                             0.524768   \n",
       "microsoft__graphcodebert-base                                        0.546306   \n",
       "nomic-ai__CodeRankEmbed                                              0.419545   \n",
       "local-repllama-llama31-8b-lora-64                                    0.511162   \n",
       "local-repllama-llama31-8b-lora-64-quality                            0.730671   \n",
       "local-repllama-llama32-3b-lora-256                                   0.496307   \n",
       "local-repllama-llama32-3b-lora-256-quality                           0.722034   \n",
       "codesage__codesage-small                                             0.525892   \n",
       "codesage__codesage-base                                              0.501625   \n",
       "\n",
       "                                                 SQLR2PreferenceRetrieval  \n",
       "bm25s                                                            0.698311  \n",
       "facebook__contriever                                             0.593825  \n",
       "Alibaba-NLP__gte-base-en-v1.5                                    0.603781  \n",
       "sentence-transformers__gtr-t5-base                               0.649839  \n",
       "sentence-transformers__gtr-t5-large                              0.681315  \n",
       "intfloat__e5-base-v2                                             0.695093  \n",
       "intfloat__e5-large-v2                                            0.730491  \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                             0.711484  \n",
       "intfloat__e5-mistral-7b-instruct                                 0.735318  \n",
       "hkunlp__instructor-base                                          0.713998  \n",
       "hkunlp__instructor-large                                         0.701227  \n",
       "hkunlp__instructor-xl                                            0.731798  \n",
       "samaya-ai__promptriever-llama2-7b-v1                             0.819690  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                           0.795253  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                  0.826529  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                       0.813355  \n",
       "openai__text-embedding-ada-002                                   0.755531  \n",
       "openai__text-embedding-3-small                                   0.715607  \n",
       "openai__text-embedding-3-large                                   0.739541  \n",
       "voyageai__voyage-code-2                                          0.723753  \n",
       "voyageai__voyage-code-3                                          0.688455  \n",
       "microsoft__codebert-base                                         0.107200  \n",
       "microsoft__graphcodebert-base                                    0.259151  \n",
       "nomic-ai__CodeRankEmbed                                          0.775442  \n",
       "local-repllama-llama31-8b-lora-64                                0.798069  \n",
       "local-repllama-llama31-8b-lora-64-quality                        0.742056  \n",
       "local-repllama-llama32-3b-lora-256                               0.805209  \n",
       "local-repllama-llama32-3b-lora-256-quality                       0.704043  \n",
       "codesage__codesage-small                                         0.597647  \n",
       "codesage__codesage-base                                          0.607401  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original_df is already your DataFrame\n",
    "ppa_df = pd.DataFrame.from_dict(ppa_dict, orient='index')\n",
    "mask = ~ppa_df.columns.astype(str).str.contains(r'-')\n",
    "ppa_mean_df = ppa_df.loc[:, mask]\n",
    "\n",
    "# inspect the result\n",
    "ppa_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c476150-6b8e-435b-b5c1-2d7ea47d47ad",
   "metadata": {},
   "source": [
    "### 2.2: Margin-based Ranking Score (MRS)\n",
    "\n",
    "Measures the average margin between positive and negative scores - in order to normalize the score across different datasets and retrievers, we use rank reciprocal function $r$\n",
    "\n",
    "$$\n",
    "\\text{MRS} = \\frac{1}{|\\mathcal{P}| \\cdot |\\mathcal{N}|} \\sum_{p \\in \\mathcal{P}} \\sum_{n \\in \\mathcal{N}} \\left( r(p) - r(n) \\right)\n",
    "$$\n",
    "\n",
    "- **Upper bound**: $\\text{MRS} \\to 1$ if positives are scored much higher than negatives.\n",
    "- **Lower bound**: $\\text{MRS} \\to -1$ if negatives are scored much higher than positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da15f8cf-e1b4-4266-84cc-fc01bb52e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mrs(_qrels_dict, _predictions):\n",
    "    overall_mrs = []\n",
    "    for _qrels_key in list(_qrels_dict.keys()):\n",
    "        pos_docids = _qrels_dict[_qrels_key]['pos-docids']\n",
    "        neg_docids = _qrels_dict[_qrels_key]['neg-docids']\n",
    "        query_mrs = []\n",
    "        for _pos_docid in pos_docids:\n",
    "            _pos_docid_rank = _predictions[_qrels_key].index(_pos_docid) if _pos_docid in _predictions[_qrels_key] else len(_predictions[_qrels_key])\n",
    "            for _neg_docid in neg_docids:\n",
    "                _neg_docid_rank = _predictions[_qrels_key].index(_neg_docid) if _neg_docid in _predictions[_qrels_key] else len(_predictions[_qrels_key])\n",
    "                query_mrs.append(1./(1+_pos_docid_rank) - 1./(1+_neg_docid_rank))\n",
    "        overall_mrs.append(np.mean(query_mrs))\n",
    "    return np.mean(overall_mrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aed215b1-eb6c-4395-98bb-357e2c73efd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [27:38<00:00, 55.29s/it]\n"
     ]
    }
   ],
   "source": [
    "mrs_dict = defaultdict(dict)\n",
    "for _model in tqdm(models):\n",
    "    mrs_values = []\n",
    "    for _task in tasks:\n",
    "        for _subtask in task_sub_task_mapping[_task]:\n",
    "            _qrels_dict = load_qrels(_task, _subtask)\n",
    "            _predictions = load_predictions(_model, _task, _subtask)\n",
    "            _mrs_value = compute_mrs(_qrels_dict, _predictions)\n",
    "            mrs_values.append(_mrs_value)\n",
    "            mrs_dict[_model][_task + '-' + _subtask if _subtask is not None else _task] = _mrs_value\n",
    "        \n",
    "        # Compute mean MRS over subtasks\n",
    "        if _task not in mrs_dict[_model]:\n",
    "            mean_mrs = sum(mrs_values) / len(mrs_values) if mrs_values else None\n",
    "            mrs_dict[_model][_task] = mean_mrs\n",
    "\n",
    "df = pd.DataFrame.from_dict(mrs_dict, orient='index').style.apply(highlight_max_in_column, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f84af0df-8594-4c26-a240-75514d4dbc2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodeNetBugPreferenceRetrieval</th>\n",
       "      <th>CodeNetEfficiencyPreferenceRetrieval</th>\n",
       "      <th>CVEFixesPreferenceRetrieval</th>\n",
       "      <th>Defects4JPreferenceRetrieval</th>\n",
       "      <th>DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th>SaferCodePreferenceRetrieval</th>\n",
       "      <th>SQLR2PreferenceRetrieval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bm25s</th>\n",
       "      <td>0.001361</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.026623</td>\n",
       "      <td>0.074746</td>\n",
       "      <td>-0.019841</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>0.217158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook__contriever</th>\n",
       "      <td>-0.001578</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>-0.017175</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>-0.010169</td>\n",
       "      <td>0.080737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-base-en-v1.5</th>\n",
       "      <td>-0.004377</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>0.104495</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.065668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-base</th>\n",
       "      <td>-0.000830</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>0.060104</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.035975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-large</th>\n",
       "      <td>-0.003788</td>\n",
       "      <td>-0.005891</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.077666</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.048570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-base-v2</th>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.090219</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>0.271137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-large-v2</th>\n",
       "      <td>-0.004649</td>\n",
       "      <td>-0.001405</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.119311</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.235500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-Qwen2-1.5B-instruct</th>\n",
       "      <td>-0.008265</td>\n",
       "      <td>-0.004938</td>\n",
       "      <td>0.025908</td>\n",
       "      <td>0.103640</td>\n",
       "      <td>0.018533</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.087614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-mistral-7b-instruct</th>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.026452</td>\n",
       "      <td>0.148796</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.022714</td>\n",
       "      <td>0.154830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base</th>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>0.019617</td>\n",
       "      <td>0.107377</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.080215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large</th>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.044288</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>0.126380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl</th>\n",
       "      <td>-0.000970</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.151370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1</th>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>0.202358</td>\n",
       "      <td>0.035403</td>\n",
       "      <td>0.036228</td>\n",
       "      <td>0.237587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1</th>\n",
       "      <td>0.005508</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.027411</td>\n",
       "      <td>0.180074</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.229442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1</th>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.035685</td>\n",
       "      <td>0.184709</td>\n",
       "      <td>0.042045</td>\n",
       "      <td>0.037466</td>\n",
       "      <td>0.300318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1</th>\n",
       "      <td>-0.001498</td>\n",
       "      <td>-0.004748</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.197648</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>0.233568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-ada-002</th>\n",
       "      <td>0.008260</td>\n",
       "      <td>-0.002204</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.140504</td>\n",
       "      <td>0.025071</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.225891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-small</th>\n",
       "      <td>-0.006774</td>\n",
       "      <td>-0.004254</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>0.120289</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>0.186433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-large</th>\n",
       "      <td>0.013147</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.024662</td>\n",
       "      <td>0.142383</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.232123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-2</th>\n",
       "      <td>0.057168</td>\n",
       "      <td>0.030648</td>\n",
       "      <td>0.058471</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>0.047801</td>\n",
       "      <td>0.042637</td>\n",
       "      <td>0.237849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-3</th>\n",
       "      <td>0.095882</td>\n",
       "      <td>0.051223</td>\n",
       "      <td>0.077671</td>\n",
       "      <td>0.184577</td>\n",
       "      <td>0.080090</td>\n",
       "      <td>0.083564</td>\n",
       "      <td>0.208566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__codebert-base</th>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__graphcodebert-base</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>-0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai__CodeRankEmbed</th>\n",
       "      <td>-0.004843</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.148494</td>\n",
       "      <td>0.025899</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.283637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64</th>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.031942</td>\n",
       "      <td>0.151723</td>\n",
       "      <td>0.037369</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>0.239974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64-quality</th>\n",
       "      <td>0.115935</td>\n",
       "      <td>0.123620</td>\n",
       "      <td>0.124852</td>\n",
       "      <td>0.074211</td>\n",
       "      <td>0.133384</td>\n",
       "      <td>0.145644</td>\n",
       "      <td>0.163966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256</th>\n",
       "      <td>0.012493</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.030712</td>\n",
       "      <td>0.152794</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.259253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256-quality</th>\n",
       "      <td>0.084551</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.093216</td>\n",
       "      <td>0.075350</td>\n",
       "      <td>0.095975</td>\n",
       "      <td>0.113150</td>\n",
       "      <td>0.148587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-small</th>\n",
       "      <td>0.000534</td>\n",
       "      <td>-0.003675</td>\n",
       "      <td>0.015105</td>\n",
       "      <td>0.106644</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.021684</td>\n",
       "      <td>0.047267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-base</th>\n",
       "      <td>0.007492</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.017087</td>\n",
       "      <td>0.143633</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.095636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CodeNetBugPreferenceRetrieval  \\\n",
       "bm25s                                                                 0.001361   \n",
       "facebook__contriever                                                 -0.001578   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                        -0.004377   \n",
       "sentence-transformers__gtr-t5-base                                   -0.000830   \n",
       "sentence-transformers__gtr-t5-large                                  -0.003788   \n",
       "intfloat__e5-base-v2                                                  0.003403   \n",
       "intfloat__e5-large-v2                                                -0.004649   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                 -0.008265   \n",
       "intfloat__e5-mistral-7b-instruct                                      0.014154   \n",
       "hkunlp__instructor-base                                              -0.003342   \n",
       "hkunlp__instructor-large                                             -0.007316   \n",
       "hkunlp__instructor-xl                                                -0.000970   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                  0.005722   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                0.005508   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                       0.018778   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                           -0.001498   \n",
       "openai__text-embedding-ada-002                                        0.008260   \n",
       "openai__text-embedding-3-small                                       -0.006774   \n",
       "openai__text-embedding-3-large                                        0.013147   \n",
       "voyageai__voyage-code-2                                               0.057168   \n",
       "voyageai__voyage-code-3                                               0.095882   \n",
       "microsoft__codebert-base                                             -0.000186   \n",
       "microsoft__graphcodebert-base                                         0.001063   \n",
       "nomic-ai__CodeRankEmbed                                              -0.004843   \n",
       "local-repllama-llama31-8b-lora-64                                     0.009916   \n",
       "local-repllama-llama31-8b-lora-64-quality                             0.115935   \n",
       "local-repllama-llama32-3b-lora-256                                    0.012493   \n",
       "local-repllama-llama32-3b-lora-256-quality                            0.084551   \n",
       "codesage__codesage-small                                              0.000534   \n",
       "codesage__codesage-base                                               0.007492   \n",
       "\n",
       "                                                 CodeNetEfficiencyPreferenceRetrieval  \\\n",
       "bm25s                                                                       -0.000440   \n",
       "facebook__contriever                                                        -0.001291   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                               -0.002676   \n",
       "sentence-transformers__gtr-t5-base                                          -0.002046   \n",
       "sentence-transformers__gtr-t5-large                                         -0.005891   \n",
       "intfloat__e5-base-v2                                                         0.002342   \n",
       "intfloat__e5-large-v2                                                       -0.001405   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                        -0.004938   \n",
       "intfloat__e5-mistral-7b-instruct                                             0.007928   \n",
       "hkunlp__instructor-base                                                     -0.002800   \n",
       "hkunlp__instructor-large                                                    -0.005174   \n",
       "hkunlp__instructor-xl                                                       -0.001686   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                         0.001493   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                      -0.002529   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                              0.009190   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                  -0.004748   \n",
       "openai__text-embedding-ada-002                                              -0.002204   \n",
       "openai__text-embedding-3-small                                              -0.004254   \n",
       "openai__text-embedding-3-large                                               0.000027   \n",
       "voyageai__voyage-code-2                                                      0.030648   \n",
       "voyageai__voyage-code-3                                                      0.051223   \n",
       "microsoft__codebert-base                                                    -0.000667   \n",
       "microsoft__graphcodebert-base                                                0.000455   \n",
       "nomic-ai__CodeRankEmbed                                                     -0.004092   \n",
       "local-repllama-llama31-8b-lora-64                                            0.005171   \n",
       "local-repllama-llama31-8b-lora-64-quality                                    0.123620   \n",
       "local-repllama-llama32-3b-lora-256                                           0.003352   \n",
       "local-repllama-llama32-3b-lora-256-quality                                   0.085689   \n",
       "codesage__codesage-small                                                    -0.003675   \n",
       "codesage__codesage-base                                                      0.000694   \n",
       "\n",
       "                                                 CVEFixesPreferenceRetrieval  \\\n",
       "bm25s                                                               0.026623   \n",
       "facebook__contriever                                                0.006353   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                       0.010859   \n",
       "sentence-transformers__gtr-t5-base                                  0.012063   \n",
       "sentence-transformers__gtr-t5-large                                 0.010156   \n",
       "intfloat__e5-base-v2                                                0.022100   \n",
       "intfloat__e5-large-v2                                               0.021521   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                0.025908   \n",
       "intfloat__e5-mistral-7b-instruct                                    0.026452   \n",
       "hkunlp__instructor-base                                             0.019617   \n",
       "hkunlp__instructor-large                                            0.010519   \n",
       "hkunlp__instructor-xl                                               0.016299   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                0.032815   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                              0.027411   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                     0.035685   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                          0.024454   \n",
       "openai__text-embedding-ada-002                                      0.021837   \n",
       "openai__text-embedding-3-small                                      0.018753   \n",
       "openai__text-embedding-3-large                                      0.024662   \n",
       "voyageai__voyage-code-2                                             0.058471   \n",
       "voyageai__voyage-code-3                                             0.077671   \n",
       "microsoft__codebert-base                                           -0.000937   \n",
       "microsoft__graphcodebert-base                                       0.001476   \n",
       "nomic-ai__CodeRankEmbed                                             0.022258   \n",
       "local-repllama-llama31-8b-lora-64                                   0.031942   \n",
       "local-repllama-llama31-8b-lora-64-quality                           0.124852   \n",
       "local-repllama-llama32-3b-lora-256                                  0.030712   \n",
       "local-repllama-llama32-3b-lora-256-quality                          0.093216   \n",
       "codesage__codesage-small                                            0.015105   \n",
       "codesage__codesage-base                                             0.017087   \n",
       "\n",
       "                                                 Defects4JPreferenceRetrieval  \\\n",
       "bm25s                                                                0.074746   \n",
       "facebook__contriever                                                -0.017175   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                        0.104495   \n",
       "sentence-transformers__gtr-t5-base                                   0.060104   \n",
       "sentence-transformers__gtr-t5-large                                  0.077666   \n",
       "intfloat__e5-base-v2                                                 0.090219   \n",
       "intfloat__e5-large-v2                                                0.119311   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                 0.103640   \n",
       "intfloat__e5-mistral-7b-instruct                                     0.148796   \n",
       "hkunlp__instructor-base                                              0.107377   \n",
       "hkunlp__instructor-large                                             0.044288   \n",
       "hkunlp__instructor-xl                                                0.108593   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                 0.202358   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                               0.180074   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                      0.184709   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                           0.197648   \n",
       "openai__text-embedding-ada-002                                       0.140504   \n",
       "openai__text-embedding-3-small                                       0.120289   \n",
       "openai__text-embedding-3-large                                       0.142383   \n",
       "voyageai__voyage-code-2                                              0.158892   \n",
       "voyageai__voyage-code-3                                              0.184577   \n",
       "microsoft__codebert-base                                            -0.000692   \n",
       "microsoft__graphcodebert-base                                        0.001398   \n",
       "nomic-ai__CodeRankEmbed                                              0.148494   \n",
       "local-repllama-llama31-8b-lora-64                                    0.151723   \n",
       "local-repllama-llama31-8b-lora-64-quality                            0.074211   \n",
       "local-repllama-llama32-3b-lora-256                                   0.152794   \n",
       "local-repllama-llama32-3b-lora-256-quality                           0.075350   \n",
       "codesage__codesage-small                                             0.106644   \n",
       "codesage__codesage-base                                              0.143633   \n",
       "\n",
       "                                                 DeprecatedCodePreferenceRetrieval  \\\n",
       "bm25s                                                                    -0.019841   \n",
       "facebook__contriever                                                      0.003271   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.011133   \n",
       "sentence-transformers__gtr-t5-base                                        0.007494   \n",
       "sentence-transformers__gtr-t5-large                                       0.005331   \n",
       "intfloat__e5-base-v2                                                      0.015921   \n",
       "intfloat__e5-large-v2                                                     0.014561   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.018533   \n",
       "intfloat__e5-mistral-7b-instruct                                          0.028600   \n",
       "hkunlp__instructor-base                                                   0.016457   \n",
       "hkunlp__instructor-large                                                  0.009689   \n",
       "hkunlp__instructor-xl                                                     0.012374   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.035403   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.037348   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           0.042045   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.026433   \n",
       "openai__text-embedding-ada-002                                            0.025071   \n",
       "openai__text-embedding-3-small                                            0.022689   \n",
       "openai__text-embedding-3-large                                            0.027444   \n",
       "voyageai__voyage-code-2                                                   0.047801   \n",
       "voyageai__voyage-code-3                                                   0.080090   \n",
       "microsoft__codebert-base                                                 -0.000791   \n",
       "microsoft__graphcodebert-base                                             0.000477   \n",
       "nomic-ai__CodeRankEmbed                                                   0.025899   \n",
       "local-repllama-llama31-8b-lora-64                                         0.037369   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.133384   \n",
       "local-repllama-llama32-3b-lora-256                                        0.037707   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.095975   \n",
       "codesage__codesage-small                                                  0.021250   \n",
       "codesage__codesage-base                                                   0.017317   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval  \\\n",
       "bm25s                                                               -0.016983   \n",
       "facebook__contriever                                                -0.010169   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                        0.005020   \n",
       "sentence-transformers__gtr-t5-base                                   0.004252   \n",
       "sentence-transformers__gtr-t5-large                                  0.002426   \n",
       "intfloat__e5-base-v2                                                 0.016638   \n",
       "intfloat__e5-large-v2                                                0.013517   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                 0.016389   \n",
       "intfloat__e5-mistral-7b-instruct                                     0.022714   \n",
       "hkunlp__instructor-base                                              0.012225   \n",
       "hkunlp__instructor-large                                             0.007175   \n",
       "hkunlp__instructor-xl                                                0.007618   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                 0.036228   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                               0.033864   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                      0.037466   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                           0.024081   \n",
       "openai__text-embedding-ada-002                                       0.019493   \n",
       "openai__text-embedding-3-small                                       0.020410   \n",
       "openai__text-embedding-3-large                                       0.022020   \n",
       "voyageai__voyage-code-2                                              0.042637   \n",
       "voyageai__voyage-code-3                                              0.083564   \n",
       "microsoft__codebert-base                                             0.000140   \n",
       "microsoft__graphcodebert-base                                        0.002462   \n",
       "nomic-ai__CodeRankEmbed                                              0.010022   \n",
       "local-repllama-llama31-8b-lora-64                                    0.031801   \n",
       "local-repllama-llama31-8b-lora-64-quality                            0.145644   \n",
       "local-repllama-llama32-3b-lora-256                                   0.029021   \n",
       "local-repllama-llama32-3b-lora-256-quality                           0.113150   \n",
       "codesage__codesage-small                                             0.021684   \n",
       "codesage__codesage-base                                              0.012986   \n",
       "\n",
       "                                                 SQLR2PreferenceRetrieval  \n",
       "bm25s                                                            0.217158  \n",
       "facebook__contriever                                             0.080737  \n",
       "Alibaba-NLP__gte-base-en-v1.5                                    0.065668  \n",
       "sentence-transformers__gtr-t5-base                               0.035975  \n",
       "sentence-transformers__gtr-t5-large                              0.048570  \n",
       "intfloat__e5-base-v2                                             0.271137  \n",
       "intfloat__e5-large-v2                                            0.235500  \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                             0.087614  \n",
       "intfloat__e5-mistral-7b-instruct                                 0.154830  \n",
       "hkunlp__instructor-base                                          0.080215  \n",
       "hkunlp__instructor-large                                         0.126380  \n",
       "hkunlp__instructor-xl                                            0.151370  \n",
       "samaya-ai__promptriever-llama2-7b-v1                             0.237587  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                           0.229442  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                  0.300318  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                       0.233568  \n",
       "openai__text-embedding-ada-002                                   0.225891  \n",
       "openai__text-embedding-3-small                                   0.186433  \n",
       "openai__text-embedding-3-large                                   0.232123  \n",
       "voyageai__voyage-code-2                                          0.237849  \n",
       "voyageai__voyage-code-3                                          0.208566  \n",
       "microsoft__codebert-base                                         0.000485  \n",
       "microsoft__graphcodebert-base                                   -0.000782  \n",
       "nomic-ai__CodeRankEmbed                                          0.283637  \n",
       "local-repllama-llama31-8b-lora-64                                0.239974  \n",
       "local-repllama-llama31-8b-lora-64-quality                        0.163966  \n",
       "local-repllama-llama32-3b-lora-256                               0.259253  \n",
       "local-repllama-llama32-3b-lora-256-quality                       0.148587  \n",
       "codesage__codesage-small                                         0.047267  \n",
       "codesage__codesage-base                                          0.095636  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrs_df = pd.DataFrame.from_dict(mrs_dict, orient='index')\n",
    "# original_df is already your DataFrame\n",
    "mask = ~mrs_df.columns.astype(str).str.contains(r'-')\n",
    "mrs_mean_df = mrs_df.loc[:, mask]\n",
    "\n",
    "# inspect the result\n",
    "mrs_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71c84d-e43d-492c-9a37-a4410edf1b23",
   "metadata": {},
   "source": [
    "### 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c5c35-a8b1-4687-a5d9-fc8b5c45a750",
   "metadata": {},
   "source": [
    "#### 3.1 PPA across multiple languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1a4bf5e-1437-473a-8ed9-0c520ed98a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-c</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-cpp</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-go</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-java</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-javascript</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-python</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-ruby</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-rust</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-swift</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-typescript</th>\n",
       "      <th>...</th>\n",
       "      <th>DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th>SaferCodePreferenceRetrieval-c</th>\n",
       "      <th>SaferCodePreferenceRetrieval-cpp</th>\n",
       "      <th>SaferCodePreferenceRetrieval-python</th>\n",
       "      <th>SaferCodePreferenceRetrieval-java</th>\n",
       "      <th>SaferCodePreferenceRetrieval-javascript</th>\n",
       "      <th>SaferCodePreferenceRetrieval-go</th>\n",
       "      <th>SaferCodePreferenceRetrieval-ruby</th>\n",
       "      <th>SaferCodePreferenceRetrieval</th>\n",
       "      <th>SQLR2PreferenceRetrieval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bm25s</th>\n",
       "      <td>0.450830</td>\n",
       "      <td>0.447957</td>\n",
       "      <td>0.421137</td>\n",
       "      <td>0.550447</td>\n",
       "      <td>0.492656</td>\n",
       "      <td>0.428161</td>\n",
       "      <td>0.449553</td>\n",
       "      <td>0.477331</td>\n",
       "      <td>0.433509</td>\n",
       "      <td>0.454342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177335</td>\n",
       "      <td>0.318072</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.585551</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.477876</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.505294</td>\n",
       "      <td>0.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook__contriever</th>\n",
       "      <td>0.408365</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.327267</td>\n",
       "      <td>0.445083</td>\n",
       "      <td>0.437420</td>\n",
       "      <td>0.440294</td>\n",
       "      <td>0.441411</td>\n",
       "      <td>0.426165</td>\n",
       "      <td>0.428081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473865</td>\n",
       "      <td>0.383133</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.456274</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.426829</td>\n",
       "      <td>0.410161</td>\n",
       "      <td>0.593825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-base-en-v1.5</th>\n",
       "      <td>0.471584</td>\n",
       "      <td>0.433908</td>\n",
       "      <td>0.446679</td>\n",
       "      <td>0.439017</td>\n",
       "      <td>0.479885</td>\n",
       "      <td>0.426245</td>\n",
       "      <td>0.429757</td>\n",
       "      <td>0.390964</td>\n",
       "      <td>0.457375</td>\n",
       "      <td>0.448835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506067</td>\n",
       "      <td>0.484337</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.477186</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.477051</td>\n",
       "      <td>0.603781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-base</th>\n",
       "      <td>0.401980</td>\n",
       "      <td>0.386654</td>\n",
       "      <td>0.382184</td>\n",
       "      <td>0.428480</td>\n",
       "      <td>0.444125</td>\n",
       "      <td>0.411239</td>\n",
       "      <td>0.409323</td>\n",
       "      <td>0.409004</td>\n",
       "      <td>0.373164</td>\n",
       "      <td>0.425607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474838</td>\n",
       "      <td>0.573494</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.465779</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.433628</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.496209</td>\n",
       "      <td>0.649839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-large</th>\n",
       "      <td>0.462324</td>\n",
       "      <td>0.408046</td>\n",
       "      <td>0.402937</td>\n",
       "      <td>0.535441</td>\n",
       "      <td>0.503512</td>\n",
       "      <td>0.461367</td>\n",
       "      <td>0.477011</td>\n",
       "      <td>0.410281</td>\n",
       "      <td>0.439017</td>\n",
       "      <td>0.453624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467169</td>\n",
       "      <td>0.607229</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.545627</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.451327</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.488318</td>\n",
       "      <td>0.681315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-base-v2</th>\n",
       "      <td>0.477011</td>\n",
       "      <td>0.369413</td>\n",
       "      <td>0.424330</td>\n",
       "      <td>0.660600</td>\n",
       "      <td>0.534163</td>\n",
       "      <td>0.475734</td>\n",
       "      <td>0.501916</td>\n",
       "      <td>0.367178</td>\n",
       "      <td>0.457216</td>\n",
       "      <td>0.495929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479891</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.480989</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.527586</td>\n",
       "      <td>0.695093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-large-v2</th>\n",
       "      <td>0.484355</td>\n",
       "      <td>0.458493</td>\n",
       "      <td>0.435504</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.467752</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.496488</td>\n",
       "      <td>0.338442</td>\n",
       "      <td>0.481003</td>\n",
       "      <td>0.503193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467820</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.433628</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.516071</td>\n",
       "      <td>0.730491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-Qwen2-1.5B-instruct</th>\n",
       "      <td>0.412197</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.431354</td>\n",
       "      <td>0.305236</td>\n",
       "      <td>0.529693</td>\n",
       "      <td>0.531609</td>\n",
       "      <td>0.505109</td>\n",
       "      <td>0.371328</td>\n",
       "      <td>0.461606</td>\n",
       "      <td>0.526980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468762</td>\n",
       "      <td>0.628916</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551331</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.516740</td>\n",
       "      <td>0.711484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-mistral-7b-instruct</th>\n",
       "      <td>0.458174</td>\n",
       "      <td>0.447318</td>\n",
       "      <td>0.463442</td>\n",
       "      <td>0.554278</td>\n",
       "      <td>0.522350</td>\n",
       "      <td>0.504789</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>0.441571</td>\n",
       "      <td>0.505268</td>\n",
       "      <td>0.539272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524875</td>\n",
       "      <td>0.633735</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.528517</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.477876</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.503371</td>\n",
       "      <td>0.735318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base</th>\n",
       "      <td>0.428480</td>\n",
       "      <td>0.430077</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.409962</td>\n",
       "      <td>0.458812</td>\n",
       "      <td>0.475734</td>\n",
       "      <td>0.473819</td>\n",
       "      <td>0.303959</td>\n",
       "      <td>0.433589</td>\n",
       "      <td>0.446839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490619</td>\n",
       "      <td>0.556627</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.477186</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.442478</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.495242</td>\n",
       "      <td>0.713998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large</th>\n",
       "      <td>0.469029</td>\n",
       "      <td>0.441890</td>\n",
       "      <td>0.372925</td>\n",
       "      <td>0.358557</td>\n",
       "      <td>0.483397</td>\n",
       "      <td>0.482439</td>\n",
       "      <td>0.480524</td>\n",
       "      <td>0.279055</td>\n",
       "      <td>0.464480</td>\n",
       "      <td>0.497206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.573494</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.557034</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.424779</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.495357</td>\n",
       "      <td>0.701227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl</th>\n",
       "      <td>0.470626</td>\n",
       "      <td>0.518199</td>\n",
       "      <td>0.393199</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.495849</td>\n",
       "      <td>0.460409</td>\n",
       "      <td>0.496807</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.479087</td>\n",
       "      <td>0.483716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475088</td>\n",
       "      <td>0.595181</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.484791</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.475076</td>\n",
       "      <td>0.731798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1</th>\n",
       "      <td>0.466794</td>\n",
       "      <td>0.430715</td>\n",
       "      <td>0.470785</td>\n",
       "      <td>0.386654</td>\n",
       "      <td>0.553001</td>\n",
       "      <td>0.507982</td>\n",
       "      <td>0.514049</td>\n",
       "      <td>0.414432</td>\n",
       "      <td>0.474457</td>\n",
       "      <td>0.540070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518630</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.482890</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.536916</td>\n",
       "      <td>0.819690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1</th>\n",
       "      <td>0.482120</td>\n",
       "      <td>0.457535</td>\n",
       "      <td>0.462005</td>\n",
       "      <td>0.334930</td>\n",
       "      <td>0.571520</td>\n",
       "      <td>0.506386</td>\n",
       "      <td>0.531609</td>\n",
       "      <td>0.439017</td>\n",
       "      <td>0.483078</td>\n",
       "      <td>0.539591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553417</td>\n",
       "      <td>0.563855</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.452471</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.539823</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.519658</td>\n",
       "      <td>0.795253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1</th>\n",
       "      <td>0.503193</td>\n",
       "      <td>0.462005</td>\n",
       "      <td>0.505587</td>\n",
       "      <td>0.447318</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.502235</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.479566</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545447</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.486726</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.826529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1</th>\n",
       "      <td>0.466475</td>\n",
       "      <td>0.433908</td>\n",
       "      <td>0.447957</td>\n",
       "      <td>0.321201</td>\n",
       "      <td>0.572478</td>\n",
       "      <td>0.498404</td>\n",
       "      <td>0.520434</td>\n",
       "      <td>0.385217</td>\n",
       "      <td>0.499840</td>\n",
       "      <td>0.527139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512973</td>\n",
       "      <td>0.575904</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.467681</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.507586</td>\n",
       "      <td>0.813355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-ada-002</th>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.530332</td>\n",
       "      <td>0.471903</td>\n",
       "      <td>0.321201</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.553959</td>\n",
       "      <td>0.472382</td>\n",
       "      <td>0.517082</td>\n",
       "      <td>0.561622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511178</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.522814</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.490298</td>\n",
       "      <td>0.755531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-small</th>\n",
       "      <td>0.471584</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.428161</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.520754</td>\n",
       "      <td>0.500958</td>\n",
       "      <td>0.535441</td>\n",
       "      <td>0.433589</td>\n",
       "      <td>0.488745</td>\n",
       "      <td>0.513809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520049</td>\n",
       "      <td>0.448193</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.475285</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.513274</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.715607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-large</th>\n",
       "      <td>0.515645</td>\n",
       "      <td>0.527458</td>\n",
       "      <td>0.477171</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.528416</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.556194</td>\n",
       "      <td>0.536398</td>\n",
       "      <td>0.511414</td>\n",
       "      <td>0.569205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533620</td>\n",
       "      <td>0.479518</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461977</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.504370</td>\n",
       "      <td>0.739541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-2</th>\n",
       "      <td>0.517880</td>\n",
       "      <td>0.514368</td>\n",
       "      <td>0.549808</td>\n",
       "      <td>0.551405</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.542146</td>\n",
       "      <td>0.567688</td>\n",
       "      <td>0.595785</td>\n",
       "      <td>0.555635</td>\n",
       "      <td>0.580061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494402</td>\n",
       "      <td>0.479518</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.543726</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.486726</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.519476</td>\n",
       "      <td>0.723753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-3</th>\n",
       "      <td>0.575990</td>\n",
       "      <td>0.570243</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.645275</td>\n",
       "      <td>0.591954</td>\n",
       "      <td>0.577905</td>\n",
       "      <td>0.625479</td>\n",
       "      <td>0.629151</td>\n",
       "      <td>0.563617</td>\n",
       "      <td>0.593790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573364</td>\n",
       "      <td>0.532530</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.593156</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.610619</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.604895</td>\n",
       "      <td>0.688455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__codebert-base</th>\n",
       "      <td>0.357918</td>\n",
       "      <td>0.309706</td>\n",
       "      <td>0.287197</td>\n",
       "      <td>0.488186</td>\n",
       "      <td>0.319604</td>\n",
       "      <td>0.286398</td>\n",
       "      <td>0.308110</td>\n",
       "      <td>0.417625</td>\n",
       "      <td>0.299330</td>\n",
       "      <td>0.359435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191906</td>\n",
       "      <td>0.508434</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.568441</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.524768</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__graphcodebert-base</th>\n",
       "      <td>0.433589</td>\n",
       "      <td>0.489783</td>\n",
       "      <td>0.338442</td>\n",
       "      <td>0.401660</td>\n",
       "      <td>0.392720</td>\n",
       "      <td>0.319604</td>\n",
       "      <td>0.358238</td>\n",
       "      <td>0.436941</td>\n",
       "      <td>0.353289</td>\n",
       "      <td>0.411079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282865</td>\n",
       "      <td>0.532530</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.513308</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.546306</td>\n",
       "      <td>0.259151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai__CodeRankEmbed</th>\n",
       "      <td>0.432950</td>\n",
       "      <td>0.502235</td>\n",
       "      <td>0.423052</td>\n",
       "      <td>0.565453</td>\n",
       "      <td>0.485632</td>\n",
       "      <td>0.418582</td>\n",
       "      <td>0.492656</td>\n",
       "      <td>0.364943</td>\n",
       "      <td>0.417225</td>\n",
       "      <td>0.484754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524456</td>\n",
       "      <td>0.387952</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.460076</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.433628</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.419545</td>\n",
       "      <td>0.775442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64</th>\n",
       "      <td>0.489464</td>\n",
       "      <td>0.467752</td>\n",
       "      <td>0.465198</td>\n",
       "      <td>0.320562</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.497126</td>\n",
       "      <td>0.543742</td>\n",
       "      <td>0.458653</td>\n",
       "      <td>0.500958</td>\n",
       "      <td>0.557870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541780</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.448669</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.511162</td>\n",
       "      <td>0.798069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64-quality</th>\n",
       "      <td>0.651341</td>\n",
       "      <td>0.757663</td>\n",
       "      <td>0.666188</td>\n",
       "      <td>0.908365</td>\n",
       "      <td>0.625160</td>\n",
       "      <td>0.671137</td>\n",
       "      <td>0.660920</td>\n",
       "      <td>0.695562</td>\n",
       "      <td>0.570482</td>\n",
       "      <td>0.588442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720812</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.825095</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.730671</td>\n",
       "      <td>0.742056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256</th>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.408365</td>\n",
       "      <td>0.414432</td>\n",
       "      <td>0.225734</td>\n",
       "      <td>0.521073</td>\n",
       "      <td>0.483078</td>\n",
       "      <td>0.502554</td>\n",
       "      <td>0.353129</td>\n",
       "      <td>0.408924</td>\n",
       "      <td>0.527219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553844</td>\n",
       "      <td>0.527711</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.450570</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.442478</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.496307</td>\n",
       "      <td>0.805209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256-quality</th>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.734674</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.921775</td>\n",
       "      <td>0.625798</td>\n",
       "      <td>0.674330</td>\n",
       "      <td>0.657727</td>\n",
       "      <td>0.668103</td>\n",
       "      <td>0.541347</td>\n",
       "      <td>0.588602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664861</td>\n",
       "      <td>0.595181</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.815589</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.722034</td>\n",
       "      <td>0.704043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-small</th>\n",
       "      <td>0.510856</td>\n",
       "      <td>0.476373</td>\n",
       "      <td>0.457854</td>\n",
       "      <td>0.396232</td>\n",
       "      <td>0.538314</td>\n",
       "      <td>0.521711</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.420658</td>\n",
       "      <td>0.482998</td>\n",
       "      <td>0.492497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.525301</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.513308</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.525892</td>\n",
       "      <td>0.597647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-base</th>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.512452</td>\n",
       "      <td>0.433269</td>\n",
       "      <td>0.433908</td>\n",
       "      <td>0.540868</td>\n",
       "      <td>0.546935</td>\n",
       "      <td>0.544061</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.516603</td>\n",
       "      <td>0.532088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507169</td>\n",
       "      <td>0.532530</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.451220</td>\n",
       "      <td>0.501625</td>\n",
       "      <td>0.607401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CodeNetBugPreferenceRetrieval-c  \\\n",
       "bm25s                                                                   0.450830   \n",
       "facebook__contriever                                                    0.408365   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                           0.471584   \n",
       "sentence-transformers__gtr-t5-base                                      0.401980   \n",
       "sentence-transformers__gtr-t5-large                                     0.462324   \n",
       "intfloat__e5-base-v2                                                    0.477011   \n",
       "intfloat__e5-large-v2                                                   0.484355   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                    0.412197   \n",
       "intfloat__e5-mistral-7b-instruct                                        0.458174   \n",
       "hkunlp__instructor-base                                                 0.428480   \n",
       "hkunlp__instructor-large                                                0.469029   \n",
       "hkunlp__instructor-xl                                                   0.470626   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                    0.466794   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                  0.482120   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                         0.503193   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                              0.466475   \n",
       "openai__text-embedding-ada-002                                          0.505747   \n",
       "openai__text-embedding-3-small                                          0.471584   \n",
       "openai__text-embedding-3-large                                          0.515645   \n",
       "voyageai__voyage-code-2                                                 0.517880   \n",
       "voyageai__voyage-code-3                                                 0.575990   \n",
       "microsoft__codebert-base                                                0.357918   \n",
       "microsoft__graphcodebert-base                                           0.433589   \n",
       "nomic-ai__CodeRankEmbed                                                 0.432950   \n",
       "local-repllama-llama31-8b-lora-64                                       0.489464   \n",
       "local-repllama-llama31-8b-lora-64-quality                               0.651341   \n",
       "local-repllama-llama32-3b-lora-256                                      0.435185   \n",
       "local-repllama-llama32-3b-lora-256-quality                              0.648148   \n",
       "codesage__codesage-small                                                0.510856   \n",
       "codesage__codesage-base                                                 0.511494   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-cpp  \\\n",
       "bm25s                                                                     0.447957   \n",
       "facebook__contriever                                                      0.360153   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.433908   \n",
       "sentence-transformers__gtr-t5-base                                        0.386654   \n",
       "sentence-transformers__gtr-t5-large                                       0.408046   \n",
       "intfloat__e5-base-v2                                                      0.369413   \n",
       "intfloat__e5-large-v2                                                     0.458493   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.360153   \n",
       "intfloat__e5-mistral-7b-instruct                                          0.447318   \n",
       "hkunlp__instructor-base                                                   0.430077   \n",
       "hkunlp__instructor-large                                                  0.441890   \n",
       "hkunlp__instructor-xl                                                     0.518199   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.430715   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.457535   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           0.462005   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.433908   \n",
       "openai__text-embedding-ada-002                                            0.530332   \n",
       "openai__text-embedding-3-small                                            0.528736   \n",
       "openai__text-embedding-3-large                                            0.527458   \n",
       "voyageai__voyage-code-2                                                   0.514368   \n",
       "voyageai__voyage-code-3                                                   0.570243   \n",
       "microsoft__codebert-base                                                  0.309706   \n",
       "microsoft__graphcodebert-base                                             0.489783   \n",
       "nomic-ai__CodeRankEmbed                                                   0.502235   \n",
       "local-repllama-llama31-8b-lora-64                                         0.467752   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.757663   \n",
       "local-repllama-llama32-3b-lora-256                                        0.408365   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.734674   \n",
       "codesage__codesage-small                                                  0.476373   \n",
       "codesage__codesage-base                                                   0.512452   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-go  \\\n",
       "bm25s                                                                    0.421137   \n",
       "facebook__contriever                                                     0.371488   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                            0.446679   \n",
       "sentence-transformers__gtr-t5-base                                       0.382184   \n",
       "sentence-transformers__gtr-t5-large                                      0.402937   \n",
       "intfloat__e5-base-v2                                                     0.424330   \n",
       "intfloat__e5-large-v2                                                    0.435504   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                     0.431354   \n",
       "intfloat__e5-mistral-7b-instruct                                         0.463442   \n",
       "hkunlp__instructor-base                                                  0.365741   \n",
       "hkunlp__instructor-large                                                 0.372925   \n",
       "hkunlp__instructor-xl                                                    0.393199   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                     0.470785   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                   0.462005   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                          0.505587   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                               0.447957   \n",
       "openai__text-embedding-ada-002                                           0.471903   \n",
       "openai__text-embedding-3-small                                           0.428161   \n",
       "openai__text-embedding-3-large                                           0.477171   \n",
       "voyageai__voyage-code-2                                                  0.549808   \n",
       "voyageai__voyage-code-3                                                  0.586207   \n",
       "microsoft__codebert-base                                                 0.287197   \n",
       "microsoft__graphcodebert-base                                            0.338442   \n",
       "nomic-ai__CodeRankEmbed                                                  0.423052   \n",
       "local-repllama-llama31-8b-lora-64                                        0.465198   \n",
       "local-repllama-llama31-8b-lora-64-quality                                0.666188   \n",
       "local-repllama-llama32-3b-lora-256                                       0.414432   \n",
       "local-repllama-llama32-3b-lora-256-quality                               0.685185   \n",
       "codesage__codesage-small                                                 0.457854   \n",
       "codesage__codesage-base                                                  0.433269   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-java  \\\n",
       "bm25s                                                                      0.550447   \n",
       "facebook__contriever                                                       0.327267   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                              0.439017   \n",
       "sentence-transformers__gtr-t5-base                                         0.428480   \n",
       "sentence-transformers__gtr-t5-large                                        0.535441   \n",
       "intfloat__e5-base-v2                                                       0.660600   \n",
       "intfloat__e5-large-v2                                                      0.472222   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                       0.305236   \n",
       "intfloat__e5-mistral-7b-instruct                                           0.554278   \n",
       "hkunlp__instructor-base                                                    0.409962   \n",
       "hkunlp__instructor-large                                                   0.358557   \n",
       "hkunlp__instructor-xl                                                      0.353448   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                       0.386654   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                     0.334930   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                            0.447318   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                 0.321201   \n",
       "openai__text-embedding-ada-002                                             0.321201   \n",
       "openai__text-embedding-3-small                                             0.363985   \n",
       "openai__text-embedding-3-large                                             0.472222   \n",
       "voyageai__voyage-code-2                                                    0.551405   \n",
       "voyageai__voyage-code-3                                                    0.645275   \n",
       "microsoft__codebert-base                                                   0.488186   \n",
       "microsoft__graphcodebert-base                                              0.401660   \n",
       "nomic-ai__CodeRankEmbed                                                    0.565453   \n",
       "local-repllama-llama31-8b-lora-64                                          0.320562   \n",
       "local-repllama-llama31-8b-lora-64-quality                                  0.908365   \n",
       "local-repllama-llama32-3b-lora-256                                         0.225734   \n",
       "local-repllama-llama32-3b-lora-256-quality                                 0.921775   \n",
       "codesage__codesage-small                                                   0.396232   \n",
       "codesage__codesage-base                                                    0.433908   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-javascript  \\\n",
       "bm25s                                                                            0.492656   \n",
       "facebook__contriever                                                             0.445083   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                    0.479885   \n",
       "sentence-transformers__gtr-t5-base                                               0.444125   \n",
       "sentence-transformers__gtr-t5-large                                              0.503512   \n",
       "intfloat__e5-base-v2                                                             0.534163   \n",
       "intfloat__e5-large-v2                                                            0.467752   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                             0.529693   \n",
       "intfloat__e5-mistral-7b-instruct                                                 0.522350   \n",
       "hkunlp__instructor-base                                                          0.458812   \n",
       "hkunlp__instructor-large                                                         0.483397   \n",
       "hkunlp__instructor-xl                                                            0.495849   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                             0.553001   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                           0.571520   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                                  0.574074   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                       0.572478   \n",
       "openai__text-embedding-ada-002                                                   0.580460   \n",
       "openai__text-embedding-3-small                                                   0.520754   \n",
       "openai__text-embedding-3-large                                                   0.528416   \n",
       "voyageai__voyage-code-2                                                          0.580460   \n",
       "voyageai__voyage-code-3                                                          0.591954   \n",
       "microsoft__codebert-base                                                         0.319604   \n",
       "microsoft__graphcodebert-base                                                    0.392720   \n",
       "nomic-ai__CodeRankEmbed                                                          0.485632   \n",
       "local-repllama-llama31-8b-lora-64                                                0.555556   \n",
       "local-repllama-llama31-8b-lora-64-quality                                        0.625160   \n",
       "local-repllama-llama32-3b-lora-256                                               0.521073   \n",
       "local-repllama-llama32-3b-lora-256-quality                                       0.625798   \n",
       "codesage__codesage-small                                                         0.538314   \n",
       "codesage__codesage-base                                                          0.540868   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-python  \\\n",
       "bm25s                                                                        0.428161   \n",
       "facebook__contriever                                                         0.437420   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                0.426245   \n",
       "sentence-transformers__gtr-t5-base                                           0.411239   \n",
       "sentence-transformers__gtr-t5-large                                          0.461367   \n",
       "intfloat__e5-base-v2                                                         0.475734   \n",
       "intfloat__e5-large-v2                                                        0.482759   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                         0.531609   \n",
       "intfloat__e5-mistral-7b-instruct                                             0.504789   \n",
       "hkunlp__instructor-base                                                      0.475734   \n",
       "hkunlp__instructor-large                                                     0.482439   \n",
       "hkunlp__instructor-xl                                                        0.460409   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                         0.507982   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                       0.506386   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                              0.502235   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                   0.498404   \n",
       "openai__text-embedding-ada-002                                               0.517241   \n",
       "openai__text-embedding-3-small                                               0.500958   \n",
       "openai__text-embedding-3-large                                               0.528736   \n",
       "voyageai__voyage-code-2                                                      0.542146   \n",
       "voyageai__voyage-code-3                                                      0.577905   \n",
       "microsoft__codebert-base                                                     0.286398   \n",
       "microsoft__graphcodebert-base                                                0.319604   \n",
       "nomic-ai__CodeRankEmbed                                                      0.418582   \n",
       "local-repllama-llama31-8b-lora-64                                            0.497126   \n",
       "local-repllama-llama31-8b-lora-64-quality                                    0.671137   \n",
       "local-repllama-llama32-3b-lora-256                                           0.483078   \n",
       "local-repllama-llama32-3b-lora-256-quality                                   0.674330   \n",
       "codesage__codesage-small                                                     0.521711   \n",
       "codesage__codesage-base                                                      0.546935   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-ruby  \\\n",
       "bm25s                                                                      0.449553   \n",
       "facebook__contriever                                                       0.440294   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                              0.429757   \n",
       "sentence-transformers__gtr-t5-base                                         0.409323   \n",
       "sentence-transformers__gtr-t5-large                                        0.477011   \n",
       "intfloat__e5-base-v2                                                       0.501916   \n",
       "intfloat__e5-large-v2                                                      0.496488   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                       0.505109   \n",
       "intfloat__e5-mistral-7b-instruct                                           0.490741   \n",
       "hkunlp__instructor-base                                                    0.473819   \n",
       "hkunlp__instructor-large                                                   0.480524   \n",
       "hkunlp__instructor-xl                                                      0.496807   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                       0.514049   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                     0.531609   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                            0.537037   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                 0.520434   \n",
       "openai__text-embedding-ada-002                                             0.553959   \n",
       "openai__text-embedding-3-small                                             0.535441   \n",
       "openai__text-embedding-3-large                                             0.556194   \n",
       "voyageai__voyage-code-2                                                    0.567688   \n",
       "voyageai__voyage-code-3                                                    0.625479   \n",
       "microsoft__codebert-base                                                   0.308110   \n",
       "microsoft__graphcodebert-base                                              0.358238   \n",
       "nomic-ai__CodeRankEmbed                                                    0.492656   \n",
       "local-repllama-llama31-8b-lora-64                                          0.543742   \n",
       "local-repllama-llama31-8b-lora-64-quality                                  0.660920   \n",
       "local-repllama-llama32-3b-lora-256                                         0.502554   \n",
       "local-repllama-llama32-3b-lora-256-quality                                 0.657727   \n",
       "codesage__codesage-small                                                   0.500000   \n",
       "codesage__codesage-base                                                    0.544061   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-rust  \\\n",
       "bm25s                                                                      0.477331   \n",
       "facebook__contriever                                                       0.441411   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                              0.390964   \n",
       "sentence-transformers__gtr-t5-base                                         0.409004   \n",
       "sentence-transformers__gtr-t5-large                                        0.410281   \n",
       "intfloat__e5-base-v2                                                       0.367178   \n",
       "intfloat__e5-large-v2                                                      0.338442   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                       0.371328   \n",
       "intfloat__e5-mistral-7b-instruct                                           0.441571   \n",
       "hkunlp__instructor-base                                                    0.303959   \n",
       "hkunlp__instructor-large                                                   0.279055   \n",
       "hkunlp__instructor-xl                                                      0.300926   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                       0.414432   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                     0.439017   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                            0.479566   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                 0.385217   \n",
       "openai__text-embedding-ada-002                                             0.472382   \n",
       "openai__text-embedding-3-small                                             0.433589   \n",
       "openai__text-embedding-3-large                                             0.536398   \n",
       "voyageai__voyage-code-2                                                    0.595785   \n",
       "voyageai__voyage-code-3                                                    0.629151   \n",
       "microsoft__codebert-base                                                   0.417625   \n",
       "microsoft__graphcodebert-base                                              0.436941   \n",
       "nomic-ai__CodeRankEmbed                                                    0.364943   \n",
       "local-repllama-llama31-8b-lora-64                                          0.458653   \n",
       "local-repllama-llama31-8b-lora-64-quality                                  0.695562   \n",
       "local-repllama-llama32-3b-lora-256                                         0.353129   \n",
       "local-repllama-llama32-3b-lora-256-quality                                 0.668103   \n",
       "codesage__codesage-small                                                   0.420658   \n",
       "codesage__codesage-base                                                    0.430556   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-swift  \\\n",
       "bm25s                                                                       0.433509   \n",
       "facebook__contriever                                                        0.426165   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                               0.457375   \n",
       "sentence-transformers__gtr-t5-base                                          0.373164   \n",
       "sentence-transformers__gtr-t5-large                                         0.439017   \n",
       "intfloat__e5-base-v2                                                        0.457216   \n",
       "intfloat__e5-large-v2                                                       0.481003   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                        0.461606   \n",
       "intfloat__e5-mistral-7b-instruct                                            0.505268   \n",
       "hkunlp__instructor-base                                                     0.433589   \n",
       "hkunlp__instructor-large                                                    0.464480   \n",
       "hkunlp__instructor-xl                                                       0.479087   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                        0.474457   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                      0.483078   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                             0.520594   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                  0.499840   \n",
       "openai__text-embedding-ada-002                                              0.517082   \n",
       "openai__text-embedding-3-small                                              0.488745   \n",
       "openai__text-embedding-3-large                                              0.511414   \n",
       "voyageai__voyage-code-2                                                     0.555635   \n",
       "voyageai__voyage-code-3                                                     0.563617   \n",
       "microsoft__codebert-base                                                    0.299330   \n",
       "microsoft__graphcodebert-base                                               0.353289   \n",
       "nomic-ai__CodeRankEmbed                                                     0.417225   \n",
       "local-repllama-llama31-8b-lora-64                                           0.500958   \n",
       "local-repllama-llama31-8b-lora-64-quality                                   0.570482   \n",
       "local-repllama-llama32-3b-lora-256                                          0.408924   \n",
       "local-repllama-llama32-3b-lora-256-quality                                  0.541347   \n",
       "codesage__codesage-small                                                    0.482998   \n",
       "codesage__codesage-base                                                     0.516603   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-typescript  \\\n",
       "bm25s                                                                            0.454342   \n",
       "facebook__contriever                                                             0.428081   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                    0.448835   \n",
       "sentence-transformers__gtr-t5-base                                               0.425607   \n",
       "sentence-transformers__gtr-t5-large                                              0.453624   \n",
       "intfloat__e5-base-v2                                                             0.495929   \n",
       "intfloat__e5-large-v2                                                            0.503193   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                             0.526980   \n",
       "intfloat__e5-mistral-7b-instruct                                                 0.539272   \n",
       "hkunlp__instructor-base                                                          0.446839   \n",
       "hkunlp__instructor-large                                                         0.497206   \n",
       "hkunlp__instructor-xl                                                            0.483716   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                             0.540070   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                           0.539591   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                                  0.562500   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                       0.527139   \n",
       "openai__text-embedding-ada-002                                                   0.561622   \n",
       "openai__text-embedding-3-small                                                   0.513809   \n",
       "openai__text-embedding-3-large                                                   0.569205   \n",
       "voyageai__voyage-code-2                                                          0.580061   \n",
       "voyageai__voyage-code-3                                                          0.593790   \n",
       "microsoft__codebert-base                                                         0.359435   \n",
       "microsoft__graphcodebert-base                                                    0.411079   \n",
       "nomic-ai__CodeRankEmbed                                                          0.484754   \n",
       "local-repllama-llama31-8b-lora-64                                                0.557870   \n",
       "local-repllama-llama31-8b-lora-64-quality                                        0.588442   \n",
       "local-repllama-llama32-3b-lora-256                                               0.527219   \n",
       "local-repllama-llama32-3b-lora-256-quality                                       0.588602   \n",
       "codesage__codesage-small                                                         0.492497   \n",
       "codesage__codesage-base                                                          0.532088   \n",
       "\n",
       "                                                 ...  \\\n",
       "bm25s                                            ...   \n",
       "facebook__contriever                             ...   \n",
       "Alibaba-NLP__gte-base-en-v1.5                    ...   \n",
       "sentence-transformers__gtr-t5-base               ...   \n",
       "sentence-transformers__gtr-t5-large              ...   \n",
       "intfloat__e5-base-v2                             ...   \n",
       "intfloat__e5-large-v2                            ...   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct             ...   \n",
       "intfloat__e5-mistral-7b-instruct                 ...   \n",
       "hkunlp__instructor-base                          ...   \n",
       "hkunlp__instructor-large                         ...   \n",
       "hkunlp__instructor-xl                            ...   \n",
       "samaya-ai__promptriever-llama2-7b-v1             ...   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1           ...   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1  ...   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1       ...   \n",
       "openai__text-embedding-ada-002                   ...   \n",
       "openai__text-embedding-3-small                   ...   \n",
       "openai__text-embedding-3-large                   ...   \n",
       "voyageai__voyage-code-2                          ...   \n",
       "voyageai__voyage-code-3                          ...   \n",
       "microsoft__codebert-base                         ...   \n",
       "microsoft__graphcodebert-base                    ...   \n",
       "nomic-ai__CodeRankEmbed                          ...   \n",
       "local-repllama-llama31-8b-lora-64                ...   \n",
       "local-repllama-llama31-8b-lora-64-quality        ...   \n",
       "local-repllama-llama32-3b-lora-256               ...   \n",
       "local-repllama-llama32-3b-lora-256-quality       ...   \n",
       "codesage__codesage-small                         ...   \n",
       "codesage__codesage-base                          ...   \n",
       "\n",
       "                                                 DeprecatedCodePreferenceRetrieval  \\\n",
       "bm25s                                                                     0.177335   \n",
       "facebook__contriever                                                      0.473865   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.506067   \n",
       "sentence-transformers__gtr-t5-base                                        0.474838   \n",
       "sentence-transformers__gtr-t5-large                                       0.467169   \n",
       "intfloat__e5-base-v2                                                      0.479891   \n",
       "intfloat__e5-large-v2                                                     0.467820   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.468762   \n",
       "intfloat__e5-mistral-7b-instruct                                          0.524875   \n",
       "hkunlp__instructor-base                                                   0.490619   \n",
       "hkunlp__instructor-large                                                  0.499850   \n",
       "hkunlp__instructor-xl                                                     0.475088   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.518630   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.553417   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           0.545447   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.512973   \n",
       "openai__text-embedding-ada-002                                            0.511178   \n",
       "openai__text-embedding-3-small                                            0.520049   \n",
       "openai__text-embedding-3-large                                            0.533620   \n",
       "voyageai__voyage-code-2                                                   0.494402   \n",
       "voyageai__voyage-code-3                                                   0.573364   \n",
       "microsoft__codebert-base                                                  0.191906   \n",
       "microsoft__graphcodebert-base                                             0.282865   \n",
       "nomic-ai__CodeRankEmbed                                                   0.524456   \n",
       "local-repllama-llama31-8b-lora-64                                         0.541780   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.720812   \n",
       "local-repllama-llama32-3b-lora-256                                        0.553844   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.664861   \n",
       "codesage__codesage-small                                                  0.532258   \n",
       "codesage__codesage-base                                                   0.507169   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-c  \\\n",
       "bm25s                                                                  0.318072   \n",
       "facebook__contriever                                                   0.383133   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                          0.484337   \n",
       "sentence-transformers__gtr-t5-base                                     0.573494   \n",
       "sentence-transformers__gtr-t5-large                                    0.607229   \n",
       "intfloat__e5-base-v2                                                   0.638554   \n",
       "intfloat__e5-large-v2                                                  0.626506   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                   0.628916   \n",
       "intfloat__e5-mistral-7b-instruct                                       0.633735   \n",
       "hkunlp__instructor-base                                                0.556627   \n",
       "hkunlp__instructor-large                                               0.573494   \n",
       "hkunlp__instructor-xl                                                  0.595181   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                   0.614458   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                 0.563855   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                        0.600000   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                             0.575904   \n",
       "openai__text-embedding-ada-002                                         0.481928   \n",
       "openai__text-embedding-3-small                                         0.448193   \n",
       "openai__text-embedding-3-large                                         0.479518   \n",
       "voyageai__voyage-code-2                                                0.479518   \n",
       "voyageai__voyage-code-3                                                0.532530   \n",
       "microsoft__codebert-base                                               0.508434   \n",
       "microsoft__graphcodebert-base                                          0.532530   \n",
       "nomic-ai__CodeRankEmbed                                                0.387952   \n",
       "local-repllama-llama31-8b-lora-64                                      0.542169   \n",
       "local-repllama-llama31-8b-lora-64-quality                              0.590361   \n",
       "local-repllama-llama32-3b-lora-256                                     0.527711   \n",
       "local-repllama-llama32-3b-lora-256-quality                             0.595181   \n",
       "codesage__codesage-small                                               0.525301   \n",
       "codesage__codesage-base                                                0.532530   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-cpp  \\\n",
       "bm25s                                                                    0.533333   \n",
       "facebook__contriever                                                     0.450000   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                            0.383333   \n",
       "sentence-transformers__gtr-t5-base                                       0.433333   \n",
       "sentence-transformers__gtr-t5-large                                      0.416667   \n",
       "intfloat__e5-base-v2                                                     0.583333   \n",
       "intfloat__e5-large-v2                                                    0.600000   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                     0.500000   \n",
       "intfloat__e5-mistral-7b-instruct                                         0.500000   \n",
       "hkunlp__instructor-base                                                  0.483333   \n",
       "hkunlp__instructor-large                                                 0.366667   \n",
       "hkunlp__instructor-xl                                                    0.466667   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                     0.616667   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                   0.616667   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                          0.666667   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                               0.500000   \n",
       "openai__text-embedding-ada-002                                           0.466667   \n",
       "openai__text-embedding-3-small                                           0.450000   \n",
       "openai__text-embedding-3-large                                           0.500000   \n",
       "voyageai__voyage-code-2                                                  0.483333   \n",
       "voyageai__voyage-code-3                                                  0.600000   \n",
       "microsoft__codebert-base                                                 0.516667   \n",
       "microsoft__graphcodebert-base                                            0.616667   \n",
       "nomic-ai__CodeRankEmbed                                                  0.433333   \n",
       "local-repllama-llama31-8b-lora-64                                        0.616667   \n",
       "local-repllama-llama31-8b-lora-64-quality                                0.550000   \n",
       "local-repllama-llama32-3b-lora-256                                       0.566667   \n",
       "local-repllama-llama32-3b-lora-256-quality                               0.650000   \n",
       "codesage__codesage-small                                                 0.516667   \n",
       "codesage__codesage-base                                                  0.483333   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-python  \\\n",
       "bm25s                                                                       0.585551   \n",
       "facebook__contriever                                                        0.456274   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                               0.477186   \n",
       "sentence-transformers__gtr-t5-base                                          0.465779   \n",
       "sentence-transformers__gtr-t5-large                                         0.545627   \n",
       "intfloat__e5-base-v2                                                        0.480989   \n",
       "intfloat__e5-large-v2                                                       0.500000   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                        0.551331   \n",
       "intfloat__e5-mistral-7b-instruct                                            0.528517   \n",
       "hkunlp__instructor-base                                                     0.477186   \n",
       "hkunlp__instructor-large                                                    0.557034   \n",
       "hkunlp__instructor-xl                                                       0.484791   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                        0.482890   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                      0.452471   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                             0.500000   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                  0.467681   \n",
       "openai__text-embedding-ada-002                                              0.522814   \n",
       "openai__text-embedding-3-small                                              0.475285   \n",
       "openai__text-embedding-3-large                                              0.461977   \n",
       "voyageai__voyage-code-2                                                     0.543726   \n",
       "voyageai__voyage-code-3                                                     0.593156   \n",
       "microsoft__codebert-base                                                    0.568441   \n",
       "microsoft__graphcodebert-base                                               0.513308   \n",
       "nomic-ai__CodeRankEmbed                                                     0.460076   \n",
       "local-repllama-llama31-8b-lora-64                                           0.448669   \n",
       "local-repllama-llama31-8b-lora-64-quality                                   0.825095   \n",
       "local-repllama-llama32-3b-lora-256                                          0.450570   \n",
       "local-repllama-llama32-3b-lora-256-quality                                  0.815589   \n",
       "codesage__codesage-small                                                    0.513308   \n",
       "codesage__codesage-base                                                     0.490494   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-java  \\\n",
       "bm25s                                                                     0.500000   \n",
       "facebook__contriever                                                      0.307692   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.500000   \n",
       "sentence-transformers__gtr-t5-base                                        0.461538   \n",
       "sentence-transformers__gtr-t5-large                                       0.346154   \n",
       "intfloat__e5-base-v2                                                      0.384615   \n",
       "intfloat__e5-large-v2                                                     0.384615   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.384615   \n",
       "intfloat__e5-mistral-7b-instruct                                          0.500000   \n",
       "hkunlp__instructor-base                                                   0.461538   \n",
       "hkunlp__instructor-large                                                  0.500000   \n",
       "hkunlp__instructor-xl                                                     0.346154   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.615385   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.461538   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           0.423077   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.461538   \n",
       "openai__text-embedding-ada-002                                            0.576923   \n",
       "openai__text-embedding-3-small                                            0.538462   \n",
       "openai__text-embedding-3-large                                            0.576923   \n",
       "voyageai__voyage-code-2                                                   0.615385   \n",
       "voyageai__voyage-code-3                                                   0.769231   \n",
       "microsoft__codebert-base                                                  0.500000   \n",
       "microsoft__graphcodebert-base                                             0.423077   \n",
       "nomic-ai__CodeRankEmbed                                                   0.230769   \n",
       "local-repllama-llama31-8b-lora-64                                         0.346154   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.807692   \n",
       "local-repllama-llama32-3b-lora-256                                        0.500000   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.730769   \n",
       "codesage__codesage-small                                                  0.538462   \n",
       "codesage__codesage-base                                                   0.538462   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-javascript  \\\n",
       "bm25s                                                                           0.477876   \n",
       "facebook__contriever                                                            0.380531   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                   0.469027   \n",
       "sentence-transformers__gtr-t5-base                                              0.433628   \n",
       "sentence-transformers__gtr-t5-large                                             0.451327   \n",
       "intfloat__e5-base-v2                                                            0.469027   \n",
       "intfloat__e5-large-v2                                                           0.433628   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                            0.460177   \n",
       "intfloat__e5-mistral-7b-instruct                                                0.477876   \n",
       "hkunlp__instructor-base                                                         0.442478   \n",
       "hkunlp__instructor-large                                                        0.424779   \n",
       "hkunlp__instructor-xl                                                           0.389381   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                            0.460177   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                          0.539823   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                                 0.486726   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                      0.460177   \n",
       "openai__text-embedding-ada-002                                                  0.460177   \n",
       "openai__text-embedding-3-small                                                  0.513274   \n",
       "openai__text-embedding-3-large                                                  0.566372   \n",
       "voyageai__voyage-code-2                                                         0.486726   \n",
       "voyageai__voyage-code-3                                                         0.610619   \n",
       "microsoft__codebert-base                                                        0.548673   \n",
       "microsoft__graphcodebert-base                                                   0.530973   \n",
       "nomic-ai__CodeRankEmbed                                                         0.433628   \n",
       "local-repllama-llama31-8b-lora-64                                               0.504425   \n",
       "local-repllama-llama31-8b-lora-64-quality                                       0.761062   \n",
       "local-repllama-llama32-3b-lora-256                                              0.442478   \n",
       "local-repllama-llama32-3b-lora-256-quality                                      0.734513   \n",
       "codesage__codesage-small                                                        0.566372   \n",
       "codesage__codesage-base                                                         0.548673   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-go  \\\n",
       "bm25s                                                                   0.622222   \n",
       "facebook__contriever                                                    0.466667   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                           0.488889   \n",
       "sentence-transformers__gtr-t5-base                                      0.666667   \n",
       "sentence-transformers__gtr-t5-large                                     0.600000   \n",
       "intfloat__e5-base-v2                                                    0.600000   \n",
       "intfloat__e5-large-v2                                                   0.555556   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                    0.555556   \n",
       "intfloat__e5-mistral-7b-instruct                                        0.444444   \n",
       "hkunlp__instructor-base                                                 0.533333   \n",
       "hkunlp__instructor-large                                                0.533333   \n",
       "hkunlp__instructor-xl                                                   0.555556   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                    0.444444   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                  0.466667   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                         0.533333   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                              0.600000   \n",
       "openai__text-embedding-ada-002                                          0.533333   \n",
       "openai__text-embedding-3-small                                          0.533333   \n",
       "openai__text-embedding-3-large                                          0.555556   \n",
       "voyageai__voyage-code-2                                                 0.466667   \n",
       "voyageai__voyage-code-3                                                 0.555556   \n",
       "microsoft__codebert-base                                                0.555556   \n",
       "microsoft__graphcodebert-base                                           0.622222   \n",
       "nomic-ai__CodeRankEmbed                                                 0.466667   \n",
       "local-repllama-llama31-8b-lora-64                                       0.644444   \n",
       "local-repllama-llama31-8b-lora-64-quality                               0.800000   \n",
       "local-repllama-llama32-3b-lora-256                                      0.511111   \n",
       "local-repllama-llama32-3b-lora-256-quality                              0.711111   \n",
       "codesage__codesage-small                                                0.533333   \n",
       "codesage__codesage-base                                                 0.466667   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-ruby  \\\n",
       "bm25s                                                                     0.500000   \n",
       "facebook__contriever                                                      0.426829   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.536585   \n",
       "sentence-transformers__gtr-t5-base                                        0.439024   \n",
       "sentence-transformers__gtr-t5-large                                       0.451220   \n",
       "intfloat__e5-base-v2                                                      0.536585   \n",
       "intfloat__e5-large-v2                                                     0.512195   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.536585   \n",
       "intfloat__e5-mistral-7b-instruct                                          0.439024   \n",
       "hkunlp__instructor-base                                                   0.512195   \n",
       "hkunlp__instructor-large                                                  0.512195   \n",
       "hkunlp__instructor-xl                                                     0.487805   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.524390   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.536585   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           0.402439   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.487805   \n",
       "openai__text-embedding-ada-002                                            0.390244   \n",
       "openai__text-embedding-3-small                                            0.560976   \n",
       "openai__text-embedding-3-large                                            0.390244   \n",
       "voyageai__voyage-code-2                                                   0.560976   \n",
       "voyageai__voyage-code-3                                                   0.573171   \n",
       "microsoft__codebert-base                                                  0.475610   \n",
       "microsoft__graphcodebert-base                                             0.585366   \n",
       "nomic-ai__CodeRankEmbed                                                   0.524390   \n",
       "local-repllama-llama31-8b-lora-64                                         0.475610   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.780488   \n",
       "local-repllama-llama32-3b-lora-256                                        0.475610   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.817073   \n",
       "codesage__codesage-small                                                  0.487805   \n",
       "codesage__codesage-base                                                   0.451220   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval  \\\n",
       "bm25s                                                                0.505294   \n",
       "facebook__contriever                                                 0.410161   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                        0.477051   \n",
       "sentence-transformers__gtr-t5-base                                   0.496209   \n",
       "sentence-transformers__gtr-t5-large                                  0.488318   \n",
       "intfloat__e5-base-v2                                                 0.527586   \n",
       "intfloat__e5-large-v2                                                0.516071   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                 0.516740   \n",
       "intfloat__e5-mistral-7b-instruct                                     0.503371   \n",
       "hkunlp__instructor-base                                              0.495242   \n",
       "hkunlp__instructor-large                                             0.495357   \n",
       "hkunlp__instructor-xl                                                0.475076   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                 0.536916   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                               0.519658   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                      0.516035   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                           0.507586   \n",
       "openai__text-embedding-ada-002                                       0.490298   \n",
       "openai__text-embedding-3-small                                       0.502789   \n",
       "openai__text-embedding-3-large                                       0.504370   \n",
       "voyageai__voyage-code-2                                              0.519476   \n",
       "voyageai__voyage-code-3                                              0.604895   \n",
       "microsoft__codebert-base                                             0.524768   \n",
       "microsoft__graphcodebert-base                                        0.546306   \n",
       "nomic-ai__CodeRankEmbed                                              0.419545   \n",
       "local-repllama-llama31-8b-lora-64                                    0.511162   \n",
       "local-repllama-llama31-8b-lora-64-quality                            0.730671   \n",
       "local-repllama-llama32-3b-lora-256                                   0.496307   \n",
       "local-repllama-llama32-3b-lora-256-quality                           0.722034   \n",
       "codesage__codesage-small                                             0.525892   \n",
       "codesage__codesage-base                                              0.501625   \n",
       "\n",
       "                                                 SQLR2PreferenceRetrieval  \n",
       "bm25s                                                            0.698311  \n",
       "facebook__contriever                                             0.593825  \n",
       "Alibaba-NLP__gte-base-en-v1.5                                    0.603781  \n",
       "sentence-transformers__gtr-t5-base                               0.649839  \n",
       "sentence-transformers__gtr-t5-large                              0.681315  \n",
       "intfloat__e5-base-v2                                             0.695093  \n",
       "intfloat__e5-large-v2                                            0.730491  \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                             0.711484  \n",
       "intfloat__e5-mistral-7b-instruct                                 0.735318  \n",
       "hkunlp__instructor-base                                          0.713998  \n",
       "hkunlp__instructor-large                                         0.701227  \n",
       "hkunlp__instructor-xl                                            0.731798  \n",
       "samaya-ai__promptriever-llama2-7b-v1                             0.819690  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                           0.795253  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                  0.826529  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                       0.813355  \n",
       "openai__text-embedding-ada-002                                   0.755531  \n",
       "openai__text-embedding-3-small                                   0.715607  \n",
       "openai__text-embedding-3-large                                   0.739541  \n",
       "voyageai__voyage-code-2                                          0.723753  \n",
       "voyageai__voyage-code-3                                          0.688455  \n",
       "microsoft__codebert-base                                         0.107200  \n",
       "microsoft__graphcodebert-base                                    0.259151  \n",
       "nomic-ai__CodeRankEmbed                                          0.775442  \n",
       "local-repllama-llama31-8b-lora-64                                0.798069  \n",
       "local-repllama-llama31-8b-lora-64-quality                        0.742056  \n",
       "local-repllama-llama32-3b-lora-256                               0.805209  \n",
       "local-repllama-llama32-3b-lora-256-quality                       0.704043  \n",
       "codesage__codesage-small                                         0.597647  \n",
       "codesage__codesage-base                                          0.607401  \n",
       "\n",
       "[30 rows x 47 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d36718f6-f8fa-4ffe-b8f4-ba1115611760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-c</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-cpp</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-go</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-java</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-javascript</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-python</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-ruby</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-rust</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-swift</th>\n",
       "      <th>CodeNetBugPreferenceRetrieval-typescript</th>\n",
       "      <th>...</th>\n",
       "      <th>DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th>SaferCodePreferenceRetrieval-c</th>\n",
       "      <th>SaferCodePreferenceRetrieval-cpp</th>\n",
       "      <th>SaferCodePreferenceRetrieval-python</th>\n",
       "      <th>SaferCodePreferenceRetrieval-java</th>\n",
       "      <th>SaferCodePreferenceRetrieval-javascript</th>\n",
       "      <th>SaferCodePreferenceRetrieval-go</th>\n",
       "      <th>SaferCodePreferenceRetrieval-ruby</th>\n",
       "      <th>SaferCodePreferenceRetrieval</th>\n",
       "      <th>SQLR2PreferenceRetrieval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bm25s</th>\n",
       "      <td>-0.002919</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>-0.003668</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>-0.001084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019841</td>\n",
       "      <td>-0.096946</td>\n",
       "      <td>0.027103</td>\n",
       "      <td>0.054320</td>\n",
       "      <td>-0.058136</td>\n",
       "      <td>-0.004915</td>\n",
       "      <td>0.049174</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>-0.016983</td>\n",
       "      <td>0.217158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook__contriever</th>\n",
       "      <td>0.002186</td>\n",
       "      <td>-0.012131</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-0.006725</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>-0.008630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>-0.071245</td>\n",
       "      <td>-0.034089</td>\n",
       "      <td>-0.204822</td>\n",
       "      <td>-0.075825</td>\n",
       "      <td>-0.066463</td>\n",
       "      <td>-0.017507</td>\n",
       "      <td>-0.010169</td>\n",
       "      <td>0.080737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-base-en-v1.5</th>\n",
       "      <td>-0.008158</td>\n",
       "      <td>-0.010288</td>\n",
       "      <td>-0.006254</td>\n",
       "      <td>-0.012888</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>-0.001345</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>-0.023081</td>\n",
       "      <td>-0.129503</td>\n",
       "      <td>-0.025942</td>\n",
       "      <td>-0.028601</td>\n",
       "      <td>-0.023205</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>0.043305</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.065668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-base</th>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>-0.010511</td>\n",
       "      <td>-0.004831</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>-0.008854</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.064598</td>\n",
       "      <td>-0.083612</td>\n",
       "      <td>-0.024438</td>\n",
       "      <td>-0.095589</td>\n",
       "      <td>-0.039694</td>\n",
       "      <td>0.169179</td>\n",
       "      <td>-0.070909</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.035975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-transformers__gtr-t5-large</th>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.020296</td>\n",
       "      <td>-0.020596</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>-0.014564</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>-0.010922</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.083239</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>-0.164161</td>\n",
       "      <td>-0.052511</td>\n",
       "      <td>0.127963</td>\n",
       "      <td>-0.039933</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.048570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-base-v2</th>\n",
       "      <td>0.003085</td>\n",
       "      <td>-0.012237</td>\n",
       "      <td>-0.019240</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.028326</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>-0.011941</td>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>0.123194</td>\n",
       "      <td>0.081389</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>-0.125321</td>\n",
       "      <td>-0.045834</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>0.016638</td>\n",
       "      <td>0.271137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-large-v2</th>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.026434</td>\n",
       "      <td>-0.012663</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>-0.009282</td>\n",
       "      <td>-0.027497</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>-0.001469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.115895</td>\n",
       "      <td>0.085556</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>-0.132508</td>\n",
       "      <td>-0.058784</td>\n",
       "      <td>0.040344</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.235500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP__gte-Qwen2-1.5B-instruct</th>\n",
       "      <td>-0.011842</td>\n",
       "      <td>-0.039221</td>\n",
       "      <td>-0.011362</td>\n",
       "      <td>-0.063745</td>\n",
       "      <td>0.027574</td>\n",
       "      <td>0.029050</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>-0.039837</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018533</td>\n",
       "      <td>0.121807</td>\n",
       "      <td>-0.004722</td>\n",
       "      <td>0.054292</td>\n",
       "      <td>-0.151877</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.087614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat__e5-mistral-7b-instruct</th>\n",
       "      <td>-0.017348</td>\n",
       "      <td>-0.030190</td>\n",
       "      <td>-0.002506</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>0.052003</td>\n",
       "      <td>-0.013993</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>0.047450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.127216</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>-0.040216</td>\n",
       "      <td>-0.053704</td>\n",
       "      <td>-0.048801</td>\n",
       "      <td>0.022714</td>\n",
       "      <td>0.154830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base</th>\n",
       "      <td>-0.008103</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>-0.009735</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>-0.003972</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>-0.006903</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.043094</td>\n",
       "      <td>-0.039491</td>\n",
       "      <td>-0.019073</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>-0.059155</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>-0.008613</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.080215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large</th>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>-0.013166</td>\n",
       "      <td>-0.038203</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>-0.018154</td>\n",
       "      <td>-0.003203</td>\n",
       "      <td>-0.019264</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>-0.004985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>-0.137202</td>\n",
       "      <td>0.060634</td>\n",
       "      <td>-0.026987</td>\n",
       "      <td>-0.065600</td>\n",
       "      <td>0.056710</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>0.126380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.032339</td>\n",
       "      <td>-0.014542</td>\n",
       "      <td>-0.026334</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>-0.004379</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>-0.017566</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>-0.012769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>-0.031944</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>-0.131303</td>\n",
       "      <td>-0.093953</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.151370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1</th>\n",
       "      <td>-0.017693</td>\n",
       "      <td>-0.021886</td>\n",
       "      <td>-0.007430</td>\n",
       "      <td>-0.031798</td>\n",
       "      <td>0.056289</td>\n",
       "      <td>-0.006715</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>-0.001746</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.036771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035403</td>\n",
       "      <td>0.113851</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.014904</td>\n",
       "      <td>0.090751</td>\n",
       "      <td>-0.036202</td>\n",
       "      <td>-0.018122</td>\n",
       "      <td>0.035163</td>\n",
       "      <td>0.036228</td>\n",
       "      <td>0.237587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1</th>\n",
       "      <td>0.003712</td>\n",
       "      <td>-0.017108</td>\n",
       "      <td>-0.016352</td>\n",
       "      <td>-0.109216</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>0.059847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>0.056939</td>\n",
       "      <td>0.106944</td>\n",
       "      <td>-0.041131</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.039619</td>\n",
       "      <td>-0.068519</td>\n",
       "      <td>0.050407</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.229442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1</th>\n",
       "      <td>0.008216</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>-0.002082</td>\n",
       "      <td>-0.050030</td>\n",
       "      <td>0.079033</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.026929</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042045</td>\n",
       "      <td>0.095778</td>\n",
       "      <td>0.165278</td>\n",
       "      <td>-0.003674</td>\n",
       "      <td>-0.067308</td>\n",
       "      <td>-0.021251</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>-0.075203</td>\n",
       "      <td>0.037466</td>\n",
       "      <td>0.300318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1</th>\n",
       "      <td>-0.009440</td>\n",
       "      <td>-0.030088</td>\n",
       "      <td>-0.024374</td>\n",
       "      <td>-0.103169</td>\n",
       "      <td>0.077564</td>\n",
       "      <td>-0.010083</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>-0.019627</td>\n",
       "      <td>0.047133</td>\n",
       "      <td>0.039738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>0.073512</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>-0.029886</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-0.040792</td>\n",
       "      <td>0.088175</td>\n",
       "      <td>-0.014010</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>0.233568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-ada-002</th>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.029551</td>\n",
       "      <td>-0.028007</td>\n",
       "      <td>-0.130648</td>\n",
       "      <td>0.067125</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>-0.009209</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.055146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025071</td>\n",
       "      <td>-0.021124</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.068758</td>\n",
       "      <td>-0.029884</td>\n",
       "      <td>0.045370</td>\n",
       "      <td>-0.110366</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.225891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-small</th>\n",
       "      <td>-0.015352</td>\n",
       "      <td>0.017449</td>\n",
       "      <td>-0.026812</td>\n",
       "      <td>-0.074787</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>-0.004741</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>-0.002148</td>\n",
       "      <td>-0.007447</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>-0.047367</td>\n",
       "      <td>-0.054722</td>\n",
       "      <td>-0.023282</td>\n",
       "      <td>0.068573</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.040397</td>\n",
       "      <td>0.079636</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>0.186433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai__text-embedding-3-large</th>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>-0.017097</td>\n",
       "      <td>-0.041284</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.008689</td>\n",
       "      <td>0.023975</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.051149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>-0.020364</td>\n",
       "      <td>-0.001389</td>\n",
       "      <td>-0.033235</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>0.069248</td>\n",
       "      <td>0.057407</td>\n",
       "      <td>-0.116978</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.232123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-2</th>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.062451</td>\n",
       "      <td>0.080080</td>\n",
       "      <td>0.028837</td>\n",
       "      <td>0.047671</td>\n",
       "      <td>0.095715</td>\n",
       "      <td>0.068329</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047801</td>\n",
       "      <td>-0.009247</td>\n",
       "      <td>-0.019443</td>\n",
       "      <td>0.037114</td>\n",
       "      <td>0.071154</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-0.024259</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.042637</td>\n",
       "      <td>0.237849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyageai__voyage-code-3</th>\n",
       "      <td>0.082010</td>\n",
       "      <td>0.071781</td>\n",
       "      <td>0.081736</td>\n",
       "      <td>0.141653</td>\n",
       "      <td>0.096440</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.115555</td>\n",
       "      <td>0.132532</td>\n",
       "      <td>0.073435</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080090</td>\n",
       "      <td>0.032932</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.085909</td>\n",
       "      <td>0.235897</td>\n",
       "      <td>0.118928</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.083435</td>\n",
       "      <td>0.083564</td>\n",
       "      <td>0.208566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__codebert-base</th>\n",
       "      <td>0.001530</td>\n",
       "      <td>-0.002863</td>\n",
       "      <td>-0.003975</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.002912</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.028048</td>\n",
       "      <td>-0.017190</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft__graphcodebert-base</th>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>0.086962</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>-0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai__CodeRankEmbed</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>-0.015875</td>\n",
       "      <td>-0.008178</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-0.022013</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>-0.028045</td>\n",
       "      <td>-0.009038</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025899</td>\n",
       "      <td>-0.084756</td>\n",
       "      <td>-0.064977</td>\n",
       "      <td>-0.042790</td>\n",
       "      <td>-0.196237</td>\n",
       "      <td>-0.066862</td>\n",
       "      <td>-0.039822</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.283637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64</th>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-0.011353</td>\n",
       "      <td>-0.087916</td>\n",
       "      <td>0.057897</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.029978</td>\n",
       "      <td>0.062426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037369</td>\n",
       "      <td>0.042806</td>\n",
       "      <td>0.113889</td>\n",
       "      <td>-0.048132</td>\n",
       "      <td>-0.152396</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.026515</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>0.239974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama31-8b-lora-64-quality</th>\n",
       "      <td>0.107261</td>\n",
       "      <td>0.131704</td>\n",
       "      <td>0.116017</td>\n",
       "      <td>0.251947</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>0.124625</td>\n",
       "      <td>0.102598</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>0.066899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133384</td>\n",
       "      <td>0.094334</td>\n",
       "      <td>0.031508</td>\n",
       "      <td>0.340473</td>\n",
       "      <td>0.175061</td>\n",
       "      <td>0.258228</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.292330</td>\n",
       "      <td>0.145644</td>\n",
       "      <td>0.163966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256</th>\n",
       "      <td>-0.001838</td>\n",
       "      <td>-0.016183</td>\n",
       "      <td>-0.001296</td>\n",
       "      <td>-0.075138</td>\n",
       "      <td>0.081545</td>\n",
       "      <td>0.032394</td>\n",
       "      <td>0.043468</td>\n",
       "      <td>-0.017307</td>\n",
       "      <td>0.026350</td>\n",
       "      <td>0.052934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>-0.045239</td>\n",
       "      <td>-0.069063</td>\n",
       "      <td>-0.056620</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>-0.016023</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.259253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local-repllama-llama32-3b-lora-256-quality</th>\n",
       "      <td>0.064927</td>\n",
       "      <td>0.092473</td>\n",
       "      <td>0.103904</td>\n",
       "      <td>0.194133</td>\n",
       "      <td>0.058135</td>\n",
       "      <td>0.108730</td>\n",
       "      <td>0.080703</td>\n",
       "      <td>0.070076</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.049604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095975</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>0.132778</td>\n",
       "      <td>0.349840</td>\n",
       "      <td>0.163235</td>\n",
       "      <td>0.213493</td>\n",
       "      <td>0.210679</td>\n",
       "      <td>0.227352</td>\n",
       "      <td>0.113150</td>\n",
       "      <td>0.148587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-small</th>\n",
       "      <td>0.003357</td>\n",
       "      <td>-0.001475</td>\n",
       "      <td>-0.021474</td>\n",
       "      <td>-0.034125</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>-0.014773</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.014877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.028548</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.053023</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>-0.003320</td>\n",
       "      <td>0.021684</td>\n",
       "      <td>0.047267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codesage__codesage-base</th>\n",
       "      <td>-0.003247</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>-0.034263</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.035935</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>0.015724</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.029716</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.036719</td>\n",
       "      <td>0.038717</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.043061</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.095636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CodeNetBugPreferenceRetrieval-c  \\\n",
       "bm25s                                                                  -0.002919   \n",
       "facebook__contriever                                                    0.002186   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                          -0.008158   \n",
       "sentence-transformers__gtr-t5-base                                      0.000786   \n",
       "sentence-transformers__gtr-t5-large                                    -0.000032   \n",
       "intfloat__e5-base-v2                                                    0.003085   \n",
       "intfloat__e5-large-v2                                                   0.007445   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                   -0.011842   \n",
       "intfloat__e5-mistral-7b-instruct                                       -0.017348   \n",
       "hkunlp__instructor-base                                                -0.008103   \n",
       "hkunlp__instructor-large                                                0.013482   \n",
       "hkunlp__instructor-xl                                                   0.000241   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                   -0.017693   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                  0.003712   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                         0.008216   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                             -0.009440   \n",
       "openai__text-embedding-ada-002                                          0.015771   \n",
       "openai__text-embedding-3-small                                         -0.015352   \n",
       "openai__text-embedding-3-large                                          0.014825   \n",
       "voyageai__voyage-code-2                                                 0.035885   \n",
       "voyageai__voyage-code-3                                                 0.082010   \n",
       "microsoft__codebert-base                                                0.001530   \n",
       "microsoft__graphcodebert-base                                           0.003436   \n",
       "nomic-ai__CodeRankEmbed                                                 0.001999   \n",
       "local-repllama-llama31-8b-lora-64                                       0.002772   \n",
       "local-repllama-llama31-8b-lora-64-quality                               0.107261   \n",
       "local-repllama-llama32-3b-lora-256                                     -0.001838   \n",
       "local-repllama-llama32-3b-lora-256-quality                              0.064927   \n",
       "codesage__codesage-small                                                0.003357   \n",
       "codesage__codesage-base                                                -0.003247   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-cpp  \\\n",
       "bm25s                                                                     0.002914   \n",
       "facebook__contriever                                                     -0.012131   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                            -0.010288   \n",
       "sentence-transformers__gtr-t5-base                                        0.000958   \n",
       "sentence-transformers__gtr-t5-large                                      -0.020296   \n",
       "intfloat__e5-base-v2                                                     -0.012237   \n",
       "intfloat__e5-large-v2                                                     0.000047   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                     -0.039221   \n",
       "intfloat__e5-mistral-7b-instruct                                         -0.030190   \n",
       "hkunlp__instructor-base                                                  -0.001483   \n",
       "hkunlp__instructor-large                                                  0.002685   \n",
       "hkunlp__instructor-xl                                                     0.032339   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                     -0.021886   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                   -0.017108   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                          -0.008476   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                               -0.030088   \n",
       "openai__text-embedding-ada-002                                            0.029551   \n",
       "openai__text-embedding-3-small                                            0.017449   \n",
       "openai__text-embedding-3-large                                            0.029514   \n",
       "voyageai__voyage-code-2                                                   0.020558   \n",
       "voyageai__voyage-code-3                                                   0.071781   \n",
       "microsoft__codebert-base                                                 -0.002863   \n",
       "microsoft__graphcodebert-base                                             0.002901   \n",
       "nomic-ai__CodeRankEmbed                                                   0.009875   \n",
       "local-repllama-llama31-8b-lora-64                                         0.000435   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.131704   \n",
       "local-repllama-llama32-3b-lora-256                                       -0.016183   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.092473   \n",
       "codesage__codesage-small                                                 -0.001475   \n",
       "codesage__codesage-base                                                   0.009027   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-go  \\\n",
       "bm25s                                                                    0.007742   \n",
       "facebook__contriever                                                     0.000300   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                           -0.006254   \n",
       "sentence-transformers__gtr-t5-base                                      -0.010511   \n",
       "sentence-transformers__gtr-t5-large                                     -0.020596   \n",
       "intfloat__e5-base-v2                                                    -0.019240   \n",
       "intfloat__e5-large-v2                                                   -0.026434   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                    -0.011362   \n",
       "intfloat__e5-mistral-7b-instruct                                        -0.002506   \n",
       "hkunlp__instructor-base                                                 -0.009735   \n",
       "hkunlp__instructor-large                                                -0.013166   \n",
       "hkunlp__instructor-xl                                                   -0.014542   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                    -0.007430   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                  -0.016352   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                         -0.002082   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                              -0.024374   \n",
       "openai__text-embedding-ada-002                                          -0.028007   \n",
       "openai__text-embedding-3-small                                          -0.026812   \n",
       "openai__text-embedding-3-large                                          -0.017097   \n",
       "voyageai__voyage-code-2                                                  0.040001   \n",
       "voyageai__voyage-code-3                                                  0.081736   \n",
       "microsoft__codebert-base                                                -0.003975   \n",
       "microsoft__graphcodebert-base                                           -0.002798   \n",
       "nomic-ai__CodeRankEmbed                                                 -0.015875   \n",
       "local-repllama-llama31-8b-lora-64                                       -0.011353   \n",
       "local-repllama-llama31-8b-lora-64-quality                                0.116017   \n",
       "local-repllama-llama32-3b-lora-256                                      -0.001296   \n",
       "local-repllama-llama32-3b-lora-256-quality                               0.103904   \n",
       "codesage__codesage-small                                                -0.021474   \n",
       "codesage__codesage-base                                                 -0.034263   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-java  \\\n",
       "bm25s                                                                     -0.003668   \n",
       "facebook__contriever                                                      -0.006725   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             -0.012888   \n",
       "sentence-transformers__gtr-t5-base                                        -0.004831   \n",
       "sentence-transformers__gtr-t5-large                                        0.008037   \n",
       "intfloat__e5-base-v2                                                       0.016877   \n",
       "intfloat__e5-large-v2                                                     -0.012663   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      -0.063745   \n",
       "intfloat__e5-mistral-7b-instruct                                           0.063765   \n",
       "hkunlp__instructor-base                                                   -0.008916   \n",
       "hkunlp__instructor-large                                                  -0.038203   \n",
       "hkunlp__instructor-xl                                                     -0.026334   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      -0.031798   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    -0.109216   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           -0.050030   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                -0.103169   \n",
       "openai__text-embedding-ada-002                                            -0.130648   \n",
       "openai__text-embedding-3-small                                            -0.074787   \n",
       "openai__text-embedding-3-large                                            -0.041284   \n",
       "voyageai__voyage-code-2                                                    0.062451   \n",
       "voyageai__voyage-code-3                                                    0.141653   \n",
       "microsoft__codebert-base                                                   0.003987   \n",
       "microsoft__graphcodebert-base                                              0.005000   \n",
       "nomic-ai__CodeRankEmbed                                                   -0.008178   \n",
       "local-repllama-llama31-8b-lora-64                                         -0.087916   \n",
       "local-repllama-llama31-8b-lora-64-quality                                  0.251947   \n",
       "local-repllama-llama32-3b-lora-256                                        -0.075138   \n",
       "local-repllama-llama32-3b-lora-256-quality                                 0.194133   \n",
       "codesage__codesage-small                                                  -0.034125   \n",
       "codesage__codesage-base                                                   -0.036066   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-javascript  \\\n",
       "bm25s                                                                            0.005517   \n",
       "facebook__contriever                                                            -0.002834   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                    0.007311   \n",
       "sentence-transformers__gtr-t5-base                                               0.009383   \n",
       "sentence-transformers__gtr-t5-large                                              0.022215   \n",
       "intfloat__e5-base-v2                                                             0.028326   \n",
       "intfloat__e5-large-v2                                                            0.010167   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                             0.027574   \n",
       "intfloat__e5-mistral-7b-instruct                                                 0.052003   \n",
       "hkunlp__instructor-base                                                          0.007215   \n",
       "hkunlp__instructor-large                                                         0.009135   \n",
       "hkunlp__instructor-xl                                                            0.020715   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                             0.056289   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                           0.076700   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                                  0.079033   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                       0.077564   \n",
       "openai__text-embedding-ada-002                                                   0.067125   \n",
       "openai__text-embedding-3-small                                                   0.019000   \n",
       "openai__text-embedding-3-large                                                   0.016799   \n",
       "voyageai__voyage-code-2                                                          0.080080   \n",
       "voyageai__voyage-code-3                                                          0.096440   \n",
       "microsoft__codebert-base                                                        -0.001963   \n",
       "microsoft__graphcodebert-base                                                    0.000225   \n",
       "nomic-ai__CodeRankEmbed                                                          0.007406   \n",
       "local-repllama-llama31-8b-lora-64                                                0.057897   \n",
       "local-repllama-llama31-8b-lora-64-quality                                        0.092479   \n",
       "local-repllama-llama32-3b-lora-256                                               0.081545   \n",
       "local-repllama-llama32-3b-lora-256-quality                                       0.058135   \n",
       "codesage__codesage-small                                                         0.040291   \n",
       "codesage__codesage-base                                                          0.043140   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-python  \\\n",
       "bm25s                                                                       -0.000565   \n",
       "facebook__contriever                                                         0.003648   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                               -0.002694   \n",
       "sentence-transformers__gtr-t5-base                                          -0.008854   \n",
       "sentence-transformers__gtr-t5-large                                         -0.014564   \n",
       "intfloat__e5-base-v2                                                         0.015610   \n",
       "intfloat__e5-large-v2                                                        0.003101   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                         0.029050   \n",
       "intfloat__e5-mistral-7b-instruct                                            -0.013993   \n",
       "hkunlp__instructor-base                                                     -0.003972   \n",
       "hkunlp__instructor-large                                                    -0.018154   \n",
       "hkunlp__instructor-xl                                                       -0.004379   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                        -0.006715   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                       0.007560   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                              0.008380   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                  -0.010083   \n",
       "openai__text-embedding-ada-002                                               0.007222   \n",
       "openai__text-embedding-3-small                                              -0.004741   \n",
       "openai__text-embedding-3-large                                               0.008689   \n",
       "voyageai__voyage-code-2                                                      0.028837   \n",
       "voyageai__voyage-code-3                                                      0.064815   \n",
       "microsoft__codebert-base                                                    -0.002912   \n",
       "microsoft__graphcodebert-base                                               -0.000014   \n",
       "nomic-ai__CodeRankEmbed                                                     -0.022013   \n",
       "local-repllama-llama31-8b-lora-64                                            0.008357   \n",
       "local-repllama-llama31-8b-lora-64-quality                                    0.124625   \n",
       "local-repllama-llama32-3b-lora-256                                           0.032394   \n",
       "local-repllama-llama32-3b-lora-256-quality                                   0.108730   \n",
       "codesage__codesage-small                                                     0.001451   \n",
       "codesage__codesage-base                                                      0.025002   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-ruby  \\\n",
       "bm25s                                                                     -0.000755   \n",
       "facebook__contriever                                                       0.001101   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                              0.001372   \n",
       "sentence-transformers__gtr-t5-base                                         0.003850   \n",
       "sentence-transformers__gtr-t5-large                                        0.002596   \n",
       "intfloat__e5-base-v2                                                       0.000516   \n",
       "intfloat__e5-large-v2                                                     -0.009282   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                       0.015526   \n",
       "intfloat__e5-mistral-7b-instruct                                          -0.002778   \n",
       "hkunlp__instructor-base                                                   -0.000919   \n",
       "hkunlp__instructor-large                                                  -0.003203   \n",
       "hkunlp__instructor-xl                                                      0.006026   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                       0.018753   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                     0.031573   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                            0.026929   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                 0.017366   \n",
       "openai__text-embedding-ada-002                                             0.044717   \n",
       "openai__text-embedding-3-small                                             0.017257   \n",
       "openai__text-embedding-3-large                                             0.023975   \n",
       "voyageai__voyage-code-2                                                    0.047671   \n",
       "voyageai__voyage-code-3                                                    0.115555   \n",
       "microsoft__codebert-base                                                  -0.000681   \n",
       "microsoft__graphcodebert-base                                              0.000434   \n",
       "nomic-ai__CodeRankEmbed                                                    0.009066   \n",
       "local-repllama-llama31-8b-lora-64                                          0.035849   \n",
       "local-repllama-llama31-8b-lora-64-quality                                  0.102598   \n",
       "local-repllama-llama32-3b-lora-256                                         0.043468   \n",
       "local-repllama-llama32-3b-lora-256-quality                                 0.080703   \n",
       "codesage__codesage-small                                                   0.007147   \n",
       "codesage__codesage-base                                                    0.035935   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-rust  \\\n",
       "bm25s                                                                      0.003070   \n",
       "facebook__contriever                                                      -0.000030   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             -0.009430   \n",
       "sentence-transformers__gtr-t5-base                                         0.001556   \n",
       "sentence-transformers__gtr-t5-large                                       -0.010922   \n",
       "intfloat__e5-base-v2                                                      -0.011941   \n",
       "intfloat__e5-large-v2                                                     -0.027497   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      -0.039837   \n",
       "intfloat__e5-mistral-7b-instruct                                           0.004873   \n",
       "hkunlp__instructor-base                                                   -0.006903   \n",
       "hkunlp__instructor-large                                                  -0.019264   \n",
       "hkunlp__instructor-xl                                                     -0.017566   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      -0.001746   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    -0.001670   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                            0.013983   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                -0.019627   \n",
       "openai__text-embedding-ada-002                                            -0.009209   \n",
       "openai__text-embedding-3-small                                            -0.002148   \n",
       "openai__text-embedding-3-large                                             0.023750   \n",
       "voyageai__voyage-code-2                                                    0.095715   \n",
       "voyageai__voyage-code-3                                                    0.132532   \n",
       "microsoft__codebert-base                                                   0.003923   \n",
       "microsoft__graphcodebert-base                                              0.002546   \n",
       "nomic-ai__CodeRankEmbed                                                   -0.028045   \n",
       "local-repllama-llama31-8b-lora-64                                          0.000710   \n",
       "local-repllama-llama31-8b-lora-64-quality                                  0.111870   \n",
       "local-repllama-llama32-3b-lora-256                                        -0.017307   \n",
       "local-repllama-llama32-3b-lora-256-quality                                 0.070076   \n",
       "codesage__codesage-small                                                  -0.014773   \n",
       "codesage__codesage-base                                                   -0.006326   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-swift  \\\n",
       "bm25s                                                                       0.003360   \n",
       "facebook__contriever                                                        0.007334   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                              -0.001345   \n",
       "sentence-transformers__gtr-t5-base                                          0.002468   \n",
       "sentence-transformers__gtr-t5-large                                        -0.000413   \n",
       "intfloat__e5-base-v2                                                        0.012312   \n",
       "intfloat__e5-large-v2                                                       0.010095   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                        0.010528   \n",
       "intfloat__e5-mistral-7b-instruct                                            0.040267   \n",
       "hkunlp__instructor-base                                                     0.001290   \n",
       "hkunlp__instructor-large                                                   -0.001489   \n",
       "hkunlp__instructor-xl                                                       0.006565   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                        0.032671   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                      0.020040   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                             0.041918   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                  0.047133   \n",
       "openai__text-embedding-ada-002                                              0.030930   \n",
       "openai__text-embedding-3-small                                             -0.007447   \n",
       "openai__text-embedding-3-large                                              0.021153   \n",
       "voyageai__voyage-code-2                                                     0.068329   \n",
       "voyageai__voyage-code-3                                                     0.073435   \n",
       "microsoft__codebert-base                                                   -0.000718   \n",
       "microsoft__graphcodebert-base                                              -0.000588   \n",
       "nomic-ai__CodeRankEmbed                                                    -0.009038   \n",
       "local-repllama-llama31-8b-lora-64                                           0.029978   \n",
       "local-repllama-llama31-8b-lora-64-quality                                   0.053952   \n",
       "local-repllama-llama32-3b-lora-256                                          0.026350   \n",
       "local-repllama-llama32-3b-lora-256-quality                                  0.022829   \n",
       "codesage__codesage-small                                                    0.010066   \n",
       "codesage__codesage-base                                                     0.015724   \n",
       "\n",
       "                                                 CodeNetBugPreferenceRetrieval-typescript  \\\n",
       "bm25s                                                                           -0.001084   \n",
       "facebook__contriever                                                            -0.008630   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                   -0.001401   \n",
       "sentence-transformers__gtr-t5-base                                              -0.003109   \n",
       "sentence-transformers__gtr-t5-large                                             -0.003906   \n",
       "intfloat__e5-base-v2                                                             0.000722   \n",
       "intfloat__e5-large-v2                                                           -0.001469   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                             0.000678   \n",
       "intfloat__e5-mistral-7b-instruct                                                 0.047450   \n",
       "hkunlp__instructor-base                                                         -0.001891   \n",
       "hkunlp__instructor-large                                                        -0.004985   \n",
       "hkunlp__instructor-xl                                                           -0.012769   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                             0.036771   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                           0.059847   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                                  0.069910   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                       0.039738   \n",
       "openai__text-embedding-ada-002                                                   0.055146   \n",
       "openai__text-embedding-3-small                                                   0.009842   \n",
       "openai__text-embedding-3-large                                                   0.051149   \n",
       "voyageai__voyage-code-2                                                          0.092150   \n",
       "voyageai__voyage-code-3                                                          0.098857   \n",
       "microsoft__codebert-base                                                         0.001816   \n",
       "microsoft__graphcodebert-base                                                   -0.000514   \n",
       "nomic-ai__CodeRankEmbed                                                          0.006370   \n",
       "local-repllama-llama31-8b-lora-64                                                0.062426   \n",
       "local-repllama-llama31-8b-lora-64-quality                                        0.066899   \n",
       "local-repllama-llama32-3b-lora-256                                               0.052934   \n",
       "local-repllama-llama32-3b-lora-256-quality                                       0.049604   \n",
       "codesage__codesage-small                                                         0.014877   \n",
       "codesage__codesage-base                                                          0.025998   \n",
       "\n",
       "                                                 ...  \\\n",
       "bm25s                                            ...   \n",
       "facebook__contriever                             ...   \n",
       "Alibaba-NLP__gte-base-en-v1.5                    ...   \n",
       "sentence-transformers__gtr-t5-base               ...   \n",
       "sentence-transformers__gtr-t5-large              ...   \n",
       "intfloat__e5-base-v2                             ...   \n",
       "intfloat__e5-large-v2                            ...   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct             ...   \n",
       "intfloat__e5-mistral-7b-instruct                 ...   \n",
       "hkunlp__instructor-base                          ...   \n",
       "hkunlp__instructor-large                         ...   \n",
       "hkunlp__instructor-xl                            ...   \n",
       "samaya-ai__promptriever-llama2-7b-v1             ...   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1           ...   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1  ...   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1       ...   \n",
       "openai__text-embedding-ada-002                   ...   \n",
       "openai__text-embedding-3-small                   ...   \n",
       "openai__text-embedding-3-large                   ...   \n",
       "voyageai__voyage-code-2                          ...   \n",
       "voyageai__voyage-code-3                          ...   \n",
       "microsoft__codebert-base                         ...   \n",
       "microsoft__graphcodebert-base                    ...   \n",
       "nomic-ai__CodeRankEmbed                          ...   \n",
       "local-repllama-llama31-8b-lora-64                ...   \n",
       "local-repllama-llama31-8b-lora-64-quality        ...   \n",
       "local-repllama-llama32-3b-lora-256               ...   \n",
       "local-repllama-llama32-3b-lora-256-quality       ...   \n",
       "codesage__codesage-small                         ...   \n",
       "codesage__codesage-base                          ...   \n",
       "\n",
       "                                                 DeprecatedCodePreferenceRetrieval  \\\n",
       "bm25s                                                                    -0.019841   \n",
       "facebook__contriever                                                      0.003271   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.011133   \n",
       "sentence-transformers__gtr-t5-base                                        0.007494   \n",
       "sentence-transformers__gtr-t5-large                                       0.005331   \n",
       "intfloat__e5-base-v2                                                      0.015921   \n",
       "intfloat__e5-large-v2                                                     0.014561   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.018533   \n",
       "intfloat__e5-mistral-7b-instruct                                          0.028600   \n",
       "hkunlp__instructor-base                                                   0.016457   \n",
       "hkunlp__instructor-large                                                  0.009689   \n",
       "hkunlp__instructor-xl                                                     0.012374   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.035403   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.037348   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                           0.042045   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.026433   \n",
       "openai__text-embedding-ada-002                                            0.025071   \n",
       "openai__text-embedding-3-small                                            0.022689   \n",
       "openai__text-embedding-3-large                                            0.027444   \n",
       "voyageai__voyage-code-2                                                   0.047801   \n",
       "voyageai__voyage-code-3                                                   0.080090   \n",
       "microsoft__codebert-base                                                 -0.000791   \n",
       "microsoft__graphcodebert-base                                             0.000477   \n",
       "nomic-ai__CodeRankEmbed                                                   0.025899   \n",
       "local-repllama-llama31-8b-lora-64                                         0.037369   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.133384   \n",
       "local-repllama-llama32-3b-lora-256                                        0.037707   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.095975   \n",
       "codesage__codesage-small                                                  0.021250   \n",
       "codesage__codesage-base                                                   0.017317   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-c  \\\n",
       "bm25s                                                                 -0.096946   \n",
       "facebook__contriever                                                  -0.058199   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                         -0.023081   \n",
       "sentence-transformers__gtr-t5-base                                     0.064598   \n",
       "sentence-transformers__gtr-t5-large                                    0.083239   \n",
       "intfloat__e5-base-v2                                                   0.123194   \n",
       "intfloat__e5-large-v2                                                  0.115895   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                   0.121807   \n",
       "intfloat__e5-mistral-7b-instruct                                       0.127216   \n",
       "hkunlp__instructor-base                                                0.043094   \n",
       "hkunlp__instructor-large                                               0.061269   \n",
       "hkunlp__instructor-xl                                                  0.080052   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                   0.113851   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                 0.056939   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                        0.095778   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                             0.073512   \n",
       "openai__text-embedding-ada-002                                        -0.021124   \n",
       "openai__text-embedding-3-small                                        -0.047367   \n",
       "openai__text-embedding-3-large                                        -0.020364   \n",
       "voyageai__voyage-code-2                                               -0.009247   \n",
       "voyageai__voyage-code-3                                                0.032932   \n",
       "microsoft__codebert-base                                              -0.001694   \n",
       "microsoft__graphcodebert-base                                         -0.001314   \n",
       "nomic-ai__CodeRankEmbed                                               -0.084756   \n",
       "local-repllama-llama31-8b-lora-64                                      0.042806   \n",
       "local-repllama-llama31-8b-lora-64-quality                              0.094334   \n",
       "local-repllama-llama32-3b-lora-256                                     0.023950   \n",
       "local-repllama-llama32-3b-lora-256-quality                             0.078629   \n",
       "codesage__codesage-small                                               0.028548   \n",
       "codesage__codesage-base                                                0.029716   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-cpp  \\\n",
       "bm25s                                                                    0.027103   \n",
       "facebook__contriever                                                    -0.071245   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                           -0.129503   \n",
       "sentence-transformers__gtr-t5-base                                      -0.083612   \n",
       "sentence-transformers__gtr-t5-large                                     -0.083333   \n",
       "intfloat__e5-base-v2                                                     0.081389   \n",
       "intfloat__e5-large-v2                                                    0.085556   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                    -0.004722   \n",
       "intfloat__e5-mistral-7b-instruct                                        -0.012500   \n",
       "hkunlp__instructor-base                                                 -0.039491   \n",
       "hkunlp__instructor-large                                                -0.137202   \n",
       "hkunlp__instructor-xl                                                   -0.031944   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                     0.111111   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                   0.106944   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                          0.165278   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                               0.009722   \n",
       "openai__text-embedding-ada-002                                          -0.022222   \n",
       "openai__text-embedding-3-small                                          -0.054722   \n",
       "openai__text-embedding-3-large                                          -0.001389   \n",
       "voyageai__voyage-code-2                                                 -0.019443   \n",
       "voyageai__voyage-code-3                                                  0.091667   \n",
       "microsoft__codebert-base                                                -0.006746   \n",
       "microsoft__graphcodebert-base                                           -0.011305   \n",
       "nomic-ai__CodeRankEmbed                                                 -0.064977   \n",
       "local-repllama-llama31-8b-lora-64                                        0.113889   \n",
       "local-repllama-llama31-8b-lora-64-quality                                0.031508   \n",
       "local-repllama-llama32-3b-lora-256                                       0.054167   \n",
       "local-repllama-llama32-3b-lora-256-quality                               0.132778   \n",
       "codesage__codesage-small                                                 0.011111   \n",
       "codesage__codesage-base                                                 -0.011111   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-python  \\\n",
       "bm25s                                                                       0.054320   \n",
       "facebook__contriever                                                       -0.034089   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                              -0.025942   \n",
       "sentence-transformers__gtr-t5-base                                         -0.024438   \n",
       "sentence-transformers__gtr-t5-large                                         0.046931   \n",
       "intfloat__e5-base-v2                                                       -0.009569   \n",
       "intfloat__e5-large-v2                                                       0.000564   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                        0.054292   \n",
       "intfloat__e5-mistral-7b-instruct                                            0.018248   \n",
       "hkunlp__instructor-base                                                    -0.019073   \n",
       "hkunlp__instructor-large                                                    0.060634   \n",
       "hkunlp__instructor-xl                                                      -0.007461   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                       -0.014904   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                     -0.041131   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                            -0.003674   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                 -0.029886   \n",
       "openai__text-embedding-ada-002                                              0.016284   \n",
       "openai__text-embedding-3-small                                             -0.023282   \n",
       "openai__text-embedding-3-large                                             -0.033235   \n",
       "voyageai__voyage-code-2                                                     0.037114   \n",
       "voyageai__voyage-code-3                                                     0.085909   \n",
       "microsoft__codebert-base                                                    0.003754   \n",
       "microsoft__graphcodebert-base                                               0.001844   \n",
       "nomic-ai__CodeRankEmbed                                                    -0.042790   \n",
       "local-repllama-llama31-8b-lora-64                                          -0.048132   \n",
       "local-repllama-llama31-8b-lora-64-quality                                   0.340473   \n",
       "local-repllama-llama32-3b-lora-256                                         -0.045239   \n",
       "local-repllama-llama32-3b-lora-256-quality                                  0.349840   \n",
       "codesage__codesage-small                                                    0.005134   \n",
       "codesage__codesage-base                                                    -0.000556   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-java  \\\n",
       "bm25s                                                                    -0.058136   \n",
       "facebook__contriever                                                     -0.204822   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                            -0.028601   \n",
       "sentence-transformers__gtr-t5-base                                       -0.095589   \n",
       "sentence-transformers__gtr-t5-large                                      -0.164161   \n",
       "intfloat__e5-base-v2                                                     -0.125321   \n",
       "intfloat__e5-large-v2                                                    -0.132508   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                     -0.151877   \n",
       "intfloat__e5-mistral-7b-instruct                                         -0.031352   \n",
       "hkunlp__instructor-base                                                   0.008288   \n",
       "hkunlp__instructor-large                                                 -0.026987   \n",
       "hkunlp__instructor-xl                                                    -0.131303   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.090751   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                   -0.025641   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                          -0.067308   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                0.001894   \n",
       "openai__text-embedding-ada-002                                            0.068758   \n",
       "openai__text-embedding-3-small                                            0.068573   \n",
       "openai__text-embedding-3-large                                            0.015018   \n",
       "voyageai__voyage-code-2                                                   0.071154   \n",
       "voyageai__voyage-code-3                                                   0.235897   \n",
       "microsoft__codebert-base                                                  0.010020   \n",
       "microsoft__graphcodebert-base                                             0.006045   \n",
       "nomic-ai__CodeRankEmbed                                                  -0.196237   \n",
       "local-repllama-llama31-8b-lora-64                                        -0.152396   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.175061   \n",
       "local-repllama-llama32-3b-lora-256                                       -0.069063   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.163235   \n",
       "codesage__codesage-small                                                  0.053023   \n",
       "codesage__codesage-base                                                  -0.036719   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-javascript  \\\n",
       "bm25s                                                                          -0.004915   \n",
       "facebook__contriever                                                           -0.075825   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                                  -0.023205   \n",
       "sentence-transformers__gtr-t5-base                                             -0.039694   \n",
       "sentence-transformers__gtr-t5-large                                            -0.052511   \n",
       "intfloat__e5-base-v2                                                           -0.045834   \n",
       "intfloat__e5-large-v2                                                          -0.058784   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                           -0.064545   \n",
       "intfloat__e5-mistral-7b-instruct                                               -0.040216   \n",
       "hkunlp__instructor-base                                                        -0.059155   \n",
       "hkunlp__instructor-large                                                       -0.065600   \n",
       "hkunlp__instructor-xl                                                          -0.093953   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                           -0.036202   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                          0.039619   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                                -0.021251   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                                     -0.040792   \n",
       "openai__text-embedding-ada-002                                                 -0.029884   \n",
       "openai__text-embedding-3-small                                                  0.002156   \n",
       "openai__text-embedding-3-large                                                  0.069248   \n",
       "voyageai__voyage-code-2                                                         0.012463   \n",
       "voyageai__voyage-code-3                                                         0.118928   \n",
       "microsoft__codebert-base                                                        0.016414   \n",
       "microsoft__graphcodebert-base                                                  -0.003049   \n",
       "nomic-ai__CodeRankEmbed                                                        -0.066862   \n",
       "local-repllama-llama31-8b-lora-64                                              -0.007463   \n",
       "local-repllama-llama31-8b-lora-64-quality                                       0.258228   \n",
       "local-repllama-llama32-3b-lora-256                                             -0.056620   \n",
       "local-repllama-llama32-3b-lora-256-quality                                      0.213493   \n",
       "codesage__codesage-small                                                        0.054266   \n",
       "codesage__codesage-base                                                         0.038717   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-go  \\\n",
       "bm25s                                                                   0.049174   \n",
       "facebook__contriever                                                   -0.066463   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                           0.014303   \n",
       "sentence-transformers__gtr-t5-base                                      0.169179   \n",
       "sentence-transformers__gtr-t5-large                                     0.127963   \n",
       "intfloat__e5-base-v2                                                    0.080714   \n",
       "intfloat__e5-large-v2                                                   0.040344   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                    0.048889   \n",
       "intfloat__e5-mistral-7b-instruct                                       -0.053704   \n",
       "hkunlp__instructor-base                                                 0.016622   \n",
       "hkunlp__instructor-large                                                0.056710   \n",
       "hkunlp__instructor-xl                                                   0.068000   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                   -0.018122   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                 -0.068519   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                         0.012963   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                              0.088175   \n",
       "openai__text-embedding-ada-002                                          0.045370   \n",
       "openai__text-embedding-3-small                                          0.040397   \n",
       "openai__text-embedding-3-large                                          0.057407   \n",
       "voyageai__voyage-code-2                                                -0.024259   \n",
       "voyageai__voyage-code-3                                                 0.054286   \n",
       "microsoft__codebert-base                                                0.028048   \n",
       "microsoft__graphcodebert-base                                           0.086962   \n",
       "nomic-ai__CodeRankEmbed                                                -0.039822   \n",
       "local-repllama-llama31-8b-lora-64                                       0.111111   \n",
       "local-repllama-llama31-8b-lora-64-quality                               0.244400   \n",
       "local-repllama-llama32-3b-lora-256                                      0.016667   \n",
       "local-repllama-llama32-3b-lora-256-quality                              0.210679   \n",
       "codesage__codesage-small                                                0.017778   \n",
       "codesage__codesage-base                                                -0.033333   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval-ruby  \\\n",
       "bm25s                                                                     0.007689   \n",
       "facebook__contriever                                                     -0.017507   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                             0.043305   \n",
       "sentence-transformers__gtr-t5-base                                       -0.070909   \n",
       "sentence-transformers__gtr-t5-large                                      -0.039933   \n",
       "intfloat__e5-base-v2                                                      0.036258   \n",
       "intfloat__e5-large-v2                                                     0.008048   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                      0.037989   \n",
       "intfloat__e5-mistral-7b-instruct                                         -0.048801   \n",
       "hkunlp__instructor-base                                                  -0.008613   \n",
       "hkunlp__instructor-large                                                  0.015921   \n",
       "hkunlp__instructor-xl                                                     0.008232   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                      0.035163   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                                    0.050407   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                          -0.075203   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                               -0.014010   \n",
       "openai__text-embedding-ada-002                                           -0.110366   \n",
       "openai__text-embedding-3-small                                            0.079636   \n",
       "openai__text-embedding-3-large                                           -0.116978   \n",
       "voyageai__voyage-code-2                                                   0.055100   \n",
       "voyageai__voyage-code-3                                                   0.083435   \n",
       "microsoft__codebert-base                                                 -0.017190   \n",
       "microsoft__graphcodebert-base                                             0.005518   \n",
       "nomic-ai__CodeRankEmbed                                                   0.025798   \n",
       "local-repllama-llama31-8b-lora-64                                        -0.026515   \n",
       "local-repllama-llama31-8b-lora-64-quality                                 0.292330   \n",
       "local-repllama-llama32-3b-lora-256                                       -0.016023   \n",
       "local-repllama-llama32-3b-lora-256-quality                                0.227352   \n",
       "codesage__codesage-small                                                 -0.003320   \n",
       "codesage__codesage-base                                                  -0.043061   \n",
       "\n",
       "                                                 SaferCodePreferenceRetrieval  \\\n",
       "bm25s                                                               -0.016983   \n",
       "facebook__contriever                                                -0.010169   \n",
       "Alibaba-NLP__gte-base-en-v1.5                                        0.005020   \n",
       "sentence-transformers__gtr-t5-base                                   0.004252   \n",
       "sentence-transformers__gtr-t5-large                                  0.002426   \n",
       "intfloat__e5-base-v2                                                 0.016638   \n",
       "intfloat__e5-large-v2                                                0.013517   \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                                 0.016389   \n",
       "intfloat__e5-mistral-7b-instruct                                     0.022714   \n",
       "hkunlp__instructor-base                                              0.012225   \n",
       "hkunlp__instructor-large                                             0.007175   \n",
       "hkunlp__instructor-xl                                                0.007618   \n",
       "samaya-ai__promptriever-llama2-7b-v1                                 0.036228   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                               0.033864   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                      0.037466   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                           0.024081   \n",
       "openai__text-embedding-ada-002                                       0.019493   \n",
       "openai__text-embedding-3-small                                       0.020410   \n",
       "openai__text-embedding-3-large                                       0.022020   \n",
       "voyageai__voyage-code-2                                              0.042637   \n",
       "voyageai__voyage-code-3                                              0.083564   \n",
       "microsoft__codebert-base                                             0.000140   \n",
       "microsoft__graphcodebert-base                                        0.002462   \n",
       "nomic-ai__CodeRankEmbed                                              0.010022   \n",
       "local-repllama-llama31-8b-lora-64                                    0.031801   \n",
       "local-repllama-llama31-8b-lora-64-quality                            0.145644   \n",
       "local-repllama-llama32-3b-lora-256                                   0.029021   \n",
       "local-repllama-llama32-3b-lora-256-quality                           0.113150   \n",
       "codesage__codesage-small                                             0.021684   \n",
       "codesage__codesage-base                                              0.012986   \n",
       "\n",
       "                                                 SQLR2PreferenceRetrieval  \n",
       "bm25s                                                            0.217158  \n",
       "facebook__contriever                                             0.080737  \n",
       "Alibaba-NLP__gte-base-en-v1.5                                    0.065668  \n",
       "sentence-transformers__gtr-t5-base                               0.035975  \n",
       "sentence-transformers__gtr-t5-large                              0.048570  \n",
       "intfloat__e5-base-v2                                             0.271137  \n",
       "intfloat__e5-large-v2                                            0.235500  \n",
       "Alibaba-NLP__gte-Qwen2-1.5B-instruct                             0.087614  \n",
       "intfloat__e5-mistral-7b-instruct                                 0.154830  \n",
       "hkunlp__instructor-base                                          0.080215  \n",
       "hkunlp__instructor-large                                         0.126380  \n",
       "hkunlp__instructor-xl                                            0.151370  \n",
       "samaya-ai__promptriever-llama2-7b-v1                             0.237587  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1                           0.229442  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1                  0.300318  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1                       0.233568  \n",
       "openai__text-embedding-ada-002                                   0.225891  \n",
       "openai__text-embedding-3-small                                   0.186433  \n",
       "openai__text-embedding-3-large                                   0.232123  \n",
       "voyageai__voyage-code-2                                          0.237849  \n",
       "voyageai__voyage-code-3                                          0.208566  \n",
       "microsoft__codebert-base                                         0.000485  \n",
       "microsoft__graphcodebert-base                                   -0.000782  \n",
       "nomic-ai__CodeRankEmbed                                          0.283637  \n",
       "local-repllama-llama31-8b-lora-64                                0.239974  \n",
       "local-repllama-llama31-8b-lora-64-quality                        0.163966  \n",
       "local-repllama-llama32-3b-lora-256                               0.259253  \n",
       "local-repllama-llama32-3b-lora-256-quality                       0.148587  \n",
       "codesage__codesage-small                                         0.047267  \n",
       "codesage__codesage-base                                          0.095636  \n",
       "\n",
       "[30 rows x 47 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f3110-ea34-4c0e-ab04-d912be0fa4e3",
   "metadata": {},
   "source": [
    "#### 3.2 Instruction Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca675791-76d1-4c67-bfeb-65b13004eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_models = [\n",
    "    'hkunlp__instructor-base_wo_instruction',\n",
    "    'hkunlp__instructor-large_wo_instruction',\n",
    "    'hkunlp__instructor-xl_wo_instruction',\n",
    "    'samaya-ai__promptriever-llama2-7b-v1_wo_instruction',\n",
    "    'samaya-ai__promptriever-llama3.1-8b-v1_wo_instruction',\n",
    "    'samaya-ai__promptriever-llama3.1-8b-instruct-v1_wo_instruction',\n",
    "    'samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_instruction',\n",
    "    'hkunlp__instructor-base_neg_instruction',\n",
    "    'hkunlp__instructor-large_neg_instruction',\n",
    "    'hkunlp__instructor-xl_neg_instruction',\n",
    "    'samaya-ai__promptriever-llama2-7b-v1_neg_instruction',\n",
    "    'samaya-ai__promptriever-llama3.1-8b-v1_neg_instruction',\n",
    "    'samaya-ai__promptriever-llama3.1-8b-instruct-v1_neg_instruction',\n",
    "    'samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_instruction'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4740231-c343-4a02-a6f8-bcb4b062b29e",
   "metadata": {},
   "source": [
    "##### PPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b28ded7-2182-4497-901d-c473a6988e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [12:55<00:00, 55.39s/it]\n"
     ]
    }
   ],
   "source": [
    "ppa_dict = defaultdict(dict)\n",
    "\n",
    "for _model in tqdm(ablation_models):\n",
    "    for _task in tasks:\n",
    "        ppa_values = []\n",
    "        for _subtask in task_sub_task_mapping[_task]:\n",
    "            _qrels_dict = load_qrels(_task, _subtask)\n",
    "            _predictions = load_predictions(_model, _task, _subtask)\n",
    "            _ppa_value = compute_ppa(_qrels_dict, _predictions)\n",
    "            ppa_values.append(_ppa_value)\n",
    "            ppa_dict[_model][_task + '-' + _subtask if _subtask is not None else _task] = _ppa_value\n",
    "        \n",
    "        # Compute mean PPA over subtasks\n",
    "        if _task not in ppa_dict[_model]:\n",
    "            mean_ppa = sum(ppa_values) / len(ppa_values) if ppa_values else None\n",
    "            ppa_dict[_model][_task] = mean_ppa\n",
    "\n",
    "df = pd.DataFrame.from_dict(ppa_dict, orient='index').style.apply(highlight_max_in_column, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da714088-39fb-4d16-8d52-60dd0194d727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodeNetBugPreferenceRetrieval</th>\n",
       "      <th>CodeNetEfficiencyPreferenceRetrieval</th>\n",
       "      <th>CVEFixesPreferenceRetrieval</th>\n",
       "      <th>Defects4JPreferenceRetrieval</th>\n",
       "      <th>DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th>SaferCodePreferenceRetrieval</th>\n",
       "      <th>SQLR2PreferenceRetrieval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base_wo_instruction</th>\n",
       "      <td>0.422701</td>\n",
       "      <td>0.394064</td>\n",
       "      <td>0.598573</td>\n",
       "      <td>0.616702</td>\n",
       "      <td>0.491650</td>\n",
       "      <td>0.495242</td>\n",
       "      <td>0.713998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large_wo_instruction</th>\n",
       "      <td>0.432950</td>\n",
       "      <td>0.426712</td>\n",
       "      <td>0.620426</td>\n",
       "      <td>0.599572</td>\n",
       "      <td>0.525746</td>\n",
       "      <td>0.495357</td>\n",
       "      <td>0.701227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl_wo_instruction</th>\n",
       "      <td>0.445227</td>\n",
       "      <td>0.424331</td>\n",
       "      <td>0.603786</td>\n",
       "      <td>0.623126</td>\n",
       "      <td>0.484970</td>\n",
       "      <td>0.475076</td>\n",
       "      <td>0.731798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1_wo_instruction</th>\n",
       "      <td>0.475894</td>\n",
       "      <td>0.459910</td>\n",
       "      <td>0.653528</td>\n",
       "      <td>0.693790</td>\n",
       "      <td>0.518630</td>\n",
       "      <td>0.536373</td>\n",
       "      <td>0.819690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1_wo_instruction</th>\n",
       "      <td>0.480715</td>\n",
       "      <td>0.468401</td>\n",
       "      <td>0.644419</td>\n",
       "      <td>0.678801</td>\n",
       "      <td>0.556390</td>\n",
       "      <td>0.520745</td>\n",
       "      <td>0.795253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1_wo_instruction</th>\n",
       "      <td>0.509171</td>\n",
       "      <td>0.490612</td>\n",
       "      <td>0.635323</td>\n",
       "      <td>0.670236</td>\n",
       "      <td>0.543952</td>\n",
       "      <td>0.516486</td>\n",
       "      <td>0.826529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_instruction</th>\n",
       "      <td>0.467433</td>\n",
       "      <td>0.467063</td>\n",
       "      <td>0.637727</td>\n",
       "      <td>0.683084</td>\n",
       "      <td>0.513540</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.813355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base_neg_instruction</th>\n",
       "      <td>0.422733</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.598079</td>\n",
       "      <td>0.616702</td>\n",
       "      <td>0.491877</td>\n",
       "      <td>0.495242</td>\n",
       "      <td>0.713898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large_neg_instruction</th>\n",
       "      <td>0.432950</td>\n",
       "      <td>0.427212</td>\n",
       "      <td>0.619736</td>\n",
       "      <td>0.599572</td>\n",
       "      <td>0.525952</td>\n",
       "      <td>0.495357</td>\n",
       "      <td>0.701227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl_neg_instruction</th>\n",
       "      <td>0.445227</td>\n",
       "      <td>0.424217</td>\n",
       "      <td>0.603786</td>\n",
       "      <td>0.623126</td>\n",
       "      <td>0.485580</td>\n",
       "      <td>0.475076</td>\n",
       "      <td>0.731798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1_neg_instruction</th>\n",
       "      <td>0.475846</td>\n",
       "      <td>0.462160</td>\n",
       "      <td>0.652256</td>\n",
       "      <td>0.689507</td>\n",
       "      <td>0.521538</td>\n",
       "      <td>0.535757</td>\n",
       "      <td>0.820093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1_neg_instruction</th>\n",
       "      <td>0.480763</td>\n",
       "      <td>0.468189</td>\n",
       "      <td>0.642043</td>\n",
       "      <td>0.678801</td>\n",
       "      <td>0.555414</td>\n",
       "      <td>0.513819</td>\n",
       "      <td>0.795857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1_neg_instruction</th>\n",
       "      <td>0.509602</td>\n",
       "      <td>0.492216</td>\n",
       "      <td>0.637576</td>\n",
       "      <td>0.670236</td>\n",
       "      <td>0.546134</td>\n",
       "      <td>0.509961</td>\n",
       "      <td>0.826730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_instruction</th>\n",
       "      <td>0.467385</td>\n",
       "      <td>0.466531</td>\n",
       "      <td>0.637675</td>\n",
       "      <td>0.680942</td>\n",
       "      <td>0.513111</td>\n",
       "      <td>0.510851</td>\n",
       "      <td>0.813455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    CodeNetBugPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                   0.422701   \n",
       "hkunlp__instructor-large_wo_instruction                                  0.432950   \n",
       "hkunlp__instructor-xl_wo_instruction                                     0.445227   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                       0.475894   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                       0.480715   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                       0.509171   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                       0.467433   \n",
       "hkunlp__instructor-base_neg_instruction                                  0.422733   \n",
       "hkunlp__instructor-large_neg_instruction                                 0.432950   \n",
       "hkunlp__instructor-xl_neg_instruction                                    0.445227   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                       0.475846   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                       0.480763   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                       0.509602   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                       0.467385   \n",
       "\n",
       "                                                    CodeNetEfficiencyPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                          0.394064   \n",
       "hkunlp__instructor-large_wo_instruction                                         0.426712   \n",
       "hkunlp__instructor-xl_wo_instruction                                            0.424331   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                              0.459910   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                              0.468401   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                              0.490612   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                              0.467063   \n",
       "hkunlp__instructor-base_neg_instruction                                         0.394602   \n",
       "hkunlp__instructor-large_neg_instruction                                        0.427212   \n",
       "hkunlp__instructor-xl_neg_instruction                                           0.424217   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                              0.462160   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                              0.468189   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                              0.492216   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                              0.466531   \n",
       "\n",
       "                                                    CVEFixesPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                 0.598573   \n",
       "hkunlp__instructor-large_wo_instruction                                0.620426   \n",
       "hkunlp__instructor-xl_wo_instruction                                   0.603786   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                     0.653528   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                     0.644419   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                     0.635323   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                     0.637727   \n",
       "hkunlp__instructor-base_neg_instruction                                0.598079   \n",
       "hkunlp__instructor-large_neg_instruction                               0.619736   \n",
       "hkunlp__instructor-xl_neg_instruction                                  0.603786   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                     0.652256   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                     0.642043   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                     0.637576   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                     0.637675   \n",
       "\n",
       "                                                    Defects4JPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                  0.616702   \n",
       "hkunlp__instructor-large_wo_instruction                                 0.599572   \n",
       "hkunlp__instructor-xl_wo_instruction                                    0.623126   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                      0.693790   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                      0.678801   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.670236   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                      0.683084   \n",
       "hkunlp__instructor-base_neg_instruction                                 0.616702   \n",
       "hkunlp__instructor-large_neg_instruction                                0.599572   \n",
       "hkunlp__instructor-xl_neg_instruction                                   0.623126   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                      0.689507   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                      0.678801   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.670236   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                      0.680942   \n",
       "\n",
       "                                                    DeprecatedCodePreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                       0.491650   \n",
       "hkunlp__instructor-large_wo_instruction                                      0.525746   \n",
       "hkunlp__instructor-xl_wo_instruction                                         0.484970   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                           0.518630   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                           0.556390   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                           0.543952   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                           0.513540   \n",
       "hkunlp__instructor-base_neg_instruction                                      0.491877   \n",
       "hkunlp__instructor-large_neg_instruction                                     0.525952   \n",
       "hkunlp__instructor-xl_neg_instruction                                        0.485580   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                           0.521538   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                           0.555414   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                           0.546134   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                           0.513111   \n",
       "\n",
       "                                                    SaferCodePreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                  0.495242   \n",
       "hkunlp__instructor-large_wo_instruction                                 0.495357   \n",
       "hkunlp__instructor-xl_wo_instruction                                    0.475076   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                      0.536373   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                      0.520745   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.516486   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                      0.511811   \n",
       "hkunlp__instructor-base_neg_instruction                                 0.495242   \n",
       "hkunlp__instructor-large_neg_instruction                                0.495357   \n",
       "hkunlp__instructor-xl_neg_instruction                                   0.475076   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                      0.535757   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                      0.513819   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.509961   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                      0.510851   \n",
       "\n",
       "                                                    SQLR2PreferenceRetrieval  \n",
       "hkunlp__instructor-base_wo_instruction                              0.713998  \n",
       "hkunlp__instructor-large_wo_instruction                             0.701227  \n",
       "hkunlp__instructor-xl_wo_instruction                                0.731798  \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                  0.819690  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                  0.795253  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                  0.826529  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                  0.813355  \n",
       "hkunlp__instructor-base_neg_instruction                             0.713898  \n",
       "hkunlp__instructor-large_neg_instruction                            0.701227  \n",
       "hkunlp__instructor-xl_neg_instruction                               0.731798  \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                  0.820093  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                  0.795857  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                  0.826730  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                  0.813455  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original_df is already your DataFrame\n",
    "ppa_df = pd.DataFrame.from_dict(ppa_dict, orient='index')\n",
    "mask = ~ppa_df.columns.astype(str).str.contains(r'-')\n",
    "ppa_instruct_mean_df = ppa_df.loc[:, mask]\n",
    "\n",
    "# inspect the result\n",
    "ppa_instruct_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdda45-a87d-4b35-bfe6-59447adf7e30",
   "metadata": {},
   "source": [
    "##### MRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba7447d2-5b11-4f43-9894-91c85b206dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [12:06<00:00, 51.87s/it]\n"
     ]
    }
   ],
   "source": [
    "mrs_dict = defaultdict(dict)\n",
    "for _model in tqdm(ablation_models):\n",
    "    mrs_values = []\n",
    "    for _task in tasks:\n",
    "        for _subtask in task_sub_task_mapping[_task]:\n",
    "            _qrels_dict = load_qrels(_task, _subtask)\n",
    "            _predictions = load_predictions(_model, _task, _subtask)\n",
    "            _mrs_value = compute_mrs(_qrels_dict, _predictions)\n",
    "            mrs_values.append(_mrs_value)\n",
    "            mrs_dict[_model][_task + '-' + _subtask if _subtask is not None else _task] = _mrs_value\n",
    "        \n",
    "        # Compute mean MRS over subtasks\n",
    "        if _task not in mrs_dict[_model]:\n",
    "            mean_mrs = sum(mrs_values) / len(mrs_values) if mrs_values else None\n",
    "            mrs_dict[_model][_task] = mean_mrs\n",
    "\n",
    "df = pd.DataFrame.from_dict(mrs_dict, orient='index').style.apply(highlight_max_in_column, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39952d4d-d7fb-45bf-94ed-b04673cc657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CodeNetBugPreferenceRetrieval</th>\n",
       "      <th>CodeNetEfficiencyPreferenceRetrieval</th>\n",
       "      <th>CVEFixesPreferenceRetrieval</th>\n",
       "      <th>Defects4JPreferenceRetrieval</th>\n",
       "      <th>DeprecatedCodePreferenceRetrieval</th>\n",
       "      <th>SaferCodePreferenceRetrieval</th>\n",
       "      <th>SQLR2PreferenceRetrieval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base_wo_instruction</th>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>0.118422</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>0.079925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large_wo_instruction</th>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.126495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl_wo_instruction</th>\n",
       "      <td>-0.000970</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.019793</td>\n",
       "      <td>0.126674</td>\n",
       "      <td>0.016776</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.151634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1_wo_instruction</th>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.033034</td>\n",
       "      <td>0.202358</td>\n",
       "      <td>0.035563</td>\n",
       "      <td>0.036332</td>\n",
       "      <td>0.237587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1_wo_instruction</th>\n",
       "      <td>0.005519</td>\n",
       "      <td>-0.002780</td>\n",
       "      <td>0.027356</td>\n",
       "      <td>0.182466</td>\n",
       "      <td>0.037843</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>0.229442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1_wo_instruction</th>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>0.180390</td>\n",
       "      <td>0.041404</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>0.300318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_instruction</th>\n",
       "      <td>-0.001368</td>\n",
       "      <td>-0.004661</td>\n",
       "      <td>0.025296</td>\n",
       "      <td>0.196042</td>\n",
       "      <td>0.027307</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.233568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-base_neg_instruction</th>\n",
       "      <td>-0.003344</td>\n",
       "      <td>-0.002798</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>0.118422</td>\n",
       "      <td>0.015415</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.079756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-large_neg_instruction</th>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>0.126767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hkunlp__instructor-xl_neg_instruction</th>\n",
       "      <td>-0.000970</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.126674</td>\n",
       "      <td>0.016864</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.151697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama2-7b-v1_neg_instruction</th>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.032579</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.035527</td>\n",
       "      <td>0.036234</td>\n",
       "      <td>0.239931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-v1_neg_instruction</th>\n",
       "      <td>0.005538</td>\n",
       "      <td>-0.002766</td>\n",
       "      <td>0.027083</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.037716</td>\n",
       "      <td>0.033131</td>\n",
       "      <td>0.228995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-llama3.1-8b-instruct-v1_neg_instruction</th>\n",
       "      <td>0.018942</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.178071</td>\n",
       "      <td>0.042087</td>\n",
       "      <td>0.036519</td>\n",
       "      <td>0.299271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_instruction</th>\n",
       "      <td>-0.001447</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>0.024913</td>\n",
       "      <td>0.196832</td>\n",
       "      <td>0.026805</td>\n",
       "      <td>0.024968</td>\n",
       "      <td>0.233083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    CodeNetBugPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                  -0.003342   \n",
       "hkunlp__instructor-large_wo_instruction                                 -0.007316   \n",
       "hkunlp__instructor-xl_wo_instruction                                    -0.000970   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                       0.005882   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                       0.005519   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                       0.018661   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                      -0.001368   \n",
       "hkunlp__instructor-base_neg_instruction                                 -0.003344   \n",
       "hkunlp__instructor-large_neg_instruction                                -0.007316   \n",
       "hkunlp__instructor-xl_neg_instruction                                   -0.000970   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                       0.005917   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                       0.005538   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                       0.018942   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                      -0.001447   \n",
       "\n",
       "                                                    CodeNetEfficiencyPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                         -0.002800   \n",
       "hkunlp__instructor-large_wo_instruction                                        -0.005174   \n",
       "hkunlp__instructor-xl_wo_instruction                                           -0.001686   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                              0.001766   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                             -0.002780   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                              0.009019   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                             -0.004661   \n",
       "hkunlp__instructor-base_neg_instruction                                        -0.002798   \n",
       "hkunlp__instructor-large_neg_instruction                                       -0.005173   \n",
       "hkunlp__instructor-xl_neg_instruction                                          -0.001691   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                              0.001534   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                             -0.002766   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                              0.009299   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                             -0.004930   \n",
       "\n",
       "                                                    CVEFixesPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                 0.017941   \n",
       "hkunlp__instructor-large_wo_instruction                                0.019751   \n",
       "hkunlp__instructor-xl_wo_instruction                                   0.019793   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                     0.033034   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                     0.027356   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                     0.035227   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                     0.025296   \n",
       "hkunlp__instructor-base_neg_instruction                                0.017868   \n",
       "hkunlp__instructor-large_neg_instruction                               0.019613   \n",
       "hkunlp__instructor-xl_neg_instruction                                  0.019783   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                     0.032579   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                     0.027083   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                     0.035837   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                     0.024913   \n",
       "\n",
       "                                                    Defects4JPreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                  0.118422   \n",
       "hkunlp__instructor-large_wo_instruction                                 0.100129   \n",
       "hkunlp__instructor-xl_wo_instruction                                    0.126674   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                      0.202358   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                      0.182466   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.180390   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                      0.196042   \n",
       "hkunlp__instructor-base_neg_instruction                                 0.118422   \n",
       "hkunlp__instructor-large_neg_instruction                                0.100129   \n",
       "hkunlp__instructor-xl_neg_instruction                                   0.126674   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                      0.199146   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                      0.181324   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.178071   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                      0.196832   \n",
       "\n",
       "                                                    DeprecatedCodePreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                       0.015424   \n",
       "hkunlp__instructor-large_wo_instruction                                      0.023168   \n",
       "hkunlp__instructor-xl_wo_instruction                                         0.016776   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                           0.035563   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                           0.037843   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                           0.041404   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                           0.027307   \n",
       "hkunlp__instructor-base_neg_instruction                                      0.015415   \n",
       "hkunlp__instructor-large_neg_instruction                                     0.023115   \n",
       "hkunlp__instructor-xl_neg_instruction                                        0.016864   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                           0.035527   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                           0.037716   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                           0.042087   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                           0.026805   \n",
       "\n",
       "                                                    SaferCodePreferenceRetrieval  \\\n",
       "hkunlp__instructor-base_wo_instruction                                  0.011368   \n",
       "hkunlp__instructor-large_wo_instruction                                 0.018353   \n",
       "hkunlp__instructor-xl_wo_instruction                                    0.011269   \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                      0.036332   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                      0.034728   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.037095   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                      0.025500   \n",
       "hkunlp__instructor-base_neg_instruction                                 0.011360   \n",
       "hkunlp__instructor-large_neg_instruction                                0.018313   \n",
       "hkunlp__instructor-xl_neg_instruction                                   0.011341   \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                      0.036234   \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                      0.033131   \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                      0.036519   \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                      0.024968   \n",
       "\n",
       "                                                    SQLR2PreferenceRetrieval  \n",
       "hkunlp__instructor-base_wo_instruction                              0.079925  \n",
       "hkunlp__instructor-large_wo_instruction                             0.126495  \n",
       "hkunlp__instructor-xl_wo_instruction                                0.151634  \n",
       "samaya-ai__promptriever-llama2-7b-v1_wo_instruc...                  0.237587  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_wo_instr...                  0.229442  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                  0.300318  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_wo_i...                  0.233568  \n",
       "hkunlp__instructor-base_neg_instruction                             0.079756  \n",
       "hkunlp__instructor-large_neg_instruction                            0.126767  \n",
       "hkunlp__instructor-xl_neg_instruction                               0.151697  \n",
       "samaya-ai__promptriever-llama2-7b-v1_neg_instru...                  0.239931  \n",
       "samaya-ai__promptriever-llama3.1-8b-v1_neg_inst...                  0.228995  \n",
       "samaya-ai__promptriever-llama3.1-8b-instruct-v1...                  0.299271  \n",
       "samaya-ai__promptriever-mistral-v0.1-7b-v1_neg_...                  0.233083  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrs_df = pd.DataFrame.from_dict(mrs_dict, orient='index')\n",
    "# original_df is already your DataFrame\n",
    "mask = ~mrs_df.columns.astype(str).str.contains(r'-')\n",
    "mrs_mean_df = mrs_df.loc[:, mask]\n",
    "\n",
    "# inspect the result\n",
    "mrs_mean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
